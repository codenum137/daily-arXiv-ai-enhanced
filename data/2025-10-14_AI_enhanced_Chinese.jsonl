{"id": "2510.09644", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09644", "abs": "https://arxiv.org/abs/2510.09644", "authors": ["Shaharyar Alam Ansari", "Mohammad Luqman", "Aasim Zafar", "Savir Ali"], "title": "Enhanced Urban Traffic Management Using CCTV Surveillance Videos and Multi-Source Data Current State Prediction and Frequent Episode Mining", "comment": "24 pages, 9 figures", "summary": "Rapid urbanization has intensified traffic congestion, environmental strain,\nand inefficiencies in transportation systems, creating an urgent need for\nintelligent and adaptive traffic management solutions. Conventional systems\nrelying on static signals and manual monitoring are inadequate for the dynamic\nnature of modern traffic. This research aims to develop a unified framework\nthat integrates CCTV surveillance videos with multi-source data descriptors to\nenhance real-time urban traffic prediction. The proposed methodology\nincorporates spatio-temporal feature fusion, Frequent Episode Mining for\nsequential traffic pattern discovery, and a hybrid LSTM-Transformer model for\nrobust traffic state forecasting. The framework was evaluated on the CityFlowV2\ndataset comprising 313,931 annotated bounding boxes across 46 cameras. It\nachieved a high prediction accuracy of 98.46 percent, with a macro precision of\n0.9800, macro recall of 0.9839, and macro F1-score of 0.9819. FEM analysis\nrevealed significant sequential patterns such as moderate-congested transitions\nwith confidence levels exceeding 55 percent. The 46 sustained congestion alerts\nare system-generated, which shows practical value for proactive congestion\nmanagement. This emphasizes the need for the incorporation of video stream\nanalytics with data from multiple sources for the design of real-time,\nresponsive, adaptable multi-level intelligent transportation systems, which\nmakes urban mobility smarter and safer.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u96c6\u6210CCTV\u76d1\u63a7\u89c6\u9891\u548c\u591a\u6e90\u6570\u636e\u63cf\u8ff0\u7b26\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u5b9e\u65f6\u57ce\u5e02\u4ea4\u901a\u9884\u6d4b\uff0c\u5728CityFlowV2\u6570\u636e\u96c6\u4e0a\u8fbe\u523098.46%\u7684\u9884\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u5feb\u901f\u57ce\u5e02\u5316\u52a0\u5267\u4e86\u4ea4\u901a\u62e5\u5835\u3001\u73af\u5883\u538b\u529b\u548c\u4ea4\u901a\u7cfb\u7edf\u4f4e\u6548\uff0c\u8feb\u5207\u9700\u8981\u667a\u80fd\u81ea\u9002\u5e94\u7684\u4ea4\u901a\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002\u4f20\u7edf\u4f9d\u8d56\u9759\u6001\u4fe1\u53f7\u548c\u624b\u52a8\u76d1\u63a7\u7684\u7cfb\u7edf\u65e0\u6cd5\u5e94\u5bf9\u73b0\u4ee3\u4ea4\u901a\u7684\u52a8\u6001\u7279\u6027\u3002", "method": "\u91c7\u7528\u65f6\u7a7a\u7279\u5f81\u878d\u5408\u3001\u9891\u7e41\u5e8f\u5217\u6316\u6398(FEM)\u7528\u4e8e\u53d1\u73b0\u987a\u5e8f\u4ea4\u901a\u6a21\u5f0f\uff0c\u4ee5\u53ca\u6df7\u5408LSTM-Transformer\u6a21\u578b\u8fdb\u884c\u7a33\u5065\u7684\u4ea4\u901a\u72b6\u6001\u9884\u6d4b\u3002", "result": "\u5728\u5305\u542b46\u4e2a\u6444\u50cf\u5934313,931\u4e2a\u6807\u6ce8\u8fb9\u754c\u6846\u7684CityFlowV2\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e8698.46%\u7684\u9ad8\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u5b8f\u7cbe\u5ea60.9800\uff0c\u5b8f\u53ec\u56de0.9839\uff0c\u5b8fF1\u5206\u65700.9819\u3002FEM\u5206\u6790\u63ed\u793a\u4e86\u7f6e\u4fe1\u5ea6\u8d85\u8fc755%\u7684\u4e2d\u5ea6\u62e5\u5835\u8f6c\u6362\u7b49\u663e\u8457\u987a\u5e8f\u6a21\u5f0f\uff0c\u7cfb\u7edf\u751f\u6210\u4e8646\u4e2a\u6301\u7eed\u62e5\u5835\u8b66\u62a5\u3002", "conclusion": "\u5f3a\u8c03\u9700\u8981\u5c06\u89c6\u9891\u6d41\u5206\u6790\u4e0e\u591a\u6e90\u6570\u636e\u76f8\u7ed3\u5408\uff0c\u8bbe\u8ba1\u5b9e\u65f6\u3001\u54cd\u5e94\u5f0f\u3001\u81ea\u9002\u5e94\u7684\u591a\u5c42\u6b21\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\uff0c\u4f7f\u57ce\u5e02\u4ea4\u901a\u66f4\u667a\u80fd\u3001\u66f4\u5b89\u5168\u3002"}}
{"id": "2510.09657", "categories": ["cs.LG", "cs.AI", "cs.NA", "eess.SP", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.09657", "abs": "https://arxiv.org/abs/2510.09657", "authors": ["Riccardo Fosco Gramaccioni", "Christian Marinoni", "Fabrizio Frezza", "Aurelio Uncini", "Danilo Comminiello"], "title": "Generative Models for Helmholtz Equation Solutions: A Dataset of Acoustic Materials", "comment": "Accepted at EUSIPCO 2025", "summary": "Accurate simulation of wave propagation in complex acoustic materials is\ncrucial for applications in sound design, noise control, and material\nengineering. Traditional numerical solvers, such as finite element methods, are\ncomputationally expensive, especially when dealing with large-scale or\nreal-time scenarios. In this work, we introduce a dataset of 31,000 acoustic\nmaterials, named HA30K, designed and simulated solving the Helmholtz equations.\nFor each material, we provide the geometric configuration and the corresponding\npressure field solution, enabling data-driven approaches to learn Helmholtz\nequation solutions. As a baseline, we explore a deep learning approach based on\nStable Diffusion with ControlNet, a state-of-the-art model for image\ngeneration. Unlike classical solvers, our approach leverages GPU\nparallelization to process multiple simulations simultaneously, drastically\nreducing computation time. By representing solutions as images, we bypass the\nneed for complex simulation software and explicit equation-solving.\nAdditionally, the number of diffusion steps can be adjusted at inference time,\nbalancing speed and quality. We aim to demonstrate that deep learning-based\nmethods are particularly useful in early-stage research, where rapid\nexploration is more critical than absolute accuracy.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86HA30K\u6570\u636e\u96c6\uff0c\u5305\u542b31,000\u79cd\u58f0\u5b66\u6750\u6599\u7684\u51e0\u4f55\u914d\u7f6e\u548c\u538b\u529b\u573a\u89e3\uff0c\u57fa\u4e8eStable Diffusion\u4e0eControlNet\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5feb\u901f\u6c42\u89e3Helmholtz\u65b9\u7a0b\uff0c\u76f8\u6bd4\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u590d\u6742\u58f0\u5b66\u6750\u6599\u4e2d\u6ce2\u4f20\u64ad\u7684\u7cbe\u786e\u6a21\u62df\u5728\u58f0\u97f3\u8bbe\u8ba1\u3001\u566a\u58f0\u63a7\u5236\u548c\u6750\u6599\u5de5\u7a0b\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u6570\u503c\u6c42\u89e3\u5668\uff08\u5982\u6709\u9650\u5143\u65b9\u6cd5\uff09\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6216\u5b9e\u65f6\u573a\u666f\u4e0b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eStable Diffusion\u4e0eControlNet\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u89e3\u8868\u793a\u4e3a\u56fe\u50cf\uff0c\u5229\u7528GPU\u5e76\u884c\u5316\u540c\u65f6\u5904\u7406\u591a\u4e2a\u6a21\u62df\uff0c\u65e0\u9700\u590d\u6742\u6a21\u62df\u8f6f\u4ef6\u548c\u663e\u5f0f\u65b9\u7a0b\u6c42\u89e3\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\uff0c\u6269\u6563\u6b65\u9aa4\u53ef\u5728\u63a8\u7406\u65f6\u8c03\u6574\u4ee5\u5e73\u8861\u901f\u5ea6\u548c\u8d28\u91cf\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u662f\u65e9\u671f\u7814\u7a76\u9636\u6bb5\u7279\u522b\u6709\u7528\u7684\u5de5\u5177\uff0c\u6b64\u65f6\u5feb\u901f\u63a2\u7d22\u6bd4\u7edd\u5bf9\u7cbe\u5ea6\u66f4\u91cd\u8981\u3002"}}
{"id": "2510.09658", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.09658", "abs": "https://arxiv.org/abs/2510.09658", "authors": ["Filippo Rinaldi", "Aniello Panariello", "Giacomo Salici", "Fengyuan Liu", "Marco Ciccone", "Angelo Porrello", "Simone Calderara"], "title": "Gradient-Sign Masking for Task Vector Transport Across Pre-Trained Models", "comment": null, "summary": "When a new release of a foundation model is published, practitioners\ntypically need to repeat full fine-tuning, even if the same task has already\nbeen solved in the previous version. A promising alternative is to reuse the\nparameter changes (i.e., task vectors) that capture how a model adapts to a\nspecific task. However, they often fail to transfer across different\npre-trained models due to their misaligned parameter space. In this work, we\nshow that the key to successful transfer lies in the sign structure of the\ngradients of the new model. Based on this insight, we propose GradFix, a novel\nmethod that approximates the ideal gradient sign structure and leverages it to\ntransfer knowledge using only a handful of labeled samples. Notably, this\nrequires no additional fine-tuning: the adaptation is achieved by computing a\nfew gradients at the target model and masking the source task vector\naccordingly. This yields an update that is locally aligned with the target loss\nlandscape, effectively rebasing the task vector onto the new pre-training. We\nprovide a theoretical guarantee that our method ensures first-order descent.\nEmpirically, we demonstrate significant performance gains on vision and\nlanguage benchmarks, consistently outperforming naive task vector addition and\nfew-shot fine-tuning.", "AI": {"tldr": "GradFix\u662f\u4e00\u79cd\u65e0\u9700\u989d\u5916\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u65b0\u6a21\u578b\u68af\u5ea6\u7b26\u53f7\u7ed3\u6784\u6765\u8de8\u4e0d\u540c\u9884\u8bad\u7ec3\u6a21\u578b\u4f20\u8f93\u4efb\u52a1\u5411\u91cf\uff0c\u4ec5\u9700\u5c11\u91cf\u6807\u6ce8\u6837\u672c\u5373\u53ef\u5b9e\u73b0\u77e5\u8bc6\u8fc1\u79fb\u3002", "motivation": "\u5f53\u53d1\u5e03\u65b0\u7684\u57fa\u7840\u6a21\u578b\u7248\u672c\u65f6\uff0c\u5373\u4f7f\u76f8\u540c\u4efb\u52a1\u5df2\u5728\u5148\u524d\u7248\u672c\u4e2d\u89e3\u51b3\uff0c\u5b9e\u8df5\u8005\u901a\u5e38\u9700\u8981\u91cd\u590d\u5b8c\u6574\u5fae\u8c03\u3002\u4efb\u52a1\u5411\u91cf\u867d\u7136\u80fd\u6355\u83b7\u6a21\u578b\u5982\u4f55\u9002\u5e94\u7279\u5b9a\u4efb\u52a1\uff0c\u4f46\u7531\u4e8e\u53c2\u6570\u7a7a\u95f4\u4e0d\u5bf9\u9f50\uff0c\u5f80\u5f80\u65e0\u6cd5\u5728\u4e0d\u540c\u9884\u8bad\u7ec3\u6a21\u578b\u95f4\u6210\u529f\u4f20\u8f93\u3002", "method": "\u63d0\u51faGradFix\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u76ee\u6807\u6a21\u578b\u7684\u5c11\u91cf\u68af\u5ea6\u5e76\u76f8\u5e94\u5c4f\u853d\u6e90\u4efb\u52a1\u5411\u91cf\uff0c\u8fd1\u4f3c\u7406\u60f3\u68af\u5ea6\u7b26\u53f7\u7ed3\u6784\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u5fae\u8c03\uff0c\u4ec5\u9700\u5728\u76ee\u6807\u6a21\u578b\u4e0a\u8ba1\u7b97\u51e0\u4e2a\u68af\u5ea6\uff0c\u751f\u6210\u4e0e\u76ee\u6807\u635f\u5931\u666f\u89c2\u5c40\u90e8\u5bf9\u9f50\u7684\u66f4\u65b0\u3002", "result": "\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u6301\u7eed\u4f18\u4e8e\u6734\u7d20\u4efb\u52a1\u5411\u91cf\u76f8\u52a0\u548c\u5c11\u6837\u672c\u5fae\u8c03\u65b9\u6cd5\u3002", "conclusion": "GradFix\u901a\u8fc7\u5229\u7528\u68af\u5ea6\u7b26\u53f7\u7ed3\u6784\u6210\u529f\u5b9e\u73b0\u4e86\u4efb\u52a1\u5411\u91cf\u5728\u4e0d\u540c\u9884\u8bad\u7ec3\u6a21\u578b\u95f4\u7684\u4f20\u8f93\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u786e\u4fdd\u4e00\u9636\u4e0b\u964d\uff0c\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.09983", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.09983", "abs": "https://arxiv.org/abs/2510.09983", "authors": ["Ethan Thompson", "Ali Sadeghi Jahromi", "AbdelRahman Abdou"], "title": "Fine-grained CDN Delegation", "comment": "13 pages, 2 figures", "summary": "The use of Content Delivery Networks (CDNs) has significantly increased over\nthe past decade, with approximately 55 million websites currently relying on\nCDN services. Emerging solutions, such as Delegated Credentials (RFC 9345),\nlack fine-grained definitions of many critical aspects of delegation, such as\nthe length of delegation chains, revocation mechanism, permitted operations,\nand a well-defined scope for said delegation. We present Delegation\nCertificates (DeCerts), which modify X.509 certificate standard and add new\nextensions to enable fine-grained CDN delegation. DeCerts allow domain owners\nto specify delegated and non-delegated subdomains, and control the depth of\ndelegation extended by CDNs, which provides flexibility in delegation\nmanagement. But more importantly, DeCerts are built on a new principle which\nprovides full autonomy to domain owners-domain owners can issue DeCerts fully\nindependent of Certificate Authorities (CAs), and thus have greater flexibility\nin policy control, including revocation methods. Such level of flexibility\nwould be hard to match if CAs where to issue such certificates. Revoking a\nDeCert revokes delegation. We discuss multiple revocation mechanisms for a\nDeCerts balancing security, performance, and delegator control. We modify\nFirefox to support DeCert (i.e., proper validation) as a proof-of-concept, and\ntest it to demonstrate the feasibility, compatibility of DeCerts with browsers\nand TLS/HTTPS protocols. DeCerts enhance the security, scalability, and\nmanageability of CDN delegation, offering a practical solution for Internet\nservices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u59d4\u6258\u8bc1\u4e66\uff08DeCerts\uff09\uff0c\u901a\u8fc7\u4fee\u6539X.509\u8bc1\u4e66\u6807\u51c6\u5e76\u6dfb\u52a0\u65b0\u6269\u5c55\u6765\u652f\u6301\u7ec6\u7c92\u5ea6\u7684CDN\u59d4\u6258\uff0c\u4f7f\u57df\u540d\u6240\u6709\u8005\u80fd\u591f\u72ec\u7acb\u4e8e\u8bc1\u4e66\u9881\u53d1\u673a\u6784\uff08CA\uff09\u8fdb\u884c\u59d4\u6258\u7ba1\u7406\uff0c\u63d0\u9ad8\u4e86\u59d4\u6258\u7684\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u7ba1\u7406\u6027\u3002", "motivation": "\u5f53\u524dCDN\u4f7f\u7528\u5e7f\u6cdb\uff0c\u4f46\u73b0\u6709\u59d4\u6258\u89e3\u51b3\u65b9\u6848\uff08\u5982RFC 9345\uff09\u7f3a\u4e4f\u5bf9\u59d4\u6258\u94fe\u957f\u5ea6\u3001\u64a4\u9500\u673a\u5236\u3001\u5141\u8bb8\u64cd\u4f5c\u548c\u59d4\u6258\u8303\u56f4\u7b49\u5173\u952e\u65b9\u9762\u7684\u7ec6\u7c92\u5ea6\u5b9a\u4e49\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u548c\u5b89\u5168\u7684\u59d4\u6258\u673a\u5236\u3002", "method": "\u4fee\u6539X.509\u8bc1\u4e66\u6807\u51c6\uff0c\u6dfb\u52a0\u65b0\u7684\u6269\u5c55\u6765\u652f\u6301\u7ec6\u7c92\u5ea6CDN\u59d4\u6258\uff1b\u5141\u8bb8\u57df\u540d\u6240\u6709\u8005\u6307\u5b9a\u59d4\u6258\u548c\u975e\u59d4\u6258\u5b50\u57df\u540d\uff0c\u63a7\u5236\u59d4\u6258\u6df1\u5ea6\uff1b\u5b9e\u73b0\u72ec\u7acb\u4e8eCA\u7684\u8bc1\u4e66\u9881\u53d1\uff1b\u8ba8\u8bba\u591a\u79cd\u64a4\u9500\u673a\u5236\uff1b\u4fee\u6539Firefox\u6d4f\u89c8\u5668\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86DeCerts\u7684\u539f\u578b\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86\u5176\u4e0e\u6d4f\u89c8\u5668\u548cTLS/HTTPS\u534f\u8bae\u7684\u517c\u5bb9\u6027\u548c\u53ef\u884c\u6027\uff1b\u63d0\u4f9b\u4e86\u5728\u5b89\u5168\u3001\u6027\u80fd\u548c\u59d4\u6258\u8005\u63a7\u5236\u4e4b\u95f4\u7684\u5e73\u8861\u64a4\u9500\u673a\u5236\u3002", "conclusion": "DeCerts\u901a\u8fc7\u8d4b\u4e88\u57df\u540d\u6240\u6709\u8005\u5b8c\u5168\u81ea\u4e3b\u6743\uff0c\u663e\u8457\u63d0\u5347\u4e86CDN\u59d4\u6258\u7684\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u7ba1\u7406\u6027\uff0c\u4e3a\u4e92\u8054\u7f51\u670d\u52a1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09660", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.09660", "abs": "https://arxiv.org/abs/2510.09660", "authors": ["Luca Scimeca", "Thomas Jiralerspong", "Berton Earnshaw", "Jason Hartford", "Yoshua Bengio"], "title": "Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise", "comment": null, "summary": "Diffusion Probabilistic Models (DPMs) have achieved strong generative\nperformance, yet their inductive biases remain largely implicit. In this work,\nwe aim to build inductive biases into the training and sampling of diffusion\nmodels to better accommodate the target distribution of the data to model. We\nintroduce an anisotropic noise operator that shapes these biases by replacing\nthe isotropic forward covariance with a structured, frequency-diagonal\ncovariance. This operator unifies band-pass masks and power-law weightings,\nallowing us to emphasize or suppress designated frequency bands, while keeping\nthe forward process Gaussian. We refer to this as spectrally anisotropic\nGaussian diffusion (SAGD). In this work, we derive the score relation for\nanisotropic covariances and show that, under full support, the learned score\nconverges to the true data score as $t\\!\\to\\!0$, while anisotropy reshapes the\nprobability-flow path from noise to data. Empirically, we show the induced\nanisotropy outperforms standard diffusion across several vision datasets, and\nenables selective omission: learning while ignoring known corruptions confined\nto specific bands. Together, these results demonstrate that carefully designed\nanisotropic forward noise provides a simple, yet principled, handle to tailor\ninductive bias in DPMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5149\u8c31\u5404\u5411\u5f02\u6027\u9ad8\u65af\u6269\u6563\uff08SAGD\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5404\u5411\u5f02\u6027\u566a\u58f0\u7b97\u5b50\u6765\u6784\u5efa\u6269\u6563\u6982\u7387\u6a21\u578b\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u8be5\u7b97\u5b50\u7528\u7ed3\u6784\u5316\u7684\u9891\u7387\u5bf9\u89d2\u534f\u65b9\u5dee\u66ff\u6362\u4e86\u4f20\u7edf\u7684\u5404\u5411\u540c\u6027\u524d\u5411\u534f\u65b9\u5dee\u3002", "motivation": "\u6269\u6563\u6982\u7387\u6a21\u578b\u867d\u7136\u53d6\u5f97\u4e86\u5f3a\u5927\u7684\u751f\u6210\u6027\u80fd\uff0c\u4f46\u5176\u5f52\u7eb3\u504f\u7f6e\u5927\u591a\u662f\u9690\u5f0f\u7684\u3002\u672c\u6587\u65e8\u5728\u5c06\u5f52\u7eb3\u504f\u7f6e\u663e\u5f0f\u5730\u6784\u5efa\u5230\u6269\u6563\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u91c7\u6837\u8fc7\u7a0b\u4e2d\uff0c\u4ee5\u66f4\u597d\u5730\u9002\u5e94\u6570\u636e\u7684\u5206\u5e03\u7279\u6027\u3002", "method": "\u5f15\u5165\u5404\u5411\u5f02\u6027\u566a\u58f0\u7b97\u5b50\uff0c\u5c06\u5404\u5411\u540c\u6027\u524d\u5411\u534f\u65b9\u5dee\u66ff\u6362\u4e3a\u7ed3\u6784\u5316\u7684\u9891\u7387\u5bf9\u89d2\u534f\u65b9\u5dee\uff0c\u7edf\u4e00\u4e86\u5e26\u901a\u63a9\u7801\u548c\u5e42\u5f8b\u52a0\u6743\uff0c\u5141\u8bb8\u5f3a\u8c03\u6216\u6291\u5236\u6307\u5b9a\u9891\u6bb5\uff0c\u540c\u65f6\u4fdd\u6301\u524d\u5411\u8fc7\u7a0b\u7684\u9ad8\u65af\u6027\u3002\u63a8\u5bfc\u4e86\u5404\u5411\u5f02\u6027\u534f\u65b9\u5dee\u7684\u5f97\u5206\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8bf1\u5bfc\u7684\u5404\u5411\u5f02\u6027\u5728\u591a\u4e2a\u89c6\u89c9\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6807\u51c6\u6269\u6563\u6a21\u578b\uff0c\u5e76\u5b9e\u73b0\u4e86\u9009\u62e9\u6027\u5ffd\u7565\uff1a\u5728\u7279\u5b9a\u9891\u6bb5\u5185\u5ffd\u7565\u5df2\u77e5\u7684\u635f\u574f\u6a21\u5f0f\u8fdb\u884c\u5b66\u4e60\u3002", "conclusion": "\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5404\u5411\u5f02\u6027\u524d\u5411\u566a\u58f0\u4e3a\u5728\u6269\u6563\u6982\u7387\u6a21\u578b\u4e2d\u5b9a\u5236\u5f52\u7eb3\u504f\u7f6e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u539f\u5219\u7684\u673a\u5236\u3002"}}
{"id": "2510.10325", "categories": ["cs.MA", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10325", "abs": "https://arxiv.org/abs/2510.10325", "authors": ["Walid Abdela"], "title": "KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments", "comment": null, "summary": "The seamless integration of physical and digital environments in\nCyber-Physical Systems(CPS), particularly within Industry 4.0, presents\nsignificant challenges stemming from system heterogeneity and complexity.\nTraditional approaches often rely on rigid, data-centric solutions like\nco-simulation frameworks or brittle point-to-point middleware bridges, which\nlack the semantic richness and flexibility required for intelligent, autonomous\ncoordination. This report introduces the Knowledge Graph-Enhanced Multi-Agent\nInfrastructure(KG-MAS), as resolution in addressing such limitations. KG-MAS\nleverages a centralized Knowledge Graph (KG) as a dynamic, shared world model,\nproviding a common semantic foundation for a Multi-Agent System(MAS).\nAutonomous agents, representing both physical and digital components, query\nthis KG for decision-making and update it with real-time state information. The\ninfrastructure features a model-driven architecture which facilitates the\nautomatic generation of agents from semantic descriptions, thereby simplifying\nsystem extension and maintenance. By abstracting away underlying communication\nprotocols and providing a unified, intelligent coordination mechanism, KG-MAS\noffers a robust, scalable, and flexible solution for coupling heterogeneous\nphysical and digital robotic environments.", "AI": {"tldr": "KG-MAS\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u57fa\u7840\u8bbe\u65bd\uff0c\u901a\u8fc7\u96c6\u4e2d\u5f0f\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u5171\u4eab\u4e16\u754c\u6a21\u578b\uff0c\u89e3\u51b3\u5de5\u4e1a4.0\u4e2d\u7269\u7406\u4e0e\u6570\u5b57\u73af\u5883\u96c6\u6210\u7684\u5f02\u6784\u6027\u548c\u590d\u6742\u6027\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6570\u636e\u4e2d\u5fc3\u7684\u89e3\u51b3\u65b9\u6848\u5982\u534f\u540c\u4eff\u771f\u6846\u67b6\u6216\u70b9\u5bf9\u70b9\u4e2d\u95f4\u4ef6\u6865\u63a5\u7f3a\u4e4f\u8bed\u4e49\u4e30\u5bcc\u6027\u548c\u7075\u6d3b\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u667a\u80fd\u81ea\u4e3b\u534f\u8c03\u7684\u9700\u6c42\u3002", "method": "\u5229\u7528\u96c6\u4e2d\u5f0f\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u52a8\u6001\u5171\u4eab\u4e16\u754c\u6a21\u578b\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u901a\u7528\u8bed\u4e49\u57fa\u7840\u3002\u81ea\u4e3b\u667a\u80fd\u4f53\u67e5\u8be2\u77e5\u8bc6\u56fe\u8c31\u8fdb\u884c\u51b3\u7b56\uff0c\u5e76\u7528\u5b9e\u65f6\u72b6\u6001\u4fe1\u606f\u66f4\u65b0\u56fe\u8c31\u3002\u91c7\u7528\u6a21\u578b\u9a71\u52a8\u67b6\u6784\uff0c\u4ece\u8bed\u4e49\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u667a\u80fd\u4f53\u3002", "result": "\u901a\u8fc7\u62bd\u8c61\u5e95\u5c42\u901a\u4fe1\u534f\u8bae\u5e76\u63d0\u4f9b\u7edf\u4e00\u7684\u667a\u80fd\u534f\u8c03\u673a\u5236\uff0cKG-MAS\u4e3a\u5f02\u6784\u7269\u7406\u548c\u6570\u5b57\u673a\u5668\u4eba\u73af\u5883\u63d0\u4f9b\u4e86\u7a33\u5065\u3001\u53ef\u6269\u5c55\u548c\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "KG-MAS\u57fa\u7840\u8bbe\u65bd\u7b80\u5316\u4e86\u7cfb\u7edf\u6269\u5c55\u548c\u7ef4\u62a4\uff0c\u4e3a\u5de5\u4e1a4.0\u73af\u5883\u4e2d\u7684\u7269\u7406-\u6570\u5b57\u96c6\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6280\u672f\u65b9\u6848\u3002"}}
{"id": "2510.10040", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.10040", "abs": "https://arxiv.org/abs/2510.10040", "authors": ["Shafi Ullah Khan", "Michel Kulhandjian", "Debashri Roy"], "title": "Pushing the Boundaries in CBRS Band: Robust Radar Detection within High 5G Interference", "comment": null, "summary": "Spectrum sharing is a critical strategy for meeting escalating user demands\nvia commercial wireless services, yet its effective regulation and\ntechnological enablement, particularly concerning coexistence with incumbent\nsystems, remain significant challenges. Federal organizations have established\nregulatory frameworks to manage shared commercial use alongside\nmission-critical operations, such as military communications. This paper\ninvestigates the potential of machine learning (ML)-based approaches to enhance\nspectrum sharing capabilities within the Citizens Broadband Radio Service\n(CBRS) band, specifically focusing on the coexistence of commercial signals\n(e.g., 5G) and military radar systems. We demonstrate that ML techniques can\npotentially extend the Federal Communications Commission (FCC)-recommended\nsignal-to-interference-plus-noise ratio (SINR) boundaries by improving radar\ndetection and waveform identification in high-interference environments.\nThrough rigorous evaluation using both synthetic and real-world signals, our\nfindings indicate that proposed ML models, utilizing In-phase/Quadrature (IQ)\ndata and spectrograms, can achieve the FCC-recommended $99\\%$ radar detection\naccuracy even when subjected to high interference from 5G signals upto -5dB\nSINR, exceeding the required limits of $20$ SINR. Our experimental studies\ndistinguish this work from the state-of-the-art by significantly extending the\nSINR limit for $99\\%$ radar detection accuracy from approximately $12$ dB down\nto $-5$ dB. Subsequent to detection, we further apply ML to analyze and\nidentify radar waveforms. The proposed models also demonstrate the capability\nto classify six distinct radar waveform types with $93\\%$ accuracy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728CBRS\u9891\u6bb5\u9891\u8c31\u5171\u4eab\u4e2d\u7684\u5e94\u7528\uff0c\u5c55\u793a\u4e86ML\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u5347\u96f7\u8fbe\u68c0\u6d4b\u548c\u6ce2\u5f62\u8bc6\u522b\u80fd\u529b\uff0c\u5728\u5f3a5G\u4fe1\u53f7\u5e72\u6270\u4e0b\u4ecd\u80fd\u8fbe\u5230FCC\u8981\u6c42\u768499%\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5c06SINR\u8fb9\u754c\u4ece12dB\u6269\u5c55\u5230-5dB\u3002", "motivation": "\u9891\u8c31\u5171\u4eab\u662f\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u7684\u5173\u952e\u7b56\u7565\uff0c\u4f46\u5546\u4e1a\u65e0\u7ebf\u670d\u52a1\u4e0e\u519b\u4e8b\u96f7\u8fbe\u7b49\u5173\u952e\u7cfb\u7edf\u7684\u5171\u5b58\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u8054\u90a6\u7ec4\u7ec7\u5df2\u5efa\u7acb\u76d1\u7ba1\u6846\u67b6\u6765\u7ba1\u7406\u8fd9\u79cd\u5171\u4eab\u4f7f\u7528\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5982\u4f55\u589e\u5f3aCBRS\u9891\u6bb5\u7684\u9891\u8c31\u5171\u4eab\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8eIQ\u6570\u636e\u548c\u9891\u8c31\u56fe\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5728\u5305\u542b\u5408\u6210\u548c\u771f\u5b9e\u4fe1\u53f7\u7684\u9ad8\u5e72\u6270\u73af\u5883\u4e2d\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\uff0c\u91cd\u70b9\u5173\u6ce8\u96f7\u8fbe\u68c0\u6d4b\u548c\u6ce2\u5f62\u8bc6\u522b\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684ML\u6a21\u578b\u5373\u4f7f\u5728-5dB SINR\u7684\u9ad8\u5e72\u6270\u73af\u5883\u4e0b\uff0c\u4e5f\u80fd\u8fbe\u5230FCC\u8981\u6c42\u768499%\u96f7\u8fbe\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u663e\u8457\u8d85\u8d8a\u4e8620dB SINR\u7684\u8981\u6c42\u9650\u5236\u3002\u6b64\u5916\uff0c\u6a21\u578b\u8fd8\u80fd\u4ee593%\u7684\u51c6\u786e\u7387\u5206\u7c7b\u516d\u79cd\u4e0d\u540c\u7684\u96f7\u8fbe\u6ce2\u5f62\u7c7b\u578b\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6280\u672f\u80fd\u591f\u663e\u8457\u6269\u5c55FCC\u63a8\u8350\u7684SINR\u8fb9\u754c\uff0c\u5728\u5f3a\u5e72\u6270\u73af\u5883\u4e0b\u5b9e\u73b0\u53ef\u9760\u7684\u96f7\u8fbe\u68c0\u6d4b\u548c\u6ce2\u5f62\u8bc6\u522b\uff0c\u4e3a\u5546\u4e1a\u65e0\u7ebf\u670d\u52a1\u4e0e\u519b\u4e8b\u7cfb\u7edf\u7684\u6709\u6548\u5171\u5b58\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2510.09662", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.09662", "abs": "https://arxiv.org/abs/2510.09662", "authors": ["Ali Jaberi", "Amin Sadeghi", "Runze Zhang", "Zhaoyang Zhao", "Qiuyu Shi", "Robert Black", "Zoya Sadighi", "Jason Hattrick-Simpers"], "title": "Assessment of different loss functions for fitting equivalent circuit models to electrochemical impedance spectroscopy data", "comment": null, "summary": "Electrochemical impedance spectroscopy (EIS) data is typically modeled using\nan equivalent circuit model (ECM), with parameters obtained by minimizing a\nloss function via nonlinear least squares fitting. This paper introduces two\nnew loss functions, log-B and log-BW, derived from the Bode representation of\nEIS. Using a large dataset of generated EIS data, the performance of proposed\nloss functions was evaluated alongside existing ones in terms of R2 scores,\nchi-squared, computational efficiency, and the mean absolute percentage error\n(MAPE) between the predicted component values and the original values.\nStatistical comparisons revealed that the choice of loss function impacts\nconvergence, computational efficiency, quality of fit, and MAPE. Our analysis\nshowed that X2 loss function (squared sum of residuals with proportional\nweighting) achieved the highest performance across multiple quality of fit\nmetrics, making it the preferred choice when the quality of fit is the primary\ngoal. On the other hand, log-B offered a slightly lower quality of fit while\nbeing approximately 1.4 times faster and producing lower MAPE for most circuit\ncomponents, making log-B as a strong alternative. This is a critical factor for\nlarge-scale least squares fitting in data-driven applications, such as training\nmachine learning models on extensive datasets or iterations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u57fa\u4e8eBode\u56fe\u7684\u7535\u5316\u5b66\u963b\u6297\u8c31\u635f\u5931\u51fd\u6570log-B\u548clog-BW\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728\u62df\u5408\u6027\u80fd\u3001\u8ba1\u7b97\u6548\u7387\u548c\u53c2\u6570\u8bef\u5dee\u65b9\u9762\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0X2\u635f\u5931\u51fd\u6570\u5728\u62df\u5408\u8d28\u91cf\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800clog-B\u635f\u5931\u51fd\u6570\u5728\u4fdd\u6301\u8f83\u597d\u62df\u5408\u8d28\u91cf\u7684\u540c\u65f6\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\uff0c\u9002\u5408\u5927\u89c4\u6a21\u6570\u636e\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u7684\u7535\u5316\u5b66\u963b\u6297\u8c31\u6570\u636e\u901a\u5e38\u4f7f\u7528\u7b49\u6548\u7535\u8def\u6a21\u578b\u901a\u8fc7\u975e\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u62df\u5408\u6765\u5efa\u6a21\uff0c\u4f46\u73b0\u6709\u635f\u5931\u51fd\u6570\u5728\u8ba1\u7b97\u6548\u7387\u548c\u53c2\u6570\u7cbe\u5ea6\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u65b0\u7684\u635f\u5931\u51fd\u6570\u4ee5\u6539\u5584\u62df\u5408\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8eBode\u56fe\u8868\u793a\u7684\u65b0\u635f\u5931\u51fd\u6570log-B\u548clog-BW\uff0c\u4f7f\u7528\u751f\u6210\u7684\u5927\u89c4\u6a21EIS\u6570\u636e\u96c6\u8bc4\u4f30\u8fd9\u4e9b\u635f\u5931\u51fd\u6570\u4e0e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u901a\u8fc7R2\u5206\u6570\u3001\u5361\u65b9\u503c\u3001\u8ba1\u7b97\u6548\u7387\u548c\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\u7b49\u6307\u6807\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u7edf\u8ba1\u6bd4\u8f83\u663e\u793a\uff0c\u635f\u5931\u51fd\u6570\u7684\u9009\u62e9\u5f71\u54cd\u6536\u655b\u6027\u3001\u8ba1\u7b97\u6548\u7387\u3001\u62df\u5408\u8d28\u91cf\u548cMAPE\u3002X2\u635f\u5931\u51fd\u6570\u5728\u591a\u4e2a\u62df\u5408\u8d28\u91cf\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800clog-B\u635f\u5931\u51fd\u6570\u867d\u7136\u62df\u5408\u8d28\u91cf\u7565\u4f4e\uff0c\u4f46\u8ba1\u7b97\u901f\u5ea6\u5feb\u7ea61.4\u500d\uff0c\u4e14\u5bf9\u5927\u591a\u6570\u7535\u8def\u7ec4\u4ef6\u4ea7\u751f\u66f4\u4f4e\u7684MAPE\u3002", "conclusion": "\u5f53\u62df\u5408\u8d28\u91cf\u662f\u4e3b\u8981\u76ee\u6807\u65f6\uff0cX2\u635f\u5931\u51fd\u6570\u662f\u6700\u4f73\u9009\u62e9\uff1b\u800c\u5bf9\u4e8e\u5927\u89c4\u6a21\u6700\u5c0f\u4e8c\u4e58\u62df\u5408\u5e94\u7528\uff08\u5982\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff09\uff0clog-B\u635f\u5931\u51fd\u6570\u56e0\u5176\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u548c\u826f\u597d\u7684\u53c2\u6570\u7cbe\u5ea6\u800c\u6210\u4e3a\u5f3a\u6709\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.10044", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.10044", "abs": "https://arxiv.org/abs/2510.10044", "authors": ["Rahul Vanukuri", "Shafi Ullah Khan", "Talip Tolga Sar\u0131", "Gokhan Secinti", "Diego Pati\u00f1o", "Debashri Roy"], "title": "Waves of Imagination: Unconditional Spectrogram Generation using Diffusion Architectures", "comment": null, "summary": "The growing demand for effective spectrum management and interference\nmitigation in shared bands, such as the Citizens Broadband Radio Service\n(CBRS), requires robust radar detection algorithms to protect the military\ntransmission from interference due to commercial wireless transmission. These\nalgorithms, in turn, depend on large, diverse, and carefully labeled\nspectrogram datasets. However, collecting and annotating real-world radio\nfrequency (RF) spectrogram data remains a significant challenge, as radar\nsignals are rare, and their occurrences are infrequent. This challenge makes\nthe creation of balanced datasets difficult, limiting the performance and\ngeneralizability of AI models in this domain.\n  To address this critical issue, we propose a diffusion-based generative model\nfor synthesizing realistic and diverse spectrograms of five distinct categories\nthat integrate LTE, 5G, and radar signals within the CBRS band. We conduct a\nstructural and statistical fidelity analysis of the generated spectrograms\nusing widely accepted evaluation metrics Structural Similarity Index Measure\n(SSIM) and Peak Signal-to-Noise Ratio (PSNR), to quantify their divergence from\nthe training data. Furthermore, we demonstrate that pre-training on the\ngenerated spectrograms significantly improves training efficiency on a\nreal-world radar detection task by enabling $51.5\\%$ faster convergence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u5408\u6210CBRS\u9891\u6bb5\u4e2dLTE\u30015G\u548c\u96f7\u8fbe\u4fe1\u53f7\u7684\u591a\u6837\u5316\u9891\u8c31\u56fe\uff0c\u4ee5\u89e3\u51b3\u771f\u5b9e\u96f7\u8fbe\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002\u901a\u8fc7\u7ed3\u6784\u76f8\u4f3c\u6027\u548c\u5cf0\u503c\u4fe1\u566a\u6bd4\u8bc4\u4f30\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u8bc1\u660e\u9884\u8bad\u7ec3\u80fd\u663e\u8457\u63d0\u5347\u96f7\u8fbe\u68c0\u6d4b\u4efb\u52a1\u7684\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u5728CBRS\u7b49\u5171\u4eab\u9891\u6bb5\u4e2d\uff0c\u9700\u8981\u5f3a\u5927\u7684\u96f7\u8fbe\u68c0\u6d4b\u7b97\u6cd5\u6765\u4fdd\u62a4\u519b\u4e8b\u4f20\u8f93\u514d\u53d7\u5546\u4e1a\u65e0\u7ebf\u4f20\u8f93\u5e72\u6270\uff0c\u4f46\u8fd9\u4e9b\u7b97\u6cd5\u4f9d\u8d56\u5927\u91cf\u3001\u591a\u6837\u5316\u4e14\u6807\u6ce8\u826f\u597d\u7684\u9891\u8c31\u56fe\u6570\u636e\u96c6\u3002\u7531\u4e8e\u771f\u5b9e\u96f7\u8fbe\u4fe1\u53f7\u7a00\u5c11\u4e14\u51fa\u73b0\u9891\u7387\u4f4e\uff0c\u6536\u96c6\u548c\u6807\u6ce8\u771f\u5b9e\u5c04\u9891\u9891\u8c31\u56fe\u6570\u636e\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9650\u5236\u4e86AI\u6a21\u578b\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\uff0c\u7528\u4e8e\u5408\u6210CBRS\u9891\u6bb5\u4e2d\u4e94\u79cd\u4e0d\u540c\u7c7b\u522b\uff08\u5305\u542bLTE\u30015G\u548c\u96f7\u8fbe\u4fe1\u53f7\uff09\u7684\u903c\u771f\u4e14\u591a\u6837\u5316\u9891\u8c31\u56fe\u3002\u4f7f\u7528\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u6570(SSIM)\u548c\u5cf0\u503c\u4fe1\u566a\u6bd4(PSNR)\u7b49\u8bc4\u4f30\u6307\u6807\u5bf9\u751f\u6210\u9891\u8c31\u56fe\u8fdb\u884c\u7ed3\u6784\u548c\u7edf\u8ba1\u4fdd\u771f\u5ea6\u5206\u6790\u3002", "result": "\u751f\u6210\u7684\u9891\u8c31\u56fe\u5728\u7ed3\u6784\u548c\u7edf\u8ba1\u4fdd\u771f\u5ea6\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5728\u771f\u5b9e\u96f7\u8fbe\u68c0\u6d4b\u4efb\u52a1\u4e0a\uff0c\u4f7f\u7528\u751f\u6210\u7684\u9891\u8c31\u56fe\u8fdb\u884c\u9884\u8bad\u7ec3\u80fd\u591f\u5b9e\u73b051.5%\u7684\u66f4\u5feb\u6536\u655b\u901f\u5ea6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u3002", "conclusion": "\u6269\u6563\u57fa\u751f\u6210\u6a21\u578b\u80fd\u591f\u6709\u6548\u89e3\u51b3\u96f7\u8fbe\u4fe1\u53f7\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5408\u6210\u7684\u9891\u8c31\u56fe\u4e0d\u4ec5\u8d28\u91cf\u9ad8\uff0c\u8fd8\u80fd\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u96f7\u8fbe\u68c0\u6d4b\u4efb\u52a1\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u5171\u4eab\u9891\u6bb5\u4e2d\u7684\u9891\u8c31\u7ba1\u7406\u548c\u5e72\u6270\u7f13\u89e3\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6570\u636e\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09665", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09665", "abs": "https://arxiv.org/abs/2510.09665", "authors": ["Yihua Cheng", "Yuhan Liu", "Jiayi Yao", "Yuwei An", "Xiaokun Chen", "Shaoting Feng", "Yuyang Huang", "Samuel Shen", "Kuntai Du", "Junchen Jiang"], "title": "LMCache: An Efficient KV Cache Layer for Enterprise-Scale LLM Inference", "comment": null, "summary": "Today's LLM inference systems treat individual engines and queries\nindependently for simplicity, but this causes significant resource\ninefficiencies. While there are proposals to avoid redundant computation by\nreusing KV caches across queries and to increase GPU utilization by\ndisaggregating a single query to different engines, their promises cannot be\nrealized without efficiently offloading and communicating KV cache across LLM\ninference engines and queries.\n  We present LMCache, the first and so far the most efficient open-source KV\ncaching solution, which extracts and stores KV caches generated by modern LLM\nengines (vLLM and SGLang) and shares the KV caches across engines and queries.\nLMCache exposes KV caches in the LLM engine interface, effectively transforming\nLLM engines from individual token processors to a collection of engines with KV\ncache as the storage and communication medium. In particular, it supports both\ncache offloading (prefix reuse across queries) and prefill-decode\ndisaggregation (cross-engine cache transfer). LMCache's high performance and\nwide adoption stem from the following contributions: highly optimized KV cache\ndata movement with performance optimizations including batched data movement\noperations, compute and I/O pipelining; a modular KV cache connector component,\ndecoupling LMCache from the rapid evolution of inference engines; a first-class\ncontrol API, such as pinning, lookup, cleanup, movement, and compression, for\nflexible cache orchestration across GPU, CPU, storage, and network layers.\nEvaluation shows that combining LMCache with vLLM achieves up to 15x\nimprovement in throughput across diverse workloads. With a growing community,\nLMCache has seen dramatic growth in adoption by enterprise inference systems,\nwhich provides valuable lessons for future KV caching solutions. The source\ncode of LMCache is at: https://github.com/LMCache/LMCache.", "AI": {"tldr": "LMCache\u662f\u4e00\u4e2a\u9ad8\u6548\u7684KV\u7f13\u5b58\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8de8\u5f15\u64ce\u548c\u67e5\u8be2\u5171\u4eabKV\u7f13\u5b58\u6765\u89e3\u51b3LLM\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u8d44\u6e90\u4f4e\u6548\u95ee\u9898\uff0c\u652f\u6301\u7f13\u5b58\u5378\u8f7d\u548c\u9884\u586b\u5145-\u89e3\u7801\u5206\u79bb\uff0c\u7ed3\u5408vLLM\u53ef\u5b9e\u73b0\u9ad8\u8fbe15\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u5f53\u524dLLM\u63a8\u7406\u7cfb\u7edf\u5c06\u5355\u4e2a\u5f15\u64ce\u548c\u67e5\u8be2\u72ec\u7acb\u5904\u7406\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u8d44\u6e90\u4f4e\u6548\u3002\u867d\u7136\u5df2\u6709\u907f\u514d\u5197\u4f59\u8ba1\u7b97\u548c\u63d0\u5347GPU\u5229\u7528\u7387\u7684\u63d0\u6848\uff0c\u4f46\u7f3a\u4e4f\u9ad8\u6548\u7684KV\u7f13\u5b58\u5378\u8f7d\u548c\u901a\u4fe1\u673a\u5236\u3002", "method": "LMCache\u63d0\u53d6\u5e76\u5b58\u50a8\u73b0\u4ee3LLM\u5f15\u64ce\u751f\u6210\u7684KV\u7f13\u5b58\uff0c\u5728\u5f15\u64ce\u548c\u67e5\u8be2\u95f4\u5171\u4eab\u3002\u91c7\u7528\u9ad8\u5ea6\u4f18\u5316\u7684KV\u7f13\u5b58\u6570\u636e\u79fb\u52a8\uff08\u6279\u91cf\u64cd\u4f5c\u3001\u8ba1\u7b97\u548cI/O\u6d41\u6c34\u7ebf\uff09\u3001\u6a21\u5757\u5316KV\u7f13\u5b58\u8fde\u63a5\u5668\u7ec4\u4ef6\u4ee5\u53ca\u4e00\u6d41\u63a7\u5236API\uff08\u56fa\u5b9a\u3001\u67e5\u627e\u3001\u6e05\u7406\u3001\u79fb\u52a8\u548c\u538b\u7f29\uff09\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cLMCache\u4e0evLLM\u7ed3\u5408\u53ef\u5728\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u9ad8\u8fbe15\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5e76\u5728\u4f01\u4e1a\u63a8\u7406\u7cfb\u7edf\u4e2d\u5f97\u5230\u5e7f\u6cdb\u91c7\u7528\u3002", "conclusion": "LMCache\u662f\u9996\u4e2a\u4e14\u6700\u9ad8\u6548\u7684\u5f00\u6e90KV\u7f13\u5b58\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u5c06LLM\u5f15\u64ce\u4ece\u72ec\u7acb\u4ee4\u724c\u5904\u7406\u5668\u8f6c\u53d8\u4e3a\u4ee5KV\u7f13\u5b58\u4e3a\u5b58\u50a8\u548c\u901a\u4fe1\u5a92\u4ecb\u7684\u5f15\u64ce\u96c6\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002"}}
{"id": "2510.10943", "categories": ["cs.MA", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.10943", "abs": "https://arxiv.org/abs/2510.10943", "authors": ["Thi-Nhung Nguyen", "Linhao Luo", "Thuy-Trang Vu", "Dinh Phung"], "title": "The Social Cost of Intelligence: Emergence, Propagation, and Amplification of Stereotypical Bias in Multi-Agent Systems", "comment": "15 pages, 19 figures, Preprint. Under review", "summary": "Bias in large language models (LLMs) remains a persistent challenge,\nmanifesting in stereotyping and unfair treatment across social groups. While\nprior research has primarily focused on individual models, the rise of\nmulti-agent systems (MAS), where multiple LLMs collaborate and communicate,\nintroduces new and largely unexplored dynamics in bias emergence and\npropagation. In this work, we present a comprehensive study of stereotypical\nbias in MAS, examining how internal specialization, underlying LLMs and\ninter-agent communication protocols influence bias robustness, propagation, and\namplification. We simulate social contexts where agents represent different\nsocial groups and evaluate system behavior under various interaction and\nadversarial scenarios. Experiments on three bias benchmarks reveal that MAS are\ngenerally less robust than single-agent systems, with bias often emerging early\nthrough in-group favoritism. However, cooperative and debate-based\ncommunication can mitigate bias amplification, while more robust underlying\nLLMs improve overall system stability. Our findings highlight critical factors\nshaping fairness and resilience in multi-agent LLM systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u53d1\u73b0\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u6bd4\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u66f4\u5bb9\u6613\u4ea7\u751f\u504f\u89c1\uff0c\u7279\u522b\u662f\u5728\u65e9\u671f\u9636\u6bb5\u901a\u8fc7\u5185\u7fa4\u4f53\u504f\u8892\u8868\u73b0\u51fa\u6765\u3002\u7136\u800c\uff0c\u5408\u4f5c\u548c\u57fa\u4e8e\u8fa9\u8bba\u7684\u901a\u4fe1\u53ef\u4ee5\u51cf\u8f7b\u504f\u89c1\u653e\u5927\uff0c\u800c\u66f4\u7a33\u5065\u7684\u57fa\u7840LLM\u80fd\u63d0\u9ad8\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "motivation": "\u968f\u7740\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5174\u8d77\uff0c\u591a\u4e2aLLM\u4e4b\u95f4\u7684\u534f\u4f5c\u548c\u901a\u4fe1\u5f15\u5165\u4e86\u504f\u89c1\u4ea7\u751f\u548c\u4f20\u64ad\u7684\u65b0\u52a8\u6001\uff0c\u8fd9\u4e9b\u52a8\u6001\u5728\u4e4b\u524d\u7684\u7814\u7a76\u4e2d\u4e3b\u8981\u5173\u6ce8\u5355\u4e2a\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u5168\u9762\u7814\u7a76\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u523b\u677f\u5370\u8c61\u504f\u89c1\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u793e\u4ea4\u60c5\u5883\uff0c\u8ba9\u667a\u80fd\u4f53\u4ee3\u8868\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\uff0c\u5728\u5404\u79cd\u4ea4\u4e92\u548c\u5bf9\u6297\u573a\u666f\u4e0b\u8bc4\u4f30\u7cfb\u7edf\u884c\u4e3a\uff0c\u5e76\u5728\u4e09\u4e2a\u504f\u89c1\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u6bd4\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u66f4\u4e0d\u7a33\u5065\uff0c\u504f\u89c1\u5f80\u5f80\u901a\u8fc7\u5185\u7fa4\u4f53\u504f\u8892\u65e9\u671f\u51fa\u73b0\u3002\u5408\u4f5c\u548c\u57fa\u4e8e\u8fa9\u8bba\u7684\u901a\u4fe1\u53ef\u4ee5\u51cf\u8f7b\u504f\u89c1\u653e\u5927\uff0c\u800c\u66f4\u7a33\u5065\u7684\u57fa\u7840LLM\u80fd\u63d0\u9ad8\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5f71\u54cd\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u516c\u5e73\u6027\u548c\u97e7\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e3a\u6784\u5efa\u66f4\u516c\u5e73\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2510.09666", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09666", "abs": "https://arxiv.org/abs/2510.09666", "authors": ["Aditya Chakravarty"], "title": "Spatial Uncertainty Quantification in Wildfire Forecasting for Climate-Resilient Emergency Planning", "comment": null, "summary": "Climate change is intensifying wildfire risks globally, making reliable\nforecasting critical for adaptation strategies. While machine learning shows\npromise for wildfire prediction from Earth observation data, current approaches\nlack uncertainty quantification essential for risk-aware decision making. We\npresent the first systematic analysis of spatial uncertainty in wildfire spread\nforecasting using multimodal Earth observation inputs. We demonstrate that\npredictive uncertainty exhibits coherent spatial structure concentrated near\nfire perimeters. Our novel distance metric reveals high-uncertainty regions\nform consistent 20-60 meter buffer zones around predicted firelines - directly\napplicable for emergency planning. Feature attribution identifies vegetation\nhealth and fire activity as primary uncertainty drivers. This work enables more\nrobust wildfire management systems supporting communities adapting to\nincreasing fire risk under climate change.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u5730\u7403\u89c2\u6d4b\u6570\u636e\u7684\u91ce\u706b\u8513\u5ef6\u9884\u6d4b\u7a7a\u95f4\u4e0d\u786e\u5b9a\u6027\u7cfb\u7edf\u5206\u6790\uff0c\u53d1\u73b0\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u5728\u706b\u7ebf\u5468\u8fb9\u5f62\u621020-60\u7c73\u7684\u7f13\u51b2\u533a\uff0c\u4e3a\u5e94\u6025\u89c4\u5212\u63d0\u4f9b\u76f4\u63a5\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u6c14\u5019\u53d8\u5316\u52a0\u5267\u4e86\u5168\u7403\u91ce\u706b\u98ce\u9669\uff0c\u9700\u8981\u53ef\u9760\u7684\u9884\u6d4b\u6765\u5236\u5b9a\u9002\u5e94\u7b56\u7565\u3002\u5f53\u524d\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u91ce\u706b\u9884\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u8fd9\u5bf9\u4e8e\u98ce\u9669\u611f\u77e5\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u5730\u7403\u89c2\u6d4b\u6570\u636e\uff0c\u7cfb\u7edf\u5206\u6790\u91ce\u706b\u8513\u5ef6\u9884\u6d4b\u4e2d\u7684\u7a7a\u95f4\u4e0d\u786e\u5b9a\u6027\uff0c\u5f00\u53d1\u65b0\u7684\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\u8bc6\u522b\u9ad8\u4e0d\u786e\u5b9a\u6027\u533a\u57df\u3002", "result": "\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u8868\u73b0\u51fa\u8fde\u8d2f\u7684\u7a7a\u95f4\u7ed3\u6784\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u706b\u7ebf\u5468\u8fb9\uff0c\u9ad8\u4e0d\u786e\u5b9a\u6027\u533a\u57df\u5728\u9884\u6d4b\u706b\u7ebf\u5468\u56f4\u5f62\u6210\u4e00\u81f4\u768420-60\u7c73\u7f13\u51b2\u533a\u3002\u7279\u5f81\u5f52\u56e0\u8bc6\u522b\u690d\u88ab\u5065\u5eb7\u548c\u706b\u707e\u6d3b\u52a8\u662f\u4e3b\u8981\u7684\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u56e0\u7d20\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u80fd\u591f\u652f\u6301\u66f4\u7a33\u5065\u7684\u91ce\u706b\u7ba1\u7406\u7cfb\u7edf\uff0c\u5e2e\u52a9\u793e\u533a\u5728\u6c14\u5019\u53d8\u5316\u80cc\u666f\u4e0b\u9002\u5e94\u65e5\u76ca\u589e\u52a0\u7684\u706b\u707e\u98ce\u9669\uff0c\u4e3a\u5e94\u6025\u89c4\u5212\u63d0\u4f9b\u76f4\u63a5\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.11004", "categories": ["cs.MA", "cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11004", "abs": "https://arxiv.org/abs/2510.11004", "authors": ["Haoran Liang", "Yufa Zhou", "Mohammad Talebi Kalaleh", "Qipei Mei"], "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "comment": "Code: https://github.com/DelosLiang/masse", "summary": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural\nEngineering, effectively integrating large language model (LLM)-based agents\nwith real-world engineering workflows. Structural engineering is a fundamental\nyet traditionally stagnant domain, with core workflows remaining largely\nunchanged for decades despite its substantial economic impact and global market\nsize. Recent advancements in LLMs have significantly enhanced their ability to\nperform complex reasoning, long-horizon planning, and precise tool utilization\n-- capabilities well aligned with structural engineering tasks such as\ninterpreting design codes, executing load calculations, and verifying\nstructural capacities. We present a proof-of-concept showing that most\nreal-world structural engineering workflows can be fully automated through a\ntraining-free LLM-based multi-agent system. MASSE enables immediate deployment\nin professional environments, and our comprehensive validation on real-world\ncase studies demonstrates that it can reduce expert workload from approximately\ntwo hours to mere minutes, while enhancing both reliability and accuracy in\npractical engineering scenarios.", "AI": {"tldr": "MASSE\u662f\u9996\u4e2a\u7528\u4e8e\u7ed3\u6784\u5de5\u7a0b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5c06\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u4e0e\u73b0\u5b9e\u5de5\u7a0b\u5de5\u4f5c\u6d41\u96c6\u6210\uff0c\u80fd\u591f\u5c06\u4e13\u5bb6\u5de5\u4f5c\u91cf\u4ece\u7ea62\u5c0f\u65f6\u51cf\u5c11\u5230\u51e0\u5206\u949f\uff0c\u540c\u65f6\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u7ed3\u6784\u5de5\u7a0b\u662f\u4e00\u4e2a\u57fa\u7840\u4f46\u4f20\u7edf\u4e0a\u505c\u6ede\u7684\u9886\u57df\uff0c\u6838\u5fc3\u5de5\u4f5c\u6d41\u51e0\u5341\u5e74\u6765\u57fa\u672c\u672a\u53d8\uff0c\u5c3d\u7ba1\u5176\u5177\u6709\u91cd\u5927\u7ecf\u6d4e\u5f71\u54cd\u548c\u5168\u7403\u5e02\u573a\u89c4\u6a21\u3002\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u3001\u957f\u671f\u89c4\u5212\u548c\u7cbe\u786e\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u7684\u8fdb\u6b65\u4e0e\u7ed3\u6784\u5de5\u7a0b\u4efb\u52a1\uff08\u5982\u89e3\u91ca\u8bbe\u8ba1\u89c4\u8303\u3001\u6267\u884c\u8377\u8f7d\u8ba1\u7b97\u548c\u9a8c\u8bc1\u7ed3\u6784\u80fd\u529b\uff09\u9ad8\u5ea6\u5951\u5408\u3002", "method": "\u5f00\u53d1\u4e86MASSE\uff0c\u8fd9\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u3001\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u5b8c\u5168\u81ea\u52a8\u5316\u5927\u591a\u6570\u73b0\u5b9e\u4e16\u754c\u7684\u7ed3\u6784\u5de5\u7a0b\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u771f\u5b9e\u6848\u4f8b\u7814\u7a76\u4e2d\u7684\u5168\u9762\u9a8c\u8bc1\u8868\u660e\uff0cMASSE\u53ef\u4ee5\u5c06\u4e13\u5bb6\u5de5\u4f5c\u91cf\u4ece\u7ea62\u5c0f\u65f6\u51cf\u5c11\u5230\u51e0\u5206\u949f\uff0c\u540c\u65f6\u5728\u5b9e\u8df5\u5de5\u7a0b\u573a\u666f\u4e2d\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "MASSE\u8bc1\u660e\u4e86\u5927\u591a\u6570\u73b0\u5b9e\u4e16\u754c\u7684\u7ed3\u6784\u5de5\u7a0b\u5de5\u4f5c\u6d41\u53ef\u4ee5\u901a\u8fc7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b8c\u5168\u81ea\u52a8\u5316\uff0c\u5e76\u80fd\u591f\u5728\u4e13\u4e1a\u73af\u5883\u4e2d\u7acb\u5373\u90e8\u7f72\u3002"}}
{"id": "2510.11108", "categories": ["cs.MA", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.11108", "abs": "https://arxiv.org/abs/2510.11108", "authors": ["Xinfeng Li", "Dong Huang", "Jie Li", "Hongyi Cai", "Zhenhong Zhou", "Wei Dong", "XiaoFeng Wang", "Yang Liu"], "title": "A Vision for Access Control in LLM-based Agent Systems", "comment": "10 pages, 1 figure", "summary": "The autonomy and contextual complexity of LLM-based agents render traditional\naccess control (AC) mechanisms insufficient. Static, rule-based systems\ndesigned for predictable environments are fundamentally ill-equipped to manage\nthe dynamic information flows inherent in agentic interactions. This position\npaper argues for a paradigm shift from binary access control to a more\nsophisticated model of information governance, positing that the core challenge\nis not merely about permission, but about governing the flow of information. We\nintroduce Agent Access Control (AAC), a novel framework that reframes AC as a\ndynamic, context-aware process of information flow governance. AAC operates on\ntwo core modules: (1) multi-dimensional contextual evaluation, which assesses\nnot just identity but also relationships, scenarios, and norms; and (2)\nadaptive response formulation, which moves beyond simple allow/deny decisions\nto shape information through redaction, summarization, and paraphrasing. This\nvision, powered by a dedicated AC reasoning engine, aims to bridge the gap\nbetween human-like nuanced judgment and scalable Al safety, proposing a new\nconceptual lens for future research in trustworthy agent design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAgent Access Control (AAC)\u6846\u67b6\uff0c\u5c06\u4f20\u7edf\u8bbf\u95ee\u63a7\u5236\u91cd\u65b0\u5b9a\u4e49\u4e3a\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4fe1\u606f\u6d41\u6cbb\u7406\u8fc7\u7a0b\uff0c\u4ee5\u89e3\u51b3LLM\u667a\u80fd\u4f53\u81ea\u4e3b\u6027\u548c\u4e0a\u4e0b\u6587\u590d\u6742\u6027\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u9759\u6001\u8bbf\u95ee\u63a7\u5236\u673a\u5236\u65e0\u6cd5\u6709\u6548\u7ba1\u7406LLM\u667a\u80fd\u4f53\u52a8\u6001\u4fe1\u606f\u6d41\uff0c\u9700\u8981\u4ece\u7b80\u5355\u7684\u6743\u9650\u63a7\u5236\u8f6c\u5411\u66f4\u590d\u6742\u7684\u4fe1\u606f\u6cbb\u7406\u8303\u5f0f\u3002", "method": "AAC\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u591a\u7ef4\u4e0a\u4e0b\u6587\u8bc4\u4f30\uff08\u8bc4\u4f30\u8eab\u4efd\u3001\u5173\u7cfb\u3001\u573a\u666f\u548c\u89c4\u8303\uff09\u548c\u81ea\u9002\u5e94\u54cd\u5e94\u5236\u5b9a\uff08\u8d85\u8d8a\u7b80\u5355\u7684\u5141\u8bb8/\u62d2\u7edd\u51b3\u7b56\uff0c\u901a\u8fc7\u7f16\u8f91\u3001\u6458\u8981\u548c\u6539\u5199\u6765\u5851\u9020\u4fe1\u606f\uff09\u3002", "result": "\u63d0\u51fa\u4e86\u7531\u4e13\u7528AC\u63a8\u7406\u5f15\u64ce\u9a71\u52a8\u7684AAC\u613f\u666f\uff0c\u65e8\u5728\u5f25\u5408\u7c7b\u4eba\u7ec6\u5fae\u5224\u65ad\u4e0e\u53ef\u6269\u5c55AI\u5b89\u5168\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "AAC\u4e3a\u53ef\u4fe1\u667a\u80fd\u4f53\u8bbe\u8ba1\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u6982\u5ff5\u89c6\u89d2\uff0c\u5c06\u8bbf\u95ee\u63a7\u5236\u91cd\u65b0\u5b9a\u4e49\u4e3a\u52a8\u6001\u4fe1\u606f\u6d41\u6cbb\u7406\u8fc7\u7a0b\u3002"}}
{"id": "2510.09669", "categories": ["cs.LG", "cs.CY", "cs.SI", "physics.soc-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09669", "abs": "https://arxiv.org/abs/2510.09669", "authors": ["Jacopo Lenti", "Lorenzo Costantini", "Ariadna Fosch", "Anna Monticelli", "David Scala", "Marco Pangallo"], "title": "Population synthesis with geographic coordinates", "comment": null, "summary": "It is increasingly important to generate synthetic populations with explicit\ncoordinates rather than coarse geographic areas, yet no established methods\nexist to achieve this. One reason is that latitude and longitude differ from\nother continuous variables, exhibiting large empty spaces and highly uneven\ndensities. To address this, we propose a population synthesis algorithm that\nfirst maps spatial coordinates into a more regular latent space using\nNormalizing Flows (NF), and then combines them with other features in a\nVariational Autoencoder (VAE) to generate synthetic populations. This approach\nalso learns the joint distribution between spatial and non-spatial features,\nexploiting spatial autocorrelations. We demonstrate the method by generating\nsynthetic homes with the same statistical properties of real homes in 121\ndatasets, corresponding to diverse geographies. We further propose an\nevaluation framework that measures both spatial accuracy and practical utility,\nwhile ensuring privacy preservation. Our results show that the NF+VAE\narchitecture outperforms popular benchmarks, including copula-based methods and\nuniform allocation within geographic areas. The ability to generate geolocated\nsynthetic populations at fine spatial resolution opens the door to applications\nrequiring detailed geography, from household responses to floods, to epidemic\nspread, evacuation planning, and transport modeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6807\u51c6\u5316\u6d41\u548c\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u5177\u6709\u7cbe\u786e\u5750\u6807\u7684\u5408\u6210\u4eba\u53e3\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u7a7a\u95f4\u5750\u6807\u5206\u5e03\u4e0d\u5747\u7684\u95ee\u9898\uff0c\u5e76\u5728121\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u751f\u6210\u5177\u6709\u660e\u786e\u5750\u6807\u7684\u5408\u6210\u4eba\u53e3\u6570\u636e\uff0c\u800c\u7a7a\u95f4\u5750\u6807\u5177\u6709\u5927\u8303\u56f4\u7a7a\u533a\u548c\u9ad8\u5ea6\u4e0d\u5747\u5300\u5bc6\u5ea6\u7684\u7279\u70b9\uff0c\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u5904\u7406\u3002", "method": "\u4f7f\u7528\u6807\u51c6\u5316\u6d41\u5c06\u7a7a\u95f4\u5750\u6807\u6620\u5c04\u5230\u66f4\u89c4\u5219\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u7136\u540e\u4e0e\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7ed3\u5408\u751f\u6210\u5408\u6210\u4eba\u53e3\u6570\u636e\uff0c\u540c\u65f6\u5b66\u4e60\u7a7a\u95f4\u548c\u975e\u7a7a\u95f4\u7279\u5f81\u7684\u8054\u5408\u5206\u5e03\u3002", "result": "\u5728121\u4e2a\u4e0d\u540c\u5730\u7406\u533a\u57df\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cNF+VAE\u67b6\u6784\u5728\u7a7a\u95f4\u51c6\u786e\u6027\u548c\u5b9e\u9645\u6548\u7528\u65b9\u9762\u4f18\u4e8e\u57fa\u4e8ecopula\u7684\u65b9\u6cd5\u548c\u5730\u7406\u533a\u57df\u5185\u5747\u5300\u5206\u914d\u7b49\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u7ec6\u7c92\u5ea6\u7a7a\u95f4\u5206\u8fa8\u7387\u7684\u5408\u6210\u4eba\u53e3\u6570\u636e\uff0c\u4e3a\u6d2a\u6c34\u54cd\u5e94\u3001\u6d41\u884c\u75c5\u4f20\u64ad\u3001\u758f\u6563\u89c4\u5212\u548c\u4ea4\u901a\u5efa\u6a21\u7b49\u9700\u8981\u8be6\u7ec6\u5730\u7406\u4fe1\u606f\u7684\u5e94\u7528\u6253\u5f00\u4e86\u5927\u95e8\u3002"}}
{"id": "2510.11123", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.11123", "abs": "https://arxiv.org/abs/2510.11123", "authors": ["Pedro E. G\u00f3ria Silva", "Eduardo S. Lima", "Jules M. Moualeu", "Mohamed Korium", "Pedro H. J. Nardelli"], "title": "Visible Light Communication for Vehicular Networks: A Tutorial", "comment": null, "summary": "The advent of the fifth-generation technology promises to bring about more\nvertical applications and emerging services that include vehicular networks and\nintelligent transportation systems (ITSs). To achieve their vision of real-time\nand safetyapplications, vehicular networks rely on short-range to medium-range\ncommunications. One emerging technology that aims to provide reliability and\nhigh-data rate in short-range communications is the visible light\ncommunications (VLC). Due to its remarkable advantages, some studies have\nrecently investigated the integration of VLC in vehicular networks and ITSs.\nDespite their attractive features, such networks also face several\nimplementation issues. This paper provides an extended tutorial on the\nimplementation of VLC-based vehicular networks. To begin with, we present the\nimplementation characteristics of these systems and discuss some related\nissues. The underlying system considers a general structure with transmitters,\nchannels, and receivers based on photodetectors and cameras, as well as\nstandardization efforts and types of topologies. In addition, we discuss the\nimpact of the sun and artificial light sources, flickering, dimming, throughput\nenhancement, uplink security, and mobility on practical implementation.\nFinally, we highlight some key challenges and potential solutions and provide\nsome directions for future research investigations that could constitute an\nadvancement toward the development of commercial VLC-based vehicular systems.", "AI": {"tldr": "\u672c\u6587\u662f\u5173\u4e8e\u57fa\u4e8e\u53ef\u89c1\u5149\u901a\u4fe1(VLC)\u7684\u8f66\u8054\u7f51\u5b9e\u73b0\u7684\u6269\u5c55\u6559\u7a0b\uff0c\u8ba8\u8bba\u4e86VLC\u5728\u8f66\u8054\u7f51\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\u3001\u5b9e\u73b0\u7279\u6027\u3001\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7b2c\u4e94\u4ee3\u6280\u672f\u5e26\u6765\u4e86\u66f4\u591a\u5782\u76f4\u5e94\u7528\u548c\u65b0\u5174\u670d\u52a1\uff0c\u5305\u62ec\u8f66\u8054\u7f51\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u3002\u4e3a\u5b9e\u73b0\u5b9e\u65f6\u548c\u5b89\u5168\u5e94\u7528\uff0c\u8f66\u8054\u7f51\u4f9d\u8d56\u77ed\u8ddd\u79bb\u5230\u4e2d\u8ddd\u79bb\u901a\u4fe1\uff0c\u800cVLC\u6280\u672f\u56e0\u5176\u5728\u77ed\u8ddd\u79bb\u901a\u4fe1\u4e2d\u63d0\u4f9b\u53ef\u9760\u6027\u548c\u9ad8\u6570\u636e\u7387\u7684\u4f18\u52bf\uff0c\u88ab\u8003\u8651\u96c6\u6210\u5230\u8f66\u8054\u7f51\u4e2d\u3002", "method": "\u672c\u6587\u91c7\u7528\u6559\u7a0b\u5f62\u5f0f\uff0c\u9996\u5148\u4ecb\u7ecdVLC\u8f66\u8054\u7f51\u7cfb\u7edf\u7684\u5b9e\u73b0\u7279\u6027\uff0c\u5305\u62ec\u53d1\u5c04\u5668\u3001\u4fe1\u9053\u548c\u57fa\u4e8e\u5149\u7535\u63a2\u6d4b\u5668\u53ca\u6444\u50cf\u5934\u7684\u63a5\u6536\u5668\u7684\u4e00\u822c\u7ed3\u6784\uff0c\u6807\u51c6\u5316\u52aa\u529b\u548c\u62d3\u6251\u7c7b\u578b\u3002\u7136\u540e\u8ba8\u8bba\u4e86\u592a\u9633\u548c\u4eba\u5de5\u5149\u6e90\u5f71\u54cd\u3001\u95ea\u70c1\u3001\u8c03\u5149\u3001\u541e\u5410\u91cf\u589e\u5f3a\u3001\u4e0a\u884c\u94fe\u8def\u5b89\u5168\u6027\u548c\u79fb\u52a8\u6027\u7b49\u5b9e\u9645\u5b9e\u73b0\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u5206\u6790\u53d1\u73b0\uff0c\u5c3d\u7ba1VLC\u8f66\u8054\u7f51\u5177\u6709\u5438\u5f15\u529b\uff0c\u4f46\u5728\u5b9e\u9645\u5b9e\u65bd\u4e2d\u9762\u4e34\u591a\u4e2a\u95ee\u9898\uff0c\u5305\u62ec\u73af\u5883\u5149\u6e90\u5e72\u6270\u3001\u901a\u4fe1\u7a33\u5b9a\u6027\u3001\u5b89\u5168\u6027\u548c\u79fb\u52a8\u6027\u7ba1\u7406\u7b49\u6311\u6218\u3002", "conclusion": "\u6587\u7ae0\u5f3a\u8c03\u4e86VLC\u8f66\u8054\u7f51\u5b9e\u65bd\u4e2d\u7684\u5173\u952e\u6311\u6218\u548c\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u8fd9\u4e9b\u7814\u7a76\u53ef\u80fd\u63a8\u52a8\u5546\u4e1aVLC\u8f66\u8054\u7f51\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.09676", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09676", "abs": "https://arxiv.org/abs/2510.09676", "authors": ["Shayan Mohajer Hamidi", "En-Hui Yang", "Ben Liang"], "title": "Coupled Data and Measurement Space Dynamics for Enhanced Diffusion Posterior Sampling", "comment": null, "summary": "Inverse problems, where the goal is to recover an unknown signal from noisy\nor incomplete measurements, are central to applications in medical imaging,\nremote sensing, and computational biology. Diffusion models have recently\nemerged as powerful priors for solving such problems. However, existing methods\neither rely on projection-based techniques that enforce measurement consistency\nthrough heuristic updates, or they approximate the likelihood $p(\\boldsymbol{y}\n\\mid \\boldsymbol{x})$, often resulting in artifacts and instability under\ncomplex or high-noise conditions. To address these limitations, we propose a\nnovel framework called \\emph{coupled data and measurement space diffusion\nposterior sampling} (C-DPS), which eliminates the need for constraint tuning or\nlikelihood approximation. C-DPS introduces a forward stochastic process in the\nmeasurement space $\\{\\boldsymbol{y}_t\\}$, evolving in parallel with the\ndata-space diffusion $\\{\\boldsymbol{x}_t\\}$, which enables the derivation of a\nclosed-form posterior $p(\\boldsymbol{x}_{t-1} \\mid \\boldsymbol{x}_t,\n\\boldsymbol{y}_{t-1})$. This coupling allows for accurate and recursive\nsampling based on a well-defined posterior distribution. Empirical results\ndemonstrate that C-DPS consistently outperforms existing baselines, both\nqualitatively and quantitatively, across multiple inverse problem benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8026\u5408\u6570\u636e\u4e0e\u6d4b\u91cf\u7a7a\u95f4\u6269\u6563\u540e\u9a8c\u91c7\u6837\uff08C-DPS\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u9006\u95ee\u9898\uff0c\u65e0\u9700\u7ea6\u675f\u8c03\u4f18\u6216\u4f3c\u7136\u8fd1\u4f3c\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u57fa\u4e8e\u6295\u5f71\u7684\u6280\u672f\u901a\u8fc7\u542f\u53d1\u5f0f\u66f4\u65b0\u5f3a\u5236\u6d4b\u91cf\u4e00\u81f4\u6027\uff0c\u8981\u4e48\u8fd1\u4f3c\u4f3c\u7136\u51fd\u6570\uff0c\u5bfc\u81f4\u5728\u590d\u6742\u6216\u9ad8\u566a\u58f0\u6761\u4ef6\u4e0b\u4ea7\u751f\u4f2a\u5f71\u548c\u4e0d\u7a33\u5b9a\u6027\u3002", "method": "\u5728\u6d4b\u91cf\u7a7a\u95f4\u5f15\u5165\u524d\u5411\u968f\u673a\u8fc7\u7a0b\uff0c\u4e0e\u6570\u636e\u7a7a\u95f4\u6269\u6563\u5e76\u884c\u6f14\u5316\uff0c\u4ece\u800c\u63a8\u5bfc\u51fa\u5c01\u95ed\u5f62\u5f0f\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u5b9e\u73b0\u57fa\u4e8e\u660e\u786e\u5b9a\u4e49\u540e\u9a8c\u5206\u5e03\u7684\u51c6\u786e\u9012\u5f52\u91c7\u6837\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cC-DPS\u5728\u591a\u4e2a\u9006\u95ee\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u4e0a\u90fd\u4e00\u81f4\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "C-DPS\u6846\u67b6\u901a\u8fc7\u8026\u5408\u6570\u636e\u4e0e\u6d4b\u91cf\u7a7a\u95f4\u6269\u6563\u8fc7\u7a0b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u8c03\u4f18\u7ea6\u675f\u6216\u8fd1\u4f3c\u4f3c\u7136\u7684\u7a33\u5b9a\u4e14\u51c6\u786e\u7684\u9006\u95ee\u9898\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11062", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.11062", "abs": "https://arxiv.org/abs/2510.11062", "authors": ["Yujie Zhao", "Lanxiang Hu", "Yang Wang", "Minmin Hou", "Hao Zhang", "Ke Ding", "Jishen Zhao"], "title": "Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs", "comment": null, "summary": "Multi-agent systems (MAS) and reinforcement learning (RL) are widely used to\nenhance the agentic capabilities of large language models (LLMs). MAS improves\ntask performance through role-based orchestration, while RL uses environmental\nrewards to learn stronger policies, such as GRPO-style optimization. However,\napplying on-policy RL to MAS remains underexplored and presents unique\nchallenges. Algorithmically, standard GRPO grouping assumptions break down\nbecause prompts vary by role and by turn. System-wise, the training stack must\nsupport MAS-workflow rollouts and on-policy updates for both single-policy and\nmulti-policy models.\n  We propose AT-GRPO, which includes (i) an agent- and turn-wise grouped RL\nalgorithm tailored to MAS and (ii) a training system that supports both single-\nand multi-policy regimes. Across game, planning, coding, and math tasks,\nAT-GRPO delivers substantial gains. On long-horizon planning, it increases\naccuracy from a 14.0 to 47.0 percent single-agent RL baseline to 96.0 to 99.5\npercent. It also improves reasoning performance, with average gains of 3.87 to\n7.62 percent on coding tasks and 9.0 to 17.93 percent on math. Code and\nenvironments are available at: https://github.com/pettingllms-ai/PettingLLMs.", "AI": {"tldr": "AT-GRPO\u662f\u4e00\u79cd\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u548c\u56de\u5408\u5206\u7ec4\u7b97\u6cd5\u4ee5\u53ca\u652f\u6301\u5355\u7b56\u7565\u548c\u591a\u7b56\u7565\u7684\u8bad\u7ec3\u7cfb\u7edf\uff0c\u5728\u6e38\u620f\u3001\u89c4\u5212\u3001\u7f16\u7801\u548c\u6570\u5b66\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u5f3a\u5316\u5b66\u4e60\u88ab\u5e7f\u6cdb\u7528\u4e8e\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u80fd\u529b\uff0c\u4f46\u5c06\u5728\u7ebf\u7b56\u7565\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u4e14\u9762\u4e34\u72ec\u7279\u6311\u6218\uff0c\u5305\u62ec\u7b97\u6cd5\u5c42\u9762\u6807\u51c6GRPO\u5206\u7ec4\u5047\u8bbe\u5931\u6548\u4ee5\u53ca\u7cfb\u7edf\u5c42\u9762\u9700\u8981\u652f\u6301MAS\u5de5\u4f5c\u6d41\u7a0b\u548c\u7b56\u7565\u66f4\u65b0\u3002", "method": "\u63d0\u51fa\u4e86AT-GRPO\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a(i) \u9488\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b9a\u5236\u7684\u667a\u80fd\u4f53\u548c\u56de\u5408\u5206\u7ec4\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff1b(ii) \u652f\u6301\u5355\u7b56\u7565\u548c\u591a\u7b56\u7565\u673a\u5236\u7684\u8bad\u7ec3\u7cfb\u7edf\u3002", "result": "\u5728\u957f\u671f\u89c4\u5212\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u7387\u4ece\u5355\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u768414.0-47.0%\u63d0\u5347\u523096.0-99.5%\uff1b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u7f16\u7801\u4efb\u52a1\u5e73\u5747\u63d0\u53473.87-7.62%\uff0c\u6570\u5b66\u4efb\u52a1\u5e73\u5747\u63d0\u53479.0-17.93%\u3002", "conclusion": "AT-GRPO\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4ee3\u7801\u548c\u73af\u5883\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.09684", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.09684", "abs": "https://arxiv.org/abs/2510.09684", "authors": ["Chris Engh", "P. M. Aronow"], "title": "Using LLMs to Directly Guess Conditional Expectations Can Improve Efficiency in Causal Estimation", "comment": null, "summary": "We propose a simple yet effective use of LLM-powered AI tools to improve\ncausal estimation. In double machine learning, the accuracy of causal estimates\nof the effect of a treatment on an outcome in the presence of a\nhigh-dimensional confounder depends on the performance of estimators of\nconditional expectation functions. We show that predictions made by generative\nmodels trained on historical data can be used to improve the performance of\nthese estimators relative to approaches that solely rely on adjusting for\nembeddings extracted from these models. We argue that the historical knowledge\nand reasoning capacities associated with these generative models can help\novercome curse-of-dimensionality problems in causal inference problems. We\nconsider a case study using a small dataset of online jewelry auctions, and\ndemonstrate that inclusion of LLM-generated guesses as predictors can improve\nefficiency in estimation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528LLM\u751f\u6210\u7684\u9884\u6d4b\u6765\u6539\u8fdb\u53cc\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u56e0\u679c\u4f30\u8ba1\uff0c\u901a\u8fc7\u5229\u7528\u751f\u6210\u6a21\u578b\u7684\u5386\u53f2\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u89e3\u51b3\u9ad8\u7ef4\u6df7\u6742\u53d8\u91cf\u95ee\u9898\uff0c\u5728\u5728\u7ebf\u73e0\u5b9d\u62cd\u5356\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u80fd\u63d0\u9ad8\u4f30\u8ba1\u6548\u7387\u3002", "motivation": "\u5728\u53cc\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u9ad8\u7ef4\u6df7\u6742\u53d8\u91cf\u5b58\u5728\u65f6\uff0c\u56e0\u679c\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u4f9d\u8d56\u4e8e\u6761\u4ef6\u671f\u671b\u51fd\u6570\u4f30\u8ba1\u5668\u7684\u6027\u80fd\u3002\u4f20\u7edf\u65b9\u6cd5\u4ec5\u8c03\u6574\u4ece\u751f\u6210\u6a21\u578b\u4e2d\u63d0\u53d6\u7684\u5d4c\u5165\uff0c\u6027\u80fd\u6709\u9650\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5386\u53f2\u6570\u636e\u8bad\u7ec3\u7684\u751f\u6210\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\uff0c\u5c06LLM\u751f\u6210\u7684\u731c\u6d4b\u4f5c\u4e3a\u9884\u6d4b\u53d8\u91cf\u7eb3\u5165\u4f30\u8ba1\u5668\uff0c\u76f8\u6bd4\u4ec5\u4f7f\u7528\u5d4c\u5165\u8c03\u6574\u7684\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "result": "\u5728\u5728\u7ebf\u73e0\u5b9d\u62cd\u5356\u7684\u5c0f\u578b\u6570\u636e\u96c6\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u5305\u542bLLM\u751f\u6210\u7684\u731c\u6d4b\u4f5c\u4e3a\u9884\u6d4b\u53d8\u91cf\u80fd\u591f\u63d0\u9ad8\u4f30\u8ba1\u6548\u7387\u3002", "conclusion": "LLM\u9a71\u52a8\u7684AI\u5de5\u5177\u53ef\u4ee5\u6539\u8fdb\u56e0\u679c\u4f30\u8ba1\uff0c\u751f\u6210\u6a21\u578b\u7684\u5386\u53f2\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u6709\u52a9\u4e8e\u514b\u670d\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u7ef4\u5ea6\u8bc5\u5492\u95ee\u9898\u3002"}}
{"id": "2510.09691", "categories": ["cs.LG", "cs.AI", "68T07, 68M14", "I.2.6; I.2.11; K.6.5"], "pdf": "https://arxiv.org/pdf/2510.09691", "abs": "https://arxiv.org/abs/2510.09691", "authors": ["Tejash Varsani"], "title": "Evaluation of Differential Privacy Mechanisms on Federated Learning", "comment": "Supervised by Prof. Dr.-Ing. habil. Alois C. Knoll; Advisor:\n  Nagacharan Teja Tangirala, M.Sc", "summary": "Federated learning is distributed model training across several clients\nwithout disclosing raw data. Despite advancements in data privacy, risks still\nremain. Differential Privacy (DP) is a technique to protect sensitive data by\nadding noise to model updates, usually controlled by a fixed privacy budget.\nHowever, this approach can introduce excessive noise, particularly when the\nmodel converges, which compromises performance. To address this problem,\nadaptive privacy budgets have been investigated as a potential solution. This\nwork implements DP methods using Laplace and Gaussian mechanisms with an\nadaptive privacy budget, extending the SelecEval simulator. We introduce an\nadaptive clipping approach in the Gaussian mechanism, ensuring that gradients\nof the model are dynamically updated rather than using a fixed sensitivity. We\nconduct extensive experiments with various privacy budgets, IID and non-IID\ndatasets, and different numbers of selected clients per round. While our\nexperiments were limited to 200 training rounds, the results suggest that\nadaptive privacy budgets and adaptive clipping can help maintain model accuracy\nwhile preserving privacy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9e\u73b0\u62c9\u666e\u62c9\u65af\u548c\u9ad8\u65af\u673a\u5236\u7684\u5dee\u5206\u9690\u79c1\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u88c1\u526a\u6280\u672f\uff0c\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u7ef4\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u4fdd\u62a4\u4e86\u539f\u59cb\u6570\u636e\u9690\u79c1\uff0c\u4f46\u56fa\u5b9a\u9690\u79c1\u9884\u7b97\u7684\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u5728\u6a21\u578b\u6536\u655b\u65f6\u4f1a\u5f15\u5165\u8fc7\u591a\u566a\u58f0\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002\u9700\u8981\u63a2\u7d22\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u6765\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u548c\u6a21\u578b\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u548c\u9ad8\u65af\u673a\u5236\u5b9e\u73b0\u5dee\u5206\u9690\u79c1\uff0c\u5728SelecEval\u6a21\u62df\u5668\u4e2d\u6269\u5c55\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u529f\u80fd\u3002\u7279\u522b\u4e3a\u9ad8\u65af\u673a\u5236\u5f15\u5165\u81ea\u9002\u5e94\u88c1\u526a\u65b9\u6cd5\uff0c\u52a8\u6001\u66f4\u65b0\u68af\u5ea6\u800c\u975e\u4f7f\u7528\u56fa\u5b9a\u654f\u611f\u5ea6\u3002", "result": "\u5728200\u8f6e\u8bad\u7ec3\u5b9e\u9a8c\u4e2d\uff0c\u6d4b\u8bd5\u4e86\u4e0d\u540c\u9690\u79c1\u9884\u7b97\u3001IID\u548c\u975eIID\u6570\u636e\u96c6\u4ee5\u53ca\u6bcf\u8f6e\u9009\u62e9\u4e0d\u540c\u5ba2\u6237\u7aef\u6570\u91cf\u7684\u60c5\u51b5\u3002\u7ed3\u679c\u8868\u660e\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u548c\u81ea\u9002\u5e94\u88c1\u526a\u6709\u52a9\u4e8e\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u7ef4\u6301\u6a21\u578b\u51c6\u786e\u6027\u3002", "conclusion": "\u81ea\u9002\u5e94\u9690\u79c1\u9884\u7b97\u548c\u81ea\u9002\u5e94\u88c1\u526a\u6280\u672f\u80fd\u591f\u6709\u6548\u89e3\u51b3\u56fa\u5b9a\u9690\u79c1\u9884\u7b97\u5e26\u6765\u7684\u566a\u58f0\u8fc7\u591a\u95ee\u9898\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2510.09693", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.09693", "abs": "https://arxiv.org/abs/2510.09693", "authors": ["Jiakang Chen"], "title": "Neural PDE Solvers with Physics Constraints: A Comparative Study of PINNs, DRM, and WANs", "comment": "50 pages, 13 figures", "summary": "Partial differential equations (PDEs) underpin models across science and\nengineering, yet analytical solutions are atypical and classical mesh-based\nsolvers can be costly in high dimensions. This dissertation presents a unified\ncomparison of three mesh-free neural PDE solvers, physics-informed neural\nnetworks (PINNs), the deep Ritz method (DRM), and weak adversarial networks\n(WANs), on Poisson problems (up to 5D) and the time-independent Schr\\\"odinger\nequation in 1D/2D (infinite well and harmonic oscillator), and extends the\nstudy to a laser-driven case of Schr\\\"odinger's equation via the\nKramers-Henneberger (KH) transformation.\n  Under a common protocol, all methods achieve low $L_2$ errors\n($10^{-6}$-$10^{-9}$) when paired with forced boundary conditions (FBCs),\nforced nodes (FNs), and orthogonality regularization (OG). Across tasks, PINNs\nare the most reliable for accuracy and recovery of excited spectra; DRM offers\nthe best accuracy-runtime trade-off on stationary problems; WAN is more\nsensitive but competitive when weak-form constraints and FN/OG are used\neffectively. Sensitivity analyses show that FBC removes boundary-loss tuning,\nnetwork width matters more than depth for single-network solvers, and most\ngains occur within 5000-10,000 epochs. The same toolkit solves the KH case,\nindicating transfer beyond canonical benchmarks.\n  We provide practical guidelines for method selection and outline the\nfollowing extensions: time-dependent formulations for DRM and WAN, adaptive\nresidual-driven sampling, parallel multi-state training, and neural domain\ndecomposition. These results support physics-guided neural solvers as credible,\nscalable tools for solving complex PDEs.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e09\u79cd\u65e0\u7f51\u683c\u795e\u7ecfPDE\u6c42\u89e3\u5668\uff08PINNs\u3001DRM\u3001WANs\uff09\u5728\u6cca\u677e\u95ee\u9898\u548c\u859b\u5b9a\u8c14\u65b9\u7a0b\u4e0a\u8fdb\u884c\u7edf\u4e00\u6bd4\u8f83\uff0c\u6240\u6709\u65b9\u6cd5\u5728\u5f3a\u5236\u8fb9\u754c\u6761\u4ef6\u548c\u6b63\u5219\u5316\u4e0b\u90fd\u80fd\u8fbe\u523010^-6\u523010^-9\u7684\u4f4e\u8bef\u5dee\uff0c\u5e76\u63d0\u4f9b\u4e86\u65b9\u6cd5\u9009\u62e9\u6307\u5357\u548c\u6269\u5c55\u65b9\u5411\u3002", "motivation": "\u4f20\u7edf\u7f51\u683c\u5316PDE\u6c42\u89e3\u5668\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u63a2\u7d22\u65e0\u7f51\u683c\u795e\u7ecf\u6c42\u89e3\u5668\u7684\u6027\u80fd\u6bd4\u8f83\u548c\u5b9e\u9645\u5e94\u7528\u6307\u5357\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u534f\u8bae\u6bd4\u8f83PINNs\u3001DRM\u548cWANs\u4e09\u79cd\u65b9\u6cd5\uff0c\u5728\u6cca\u677e\u95ee\u9898\uff08\u6700\u9ad85D\uff09\u548c\u859b\u5b9a\u8c14\u65b9\u7a0b\uff081D/2D\uff09\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u6269\u5c55\u5230Kramers-Henneberger\u53d8\u6362\u7684\u6fc0\u5149\u9a71\u52a8\u859b\u5b9a\u8c14\u65b9\u7a0b\u3002", "result": "\u6240\u6709\u65b9\u6cd5\u5728\u5f3a\u5236\u8fb9\u754c\u6761\u4ef6\u3001\u5f3a\u5236\u8282\u70b9\u548c\u6b63\u4ea4\u6b63\u5219\u5316\u4e0b\u90fd\u80fd\u8fbe\u5230\u4f4eL2\u8bef\u5dee\uff0810^-6\u523010^-9\uff09\u3002PINNs\u5728\u7cbe\u5ea6\u548c\u6fc0\u53d1\u8c31\u6062\u590d\u65b9\u9762\u6700\u53ef\u9760\uff1bDRM\u5728\u7a33\u6001\u95ee\u9898\u4e0a\u63d0\u4f9b\u6700\u4f73\u7cbe\u5ea6-\u8fd0\u884c\u65f6\u95f4\u6743\u8861\uff1bWAN\u5bf9\u53c2\u6570\u66f4\u654f\u611f\u4f46\u5728\u5f31\u5f62\u5f0f\u7ea6\u675f\u4e0b\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u7269\u7406\u5f15\u5bfc\u7684\u795e\u7ecf\u6c42\u89e3\u5668\u662f\u89e3\u51b3\u590d\u6742PDE\u7684\u53ef\u4fe1\u3001\u53ef\u6269\u5c55\u5de5\u5177\uff0c\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u6cd5\u9009\u62e9\u6307\u5357\u5e76\u6307\u51fa\u4e86\u65f6\u95f4\u76f8\u5173\u516c\u5f0f\u3001\u81ea\u9002\u5e94\u91c7\u6837\u7b49\u6269\u5c55\u65b9\u5411\u3002"}}
{"id": "2510.09694", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09694", "abs": "https://arxiv.org/abs/2510.09694", "authors": ["Xiaodan Li", "Mengjie Wu", "Yao Zhu", "Yunna Lv", "YueFeng Chen", "Cen Chen", "Jianmei Guo", "Hui Xue"], "title": "Kelp: A Streaming Safeguard for Large Models via Latent Dynamics-Guided Risk Detection", "comment": null, "summary": "Large models (LMs) are powerful content generators, yet their open-ended\nnature can also introduce potential risks, such as generating harmful or biased\ncontent. Existing guardrails mostly perform post-hoc detection that may expose\nunsafe content before it is caught, and the latency constraints further push\nthem toward lightweight models, limiting detection accuracy. In this work, we\npropose Kelp, a novel plug-in framework that enables streaming risk detection\nwithin the LM generation pipeline. Kelp leverages intermediate LM hidden states\nthrough a Streaming Latent Dynamics Head (SLD), which models the temporal\nevolution of risk across the generated sequence for more accurate real-time\nrisk detection. To ensure reliable streaming moderation in real applications,\nwe introduce an Anchored Temporal Consistency (ATC) loss to enforce monotonic\nharm predictions by embedding a benign-then-harmful temporal prior. Besides,\nfor a rigorous evaluation of streaming guardrails, we also present\nStreamGuardBench-a model-grounded benchmark featuring on-the-fly responses from\neach protected model, reflecting real-world streaming scenarios in both text\nand vision-language tasks. Across diverse models and datasets, Kelp\nconsistently outperforms state-of-the-art post-hoc guardrails and prior plug-in\nprobes (15.61% higher average F1), while using only 20M parameters and adding\nless than 0.5 ms of per-token latency.", "AI": {"tldr": "Kelp\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u63d2\u4ef6\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u6d41\u5f0f\u98ce\u9669\u68c0\u6d4b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u540e\u5904\u7406\u68c0\u6d4b\u65b9\u6cd5\u66b4\u9732\u4e0d\u5b89\u5168\u5185\u5bb9\u548c\u68c0\u6d4b\u7cbe\u5ea6\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u9632\u62a4\u63aa\u65bd\u4e3b\u8981\u91c7\u7528\u540e\u5904\u7406\u68c0\u6d4b\uff0c\u53ef\u80fd\u5728\u6355\u83b7\u524d\u66b4\u9732\u4e0d\u5b89\u5168\u5185\u5bb9\uff0c\u4e14\u5ef6\u8fdf\u9650\u5236\u8feb\u4f7f\u5176\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u9650\u5236\u4e86\u68c0\u6d4b\u7cbe\u5ea6\u3002", "method": "Kelp\u5229\u7528\u4e2d\u95f4\u9690\u85cf\u72b6\u6001\uff0c\u901a\u8fc7\u6d41\u5f0f\u6f5c\u5728\u52a8\u6001\u5934\uff08SLD\uff09\u5efa\u6a21\u98ce\u9669\u5728\u751f\u6210\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u5e76\u5f15\u5165\u951a\u5b9a\u65f6\u95f4\u4e00\u81f4\u6027\uff08ATC\uff09\u635f\u5931\u6765\u5f3a\u5236\u6267\u884c\u5355\u8c03\u5371\u5bb3\u9884\u6d4b\u3002", "result": "\u5728\u591a\u6837\u5316\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\uff0cKelp\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u540e\u5904\u7406\u9632\u62a4\u63aa\u65bd\u548c\u5148\u524d\u7684\u63d2\u4ef6\u63a2\u9488\uff08\u5e73\u5747F1\u63d0\u9ad815.61%\uff09\uff0c\u4ec5\u4f7f\u75282000\u4e07\u53c2\u6570\u4e14\u6bcf\u6807\u8bb0\u5ef6\u8fdf\u589e\u52a0\u4e0d\u52300.5\u6beb\u79d2\u3002", "conclusion": "Kelp\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u51c6\u786e\u7684\u6d41\u5f0f\u98ce\u9669\u68c0\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u65f6\u5185\u5bb9\u5b89\u5168\u9632\u62a4\u80fd\u529b\u3002"}}
{"id": "2510.09704", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09704", "abs": "https://arxiv.org/abs/2510.09704", "authors": ["Matthew Schlegel", "Matthew E. Taylor", "Mostafa Farrokhabadi"], "title": "Operator Learning for Power Systems Simulation", "comment": null, "summary": "Time domain simulation, i.e., modeling the system's evolution over time, is a\ncrucial tool for studying and enhancing power system stability and dynamic\nperformance. However, these simulations become computationally intractable for\nrenewable-penetrated grids, due to the small simulation time step required to\ncapture renewable energy resources' ultra-fast dynamic phenomena in the range\nof 1-50 microseconds. This creates a critical need for solutions that are both\nfast and scalable, posing a major barrier for the stable integration of\nrenewable energy resources and thus climate change mitigation. This paper\nexplores operator learning, a family of machine learning methods that learn\nmappings between functions, as a surrogate model for these costly simulations.\nThe paper investigates, for the first time, the fundamental concept of\nsimulation time step-invariance, which enables models trained on coarse time\nsteps to generalize to fine-resolution dynamics. Three operator learning\nmethods are benchmarked on a simple test system that, while not incorporating\npractical complexities of renewable-penetrated grids, serves as a first\nproof-of-concept to demonstrate the viability of time step-invariance. Models\nare evaluated on (i) zero-shot super-resolution, where training is performed on\na coarse simulation time step and inference is performed at super-resolution,\nand (ii) generalization between stable and unstable dynamic regimes. This work\naddresses a key challenge in the integration of renewable energy for the\nmitigation of climate change by benchmarking operator learning methods to model\nphysical systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u7b97\u5b50\u5b66\u4e60\u4f5c\u4e3a\u7535\u529b\u7cfb\u7edf\u65f6\u57df\u4eff\u771f\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u89e3\u51b3\u53ef\u518d\u751f\u80fd\u6e90\u7535\u7f51\u4e2d\u5fae\u79d2\u7ea7\u52a8\u6001\u73b0\u8c61\u4eff\u771f\u7684\u8ba1\u7b97\u74f6\u9888\u95ee\u9898\uff0c\u5e76\u9996\u6b21\u7814\u7a76\u4e86\u4eff\u771f\u65f6\u95f4\u6b65\u957f\u4e0d\u53d8\u6027\u7684\u6982\u5ff5\u3002", "motivation": "\u53ef\u518d\u751f\u80fd\u6e90\u7535\u7f51\u7684\u65f6\u57df\u4eff\u771f\u7531\u4e8e\u9700\u8981\u6355\u83b71-50\u5fae\u79d2\u7ea7\u7684\u8d85\u5feb\u52a8\u6001\u73b0\u8c61\u800c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u8fd9\u963b\u788d\u4e86\u53ef\u518d\u751f\u80fd\u6e90\u7684\u7a33\u5b9a\u96c6\u6210\u548c\u6c14\u5019\u53d8\u5316\u7f13\u89e3\u3002\u9700\u8981\u5bfb\u627e\u65e2\u5feb\u901f\u53c8\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u7b97\u5b50\u5b66\u4e60\uff08\u5b66\u4e60\u51fd\u6570\u95f4\u6620\u5c04\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff09\u4f5c\u4e3a\u4eff\u771f\u66ff\u4ee3\u6a21\u578b\uff0c\u7814\u7a76\u65f6\u95f4\u6b65\u957f\u4e0d\u53d8\u6027\u6982\u5ff5\uff0c\u5728\u7b80\u5355\u6d4b\u8bd5\u7cfb\u7edf\u4e0a\u5bf9\u4e09\u79cd\u7b97\u5b50\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u96f6\u6837\u672c\u8d85\u5206\u8fa8\u7387\u548c\u7a33\u5b9a/\u4e0d\u7a33\u5b9a\u52a8\u6001\u673a\u5236\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u57fa\u51c6\u6d4b\u8bd5\u8bc1\u660e\u4e86\u65f6\u95f4\u6b65\u957f\u4e0d\u53d8\u6027\u7684\u53ef\u884c\u6027\uff0c\u5373\u7528\u7c97\u65f6\u95f4\u6b65\u957f\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u591f\u6cdb\u5316\u5230\u7cbe\u7ec6\u5206\u8fa8\u7387\u52a8\u6001\uff0c\u4e3a\u53ef\u518d\u751f\u80fd\u6e90\u7535\u7f51\u4eff\u771f\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u7b97\u5b50\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5efa\u6a21\u7269\u7406\u7cfb\u7edf\uff0c\u4e3a\u89e3\u51b3\u53ef\u518d\u751f\u80fd\u6e90\u96c6\u6210\u548c\u6c14\u5019\u53d8\u5316\u7f13\u89e3\u4e2d\u7684\u5173\u952e\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2510.09705", "categories": ["cs.LG", "cs.CY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09705", "abs": "https://arxiv.org/abs/2510.09705", "authors": ["Sudip Khadka", "L. S. Paudel"], "title": "A Multi-Component Reward Function with Policy Gradient for Automated Feature Selection with Dynamic Regularization and Bias Mitigation", "comment": null, "summary": "Static feature exclusion strategies often fail to prevent bias when hidden\ndependencies influence the model predictions. To address this issue, we explore\na reinforcement learning (RL) framework that integrates bias mitigation and\nautomated feature selection within a single learning process. Unlike\ntraditional heuristic-driven filter or wrapper approaches, our RL agent\nadaptively selects features using a reward signal that explicitly integrates\npredictive performance with fairness considerations. This dynamic formulation\nallows the model to balance generalization, accuracy, and equity throughout the\ntraining process, rather than rely exclusively on pre-processing adjustments or\npost hoc correction mechanisms. In this paper, we describe the construction of\na multi-component reward function, the specification of the agents action space\nover feature subsets, and the integration of this system with ensemble\nlearning. We aim to provide a flexible and generalizable way to select features\nin environments where predictors are correlated and biases can inadvertently\nre-emerge.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u5c06\u504f\u5dee\u7f13\u89e3\u548c\u7279\u5f81\u9009\u62e9\u6574\u5408\u5230\u5355\u4e00\u5b66\u4e60\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u5956\u52b1\u4fe1\u53f7\u5e73\u8861\u9884\u6d4b\u6027\u80fd\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u9759\u6001\u7279\u5f81\u6392\u9664\u7b56\u7565\u5f80\u5f80\u65e0\u6cd5\u6709\u6548\u9632\u6b62\u504f\u5dee\uff0c\u56e0\u4e3a\u9690\u85cf\u7684\u4f9d\u8d56\u5173\u7cfb\u4f1a\u5f71\u54cd\u6a21\u578b\u9884\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u52a8\u6001\u65b9\u6cd5\u6765\u5e73\u8861\u6cdb\u5316\u80fd\u529b\u3001\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u3002", "method": "\u6784\u5efa\u591a\u7ec4\u4ef6\u5956\u52b1\u51fd\u6570\uff0c\u5b9a\u4e49\u7279\u5f81\u5b50\u96c6\u4e0a\u7684\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u4e0e\u96c6\u6210\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u4f7f\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u9002\u5e94\u5730\u9009\u62e9\u7279\u5f81\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u53ef\u63a8\u5e7f\u7684\u7279\u5f81\u9009\u62e9\u65b9\u5f0f\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9884\u6d4b\u53d8\u91cf\u76f8\u5173\u4e14\u504f\u5dee\u53ef\u80fd\u65e0\u610f\u4e2d\u91cd\u65b0\u51fa\u73b0\u7684\u73af\u5883\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u52a8\u6001\u5e73\u8861\u9884\u6d4b\u6027\u80fd\u548c\u516c\u5e73\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u9884\u5904\u7406\u8c03\u6574\u6216\u4e8b\u540e\u6821\u6b63\u673a\u5236\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2510.09712", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09712", "abs": "https://arxiv.org/abs/2510.09712", "authors": ["Zhao Tong", "Chunlin Gong", "Yimeng Gu", "Haichao Shi", "Qiang Liu", "Shu Wu", "Xiao-Yu Zhang"], "title": "Group-Adaptive Adversarial Learning for Robust Fake News Detection Against Malicious Comments", "comment": "10 pages, 12 figures", "summary": "The spread of fake news online distorts public judgment and erodes trust in\nsocial media platforms. Although recent fake news detection (FND) models\nperform well in standard settings, they remain vulnerable to adversarial\ncomments-authored by real users or by large language models (LLMs)-that subtly\nshift model decisions. In view of this, we first present a comprehensive\nevaluation of comment attacks to existing fake news detectors and then\nintroduce a group-adaptive adversarial training strategy to improve the\nrobustness of FND models. To be specific, our approach comprises three steps:\n(1) dividing adversarial comments into three psychologically grounded\ncategories: perceptual, cognitive, and societal; (2) generating diverse,\ncategory-specific attacks via LLMs to enhance adversarial training; and (3)\napplying a Dirichlet-based adaptive sampling mechanism (InfoDirichlet Adjusting\nMechanism) that dynamically adjusts the learning focus across different comment\ncategories during training. Experiments on benchmark datasets show that our\nmethod maintains strong detection accuracy while substantially increasing\nrobustness to a wide range of adversarial comment perturbations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7fa4\u4f53\u81ea\u9002\u5e94\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u5bf9\u6297\u6027\u8bc4\u8bba\u5206\u4e3a\u611f\u77e5\u3001\u8ba4\u77e5\u548c\u793e\u4f1a\u4e09\u4e2a\u5fc3\u7406\u5b66\u7c7b\u522b\uff0c\u4f7f\u7528LLM\u751f\u6210\u591a\u6837\u5316\u653b\u51fb\uff0c\u5e76\u5e94\u7528\u57fa\u4e8eDirichlet\u7684\u81ea\u9002\u5e94\u91c7\u6837\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5047\u65b0\u95fb\u68c0\u6d4b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5047\u65b0\u95fb\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u4f20\u64ad\u626d\u66f2\u4e86\u516c\u4f17\u5224\u65ad\u5e76\u4fb5\u8680\u4e86\u5bf9\u5e73\u53f0\u7684\u4fe1\u4efb\u3002\u73b0\u6709\u7684\u5047\u65b0\u95fb\u68c0\u6d4b\u6a21\u578b\u5728\u6807\u51c6\u8bbe\u7f6e\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5bf9\u771f\u5b9e\u7528\u6237\u6216\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5bf9\u6297\u6027\u8bc4\u8bba\u4ecd\u7136\u8106\u5f31\u3002", "method": "1) \u5c06\u5bf9\u6297\u6027\u8bc4\u8bba\u5206\u4e3a\u611f\u77e5\u3001\u8ba4\u77e5\u548c\u793e\u4f1a\u4e09\u4e2a\u5fc3\u7406\u5b66\u7c7b\u522b\uff1b2) \u4f7f\u7528LLM\u751f\u6210\u591a\u6837\u5316\u7684\u7c7b\u522b\u7279\u5b9a\u653b\u51fb\u4ee5\u589e\u5f3a\u5bf9\u6297\u8bad\u7ec3\uff1b3) \u5e94\u7528\u57fa\u4e8eDirichlet\u7684\u81ea\u9002\u5e94\u91c7\u6837\u673a\u5236\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8c03\u6574\u4e0d\u540c\u8bc4\u8bba\u7c7b\u522b\u7684\u5b66\u4e60\u91cd\u70b9\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5f3a\u5927\u68c0\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u5404\u79cd\u5bf9\u6297\u6027\u8bc4\u8bba\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7fa4\u4f53\u81ea\u9002\u5e94\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u5047\u65b0\u95fb\u68c0\u6d4b\u6a21\u578b\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u6cd5\u3002"}}
{"id": "2510.09717", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09717", "abs": "https://arxiv.org/abs/2510.09717", "authors": ["Zhenlong Liu", "Hao Zeng", "Weiran Huang", "Hongxin Wei"], "title": "High-Power Training Data Identification with Provable Statistical Guarantees", "comment": null, "summary": "Identifying training data within large-scale models is critical for copyright\nlitigation, privacy auditing, and ensuring fair evaluation. The conventional\napproaches treat it as a simple binary classification task without statistical\nguarantees. A recent approach is designed to control the false discovery rate\n(FDR), but its guarantees rely on strong, easily violated assumptions. In this\npaper, we introduce Provable Training Data Identification (PTDI), a rigorous\nmethod that identifies a set of training data with strict false discovery rate\n(FDR) control. Specifically, our method computes p-values for each data point\nusing a set of known unseen data, and then constructs a conservative estimator\nfor the data usage proportion of the test set, which allows us to scale these\np-values. Our approach then selects the final set of training data by\nidentifying all points whose scaled p-values fall below a data-dependent\nthreshold. This entire procedure enables the discovery of training data with\nprovable, strict FDR control and significantly boosted power. Extensive\nexperiments across a wide range of models (LLMs and VLMs), and datasets\ndemonstrate that PTDI strictly controls the FDR and achieves higher power.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPTDI\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\uff0c\u5177\u6709\u4e25\u683c\u7684\u9519\u8bef\u53d1\u73b0\u7387\u63a7\u5236\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u8bc6\u522b\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u7684\u8bad\u7ec3\u6570\u636e\u5bf9\u4e8e\u7248\u6743\u8bc9\u8bbc\u3001\u9690\u79c1\u5ba1\u8ba1\u548c\u516c\u5e73\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u63a7\u5236\u9519\u8bef\u53d1\u73b0\u7387\u4f46\u4f9d\u8d56\u5f3a\u5047\u8bbe\u4e14\u6613\u88ab\u8fdd\u53cd\u3002", "method": "PTDI\u65b9\u6cd5\u4f7f\u7528\u5df2\u77e5\u672a\u89c1\u6570\u636e\u8ba1\u7b97\u6bcf\u4e2a\u6570\u636e\u70b9\u7684p\u503c\uff0c\u6784\u5efa\u6d4b\u8bd5\u96c6\u6570\u636e\u4f7f\u7528\u6bd4\u4f8b\u7684\u4fdd\u5b88\u4f30\u8ba1\u91cf\u6765\u7f29\u653ep\u503c\uff0c\u7136\u540e\u901a\u8fc7\u6570\u636e\u4f9d\u8d56\u7684\u9608\u503c\u9009\u62e9\u6700\u7ec8\u8bad\u7ec3\u6570\u636e\u96c6\u3002", "result": "\u5728\u591a\u79cd\u6a21\u578b\uff08LLMs\u548cVLMs\uff09\u548c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPTDI\u4e25\u683c\u63a7\u5236\u4e86\u9519\u8bef\u53d1\u73b0\u7387\uff0c\u5e76\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "PTDI\u65b9\u6cd5\u80fd\u591f\u4ee5\u4e25\u683c\u7684\u9519\u8bef\u53d1\u73b0\u7387\u63a7\u5236\u53d1\u73b0\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u80fd\u529b\uff0c\u4e3a\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u8bc6\u522b\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7edf\u8ba1\u4fdd\u8bc1\u3002"}}
{"id": "2510.09718", "categories": ["cs.LG", "68T05, 68T10", "I.5.3; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.09718", "abs": "https://arxiv.org/abs/2510.09718", "authors": ["A. Jung"], "title": "Federated k-Means via Generalized Total Variation Minimization", "comment": null, "summary": "We consider the problem of federated clustering, where interconnected devices\nhave access to private local datasets and need to jointly cluster the overall\ndataset without sharing their local dataset. Our focus is on hard clustering\nbased on the k-means principle. We formulate federated k-means clustering as an\ninstance of GTVMin. This formulation naturally lends to a federated k-means\nalgorithm where each device updates local cluster centroids by solving a\nmodified local k-means problem. The modification involves adding a penalty term\nto measure the discrepancy between the cluster centroid of neighbouring\ndevices. Our federated k-means algorithm is privacy-friendly as it only\nrequires sharing aggregated information among interconnected devices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u90a6k-means\u805a\u7c7b\u65b9\u6cd5\uff0c\u5141\u8bb8\u4e92\u8054\u8bbe\u5907\u5728\u4e0d\u5171\u4eab\u672c\u5730\u6570\u636e\u96c6\u7684\u60c5\u51b5\u4e0b\u8054\u5408\u805a\u7c7b\u6574\u4f53\u6570\u636e\uff0c\u901a\u8fc7GTVMin\u6846\u67b6\u548c\u6dfb\u52a0\u60e9\u7f5a\u9879\u6765\u534f\u8c03\u90bb\u8fd1\u8bbe\u5907\u95f4\u7684\u805a\u7c7b\u4e2d\u5fc3\u5dee\u5f02\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u805a\u7c7b\u95ee\u9898\uff0c\u4f7f\u4e92\u8054\u8bbe\u5907\u80fd\u591f\u5728\u4e0d\u5171\u4eab\u672c\u5730\u6570\u636e\u96c6\u7684\u60c5\u51b5\u4e0b\u8054\u5408\u805a\u7c7b\u6574\u4f53\u6570\u636e\uff0c\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u3002", "method": "\u5c06\u8054\u90a6k-means\u805a\u7c7b\u5efa\u6a21\u4e3aGTVMin\u5b9e\u4f8b\uff0c\u6bcf\u4e2a\u8bbe\u5907\u901a\u8fc7\u6c42\u89e3\u4fee\u6539\u540e\u7684\u672c\u5730k-means\u95ee\u9898\u6765\u66f4\u65b0\u672c\u5730\u805a\u7c7b\u4e2d\u5fc3\uff0c\u4fee\u6539\u5305\u62ec\u6dfb\u52a0\u60e9\u7f5a\u9879\u6765\u8861\u91cf\u90bb\u8fd1\u8bbe\u5907\u805a\u7c7b\u4e2d\u5fc3\u7684\u5dee\u5f02\u3002", "result": "\u5f00\u53d1\u51fa\u9690\u79c1\u53cb\u597d\u7684\u8054\u90a6k-means\u7b97\u6cd5\uff0c\u4ec5\u9700\u5728\u4e92\u8054\u8bbe\u5907\u95f4\u5171\u4eab\u805a\u5408\u4fe1\u606f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u8054\u90a6\u73af\u5883\u4e0b\u7684k-means\u805a\u7c7b\uff0c\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u8054\u5408\u805a\u7c7b\u3002"}}
{"id": "2510.09719", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09719", "abs": "https://arxiv.org/abs/2510.09719", "authors": ["Chenxu Wang", "Hao Li", "Yiqun Zhang", "Linyao Chen", "Jianhao Chen", "Ping Jian", "Peng Ye", "Qiaosheng Zhang", "Shuyue Hu"], "title": "ICL-Router: In-Context Learned Model Representations for LLM Routing", "comment": null, "summary": "Large language models (LLMs) often exhibit complementary strengths. Model\nrouting harnesses these strengths by dynamically directing each query to the\nmost suitable model, given a candidate model pool. However, routing performance\nrelies on accurate model representations, and adding new models typically\nrequires retraining, limiting scalability. To address these challenges, we\npropose a novel routing method using in-context vectors to represent model\ncapabilities. The method proceeds in two stages. First, queries are embedded\nand projected into vectors, with a projector and LLM-based router trained to\nreconstruct the original queries, aligning vector representations with the\nrouter's semantic space. Second, each candidate model is profiled on a query\nset, and the router learns -- based on in-context vectors of query and model\nperformance -- to predict whether each model can correctly answer new queries.\nExtensive experiments demonstrate that our method achieves state-of-the-art\nrouting performance in both in-distribution and out-of-distribution tasks.\nMoreover, our method allows for seamless integration of new models without\nretraining the router. The code is available at\nhttps://github.com/lalalamdbf/ICL-Router.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5411\u91cf\u7684\u6a21\u578b\u8def\u7531\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u5b9e\u73b0\u52a8\u6001\u9009\u62e9\u6700\u9002\u5408\u7684\u6a21\u578b\u5904\u7406\u67e5\u8be2\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u96c6\u6210\u65b0\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u8def\u7531\u65b9\u6cd5\u4f9d\u8d56\u51c6\u786e\u7684\u6a21\u578b\u8868\u793a\uff0c\u6dfb\u52a0\u65b0\u6a21\u578b\u901a\u5e38\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5c06\u67e5\u8be2\u5d4c\u5165\u5e76\u6295\u5f71\u4e3a\u5411\u91cf\uff0c\u8bad\u7ec3\u6295\u5f71\u5668\u548c\u57fa\u4e8eLLM\u7684\u8def\u7531\u5668\u6765\u91cd\u5efa\u539f\u59cb\u67e5\u8be2\uff1b\u7b2c\u4e8c\u9636\u6bb5\u57fa\u4e8e\u67e5\u8be2\u548c\u6a21\u578b\u6027\u80fd\u7684\u4e0a\u4e0b\u6587\u5411\u91cf\uff0c\u8def\u7531\u5668\u5b66\u4e60\u9884\u6d4b\u6bcf\u4e2a\u6a21\u578b\u662f\u5426\u80fd\u6b63\u786e\u56de\u7b54\u65b0\u67e5\u8be2\u3002", "result": "\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8def\u7531\u6027\u80fd\uff0c\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u65b0\u6a21\u578b\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u8def\u7531\u5668\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e0a\u4e0b\u6587\u5411\u91cf\u6709\u6548\u8868\u793a\u6a21\u578b\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u8def\u7531\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.09723", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T05 (Primary), 68T50", "I.2.6; I.2.7; I.5.4"], "pdf": "https://arxiv.org/pdf/2510.09723", "abs": "https://arxiv.org/abs/2510.09723", "authors": ["Gregory D. Baker"], "title": "It's 2025 -- Narrative Learning is the new baseline to beat for explainable machine learning", "comment": "18 pages, 5 figures", "summary": "In this paper, we introduce Narrative Learning, a methodology where models\nare defined entirely in natural language and iteratively refine their\nclassification criteria using explanatory prompts rather than traditional\nnumerical optimisation. We report on experiments to evaluate the accuracy and\npotential of this approach using 3 synthetic and 3 natural datasets and compare\nthem against 7 baseline explainable machine learning models. We demonstrate\nthat on 5 out of 6 of these datasets, Narrative Learning became more accurate\nthan the baseline explainable models in 2025 or earlier because of improvements\nin language models. We also report on trends in the lexicostatistics of these\nmodels' outputs as a proxy for the comprehensibility of the explanations.", "AI": {"tldr": "\u63d0\u51faNarrative Learning\u65b9\u6cd5\uff0c\u5b8c\u5168\u7528\u81ea\u7136\u8bed\u8a00\u5b9a\u4e49\u6a21\u578b\uff0c\u901a\u8fc7\u89e3\u91ca\u6027\u63d0\u793a\u800c\u975e\u4f20\u7edf\u6570\u503c\u4f18\u5316\u8fed\u4ee3\u6539\u8fdb\u5206\u7c7b\u6807\u51c6\u3002\u57286\u4e2a\u6570\u636e\u96c6\u4e2d\u76845\u4e2a\u4e0a\uff0c\u8be5\u65b9\u6cd5\u56e0\u8bed\u8a00\u6a21\u578b\u6539\u8fdb\u800c\u6bd4\u57fa\u7ebf\u53ef\u89e3\u91ca\u6a21\u578b\u66f4\u51c6\u786e\u3002", "motivation": "\u63a2\u7d22\u4e00\u79cd\u5b8c\u5168\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5b9a\u4e49\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u907f\u514d\u4f20\u7edf\u6570\u503c\u4f18\u5316\uff0c\u901a\u8fc7\u89e3\u91ca\u6027\u63d0\u793a\u8fed\u4ee3\u6539\u8fdb\u5206\u7c7b\u6807\u51c6\u3002", "method": "Narrative Learning\u65b9\u6cd5\uff0c\u6a21\u578b\u5b8c\u5168\u7528\u81ea\u7136\u8bed\u8a00\u5b9a\u4e49\uff0c\u4f7f\u7528\u89e3\u91ca\u6027\u63d0\u793a\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u800c\u975e\u4f20\u7edf\u6570\u503c\u4f18\u5316\u3002", "result": "\u57286\u4e2a\u6570\u636e\u96c6\uff083\u4e2a\u5408\u6210\uff0c3\u4e2a\u81ea\u7136\uff09\u4e2d\u76845\u4e2a\u4e0a\uff0cNarrative Learning\u6bd47\u4e2a\u57fa\u7ebf\u53ef\u89e3\u91ca\u673a\u5668\u5b66\u4e60\u6a21\u578b\u66f4\u51c6\u786e\uff0c\u4e3b\u8981\u5f97\u76ca\u4e8e\u8bed\u8a00\u6a21\u578b\u7684\u6539\u8fdb\u3002", "conclusion": "Narrative Learning\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edf\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u8868\u660e\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u7684\u65b9\u6cd5\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2510.09732", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09732", "abs": "https://arxiv.org/abs/2510.09732", "authors": ["P. van Oerle", "R. H. Bemthuis", "F. A. Bukhsh"], "title": "Evaluating LLM-Based Process Explanations under Progressive Behavioral-Input Reduction", "comment": "12 pages, 2 figures, 3 tables; to appear in Enterprise Design,\n  Operations, and Computing. EDOC 2025 Workshops, Lecture Notes in Business\n  Information Processing (LNBIP), Springer, 2025. Part of 29th International\n  Conference on Enterprise Design, Operations, and Computing (EDOC)", "summary": "Large Language Models (LLMs) are increasingly used to generate textual\nexplanations of process models discovered from event logs. Producing\nexplanations from large behavioral abstractions (e.g., directly-follows graphs\nor Petri nets) can be computationally expensive. This paper reports an\nexploratory evaluation of explanation quality under progressive\nbehavioral-input reduction, where models are discovered from progressively\nsmaller prefixes of a fixed log. Our pipeline (i) discovers models at multiple\ninput sizes, (ii) prompts an LLM to generate explanations, and (iii) uses a\nsecond LLM to assess completeness, bottleneck identification, and suggested\nimprovements. On synthetic logs, explanation quality is largely preserved under\nmoderate reduction, indicating a practical cost-quality trade-off. The study is\nexploratory, as the scores are LLM-based (comparative signals rather than\nground truth) and the data are synthetic. The results suggest a path toward\nmore computationally efficient, LLM-assisted process analysis in\nresource-constrained settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u4e86\u5728\u8fc7\u7a0b\u6a21\u578b\u53d1\u73b0\u4e2d\u901a\u8fc7\u9010\u6b65\u51cf\u5c11\u884c\u4e3a\u8f93\u5165\u6765\u4fdd\u6301LLM\u751f\u6210\u89e3\u91ca\u8d28\u91cf\u7684\u65b9\u6cd5\uff0c\u53d1\u73b0\u5728\u9002\u5ea6\u51cf\u5c11\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\u89e3\u91ca\u8d28\u91cf\u57fa\u672c\u4fdd\u6301\u4e0d\u53d8\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8fc7\u7a0b\u5206\u6790\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u8d28\u91cf\u7684\u6743\u8861\u65b9\u6848\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u751f\u6210\u4ece\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u53d1\u73b0\u7684\u8fc7\u7a0b\u6a21\u578b\u7684\u6587\u672c\u89e3\u91ca\uff0c\u4f46\u76f4\u63a5\u4ece\u5927\u578b\u884c\u4e3a\u62bd\u8c61\uff08\u5982\u76f4\u63a5\u8ddf\u968f\u56fe\u6216Petri\u7f51\uff09\u751f\u6210\u89e3\u91ca\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u91c7\u7528\u6e10\u8fdb\u5f0f\u884c\u4e3a\u8f93\u5165\u51cf\u5c11\u7684\u65b9\u6cd5\uff1a(i)\u4ece\u56fa\u5b9a\u65e5\u5fd7\u7684\u9010\u6b65\u7f29\u5c0f\u524d\u7f00\u4e2d\u53d1\u73b0\u6a21\u578b\uff0c(ii)\u63d0\u793aLLM\u751f\u6210\u89e3\u91ca\uff0c(iii)\u4f7f\u7528\u7b2c\u4e8c\u4e2aLLM\u8bc4\u4f30\u5b8c\u6574\u6027\u3001\u74f6\u9888\u8bc6\u522b\u548c\u5efa\u8bae\u6539\u8fdb\u3002", "result": "\u5728\u5408\u6210\u65e5\u5fd7\u4e0a\uff0c\u9002\u5ea6\u51cf\u5c11\u8f93\u5165\u65f6\u89e3\u91ca\u8d28\u91cf\u57fa\u672c\u4fdd\u6301\u4e0d\u53d8\uff0c\u8868\u660e\u5b58\u5728\u5b9e\u7528\u7684\u6210\u672c-\u8d28\u91cf\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8f93\u5165\u51cf\u5c11\u53ef\u4ee5\u5b9e\u73b0\u66f4\u8ba1\u7b97\u9ad8\u6548\u7684LLM\u8f85\u52a9\u8fc7\u7a0b\u5206\u6790\uff0c\u4f46\u9700\u6ce8\u610f\u7814\u7a76\u662f\u63a2\u7d22\u6027\u7684\uff0c\u8bc4\u5206\u57fa\u4e8eLLM\u4e14\u6570\u636e\u4e3a\u5408\u6210\u6570\u636e\u3002"}}
{"id": "2510.09734", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09734", "abs": "https://arxiv.org/abs/2510.09734", "authors": ["Jindong Tian", "Yifei Ding", "Ronghui Xu", "Hao Miao", "Chenjuan Guo", "Bin Yang"], "title": "ARROW: An Adaptive Rollout and Routing Method for Global Weather Forecasting", "comment": "16 pages, 6 figures, conference", "summary": "Weather forecasting is a fundamental task in spatiotemporal data analysis,\nwith broad applications across a wide range of domains. Existing data-driven\nforecasting methods typically model atmospheric dynamics over a fixed short\ntime interval (e.g., 6 hours) and rely on naive autoregression-based rollout\nfor long-term forecasting (e.g., 138 hours). However, this paradigm suffers\nfrom two key limitations: (1) it often inadequately models the spatial and\nmulti-scale temporal dependencies inherent in global weather systems, and (2)\nthe rollout strategy struggles to balance error accumulation with the capture\nof fine-grained atmospheric variations. In this study, we propose ARROW, an\nAdaptive-Rollout Multi-scale temporal Routing method for Global Weather\nForecasting. To contend with the first limitation, we construct a\nmulti-interval forecasting model that forecasts weather across different time\nintervals. Within the model, the Shared-Private Mixture-of-Experts captures\nboth shared patterns and specific characteristics of atmospheric dynamics\nacross different time scales, while Ring Positional Encoding accurately encodes\nthe circular latitude structure of the Earth when representing spatial\ninformation. For the second limitation, we develop an adaptive rollout\nscheduler based on reinforcement learning, which selects the most suitable time\ninterval to forecast according to the current weather state. Experimental\nresults demonstrate that ARROW achieves state-of-the-art performance in global\nweather forecasting, establishing a promising paradigm in this field.", "AI": {"tldr": "ARROW\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u6eda\u52a8\u7684\u591a\u5c3a\u5ea6\u65f6\u95f4\u8def\u7531\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf\u5929\u6c14\u9884\u6d4b\u65b9\u6cd5\u5728\u5efa\u6a21\u65f6\u7a7a\u4f9d\u8d56\u6027\u548c\u5e73\u8861\u8bef\u5dee\u7d2f\u79ef\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9a71\u52a8\u7684\u5929\u6c14\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u56fa\u5b9a\u77ed\u65f6\u95f4\u95f4\u9694\u5efa\u6a21\uff0c\u4f9d\u8d56\u6734\u7d20\u81ea\u56de\u5f52\u6eda\u52a8\u8fdb\u884c\u957f\u671f\u9884\u6d4b\uff0c\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a(1) \u96be\u4ee5\u5145\u5206\u5efa\u6a21\u5168\u7403\u5929\u6c14\u7cfb\u7edf\u7684\u7a7a\u95f4\u548c\u591a\u5c3a\u5ea6\u65f6\u95f4\u4f9d\u8d56\u6027\uff1b(2) \u6eda\u52a8\u7b56\u7565\u96be\u4ee5\u5e73\u8861\u8bef\u5dee\u7d2f\u79ef\u4e0e\u7cbe\u7ec6\u5927\u6c14\u53d8\u5316\u7684\u6355\u6349\u3002", "method": "\u6784\u5efa\u591a\u95f4\u9694\u9884\u6d4b\u6a21\u578b\uff0c\u4f7f\u7528\u5171\u4eab-\u79c1\u6709\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u6355\u83b7\u4e0d\u540c\u65f6\u95f4\u5c3a\u5ea6\u7684\u5171\u4eab\u6a21\u5f0f\u548c\u7279\u5b9a\u7279\u5f81\uff0c\u91c7\u7528\u73af\u5f62\u4f4d\u7f6e\u7f16\u7801\u51c6\u786e\u8868\u793a\u5730\u7403\u7684\u5706\u5f62\u7eac\u5ea6\u7ed3\u6784\uff0c\u5e76\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u5f00\u53d1\u81ea\u9002\u5e94\u6eda\u52a8\u8c03\u5ea6\u5668\u6765\u9009\u62e9\u6700\u5408\u9002\u7684\u65f6\u95f4\u95f4\u9694\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eARROW\u5728\u5168\u7403\u5929\u6c14\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "ARROW\u4e3a\u5168\u7403\u5929\u6c14\u9884\u6d4b\u9886\u57df\u5efa\u7acb\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u8303\u5f0f\u3002"}}
{"id": "2510.09739", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.09739", "abs": "https://arxiv.org/abs/2510.09739", "authors": ["Ayoub Bouguettaya", "Elizabeth M. Stuart"], "title": "Machine learning methods fail to provide cohesive atheoretical construction of personality traits from semantic embeddings", "comment": "1 figure, 12 pages", "summary": "The lexical hypothesis posits that personality traits are encoded in language\nand is foundational to models like the Big Five. We created a bottom-up\npersonality model from a classic adjective list using machine learning and\ncompared its descriptive utility against the Big Five by analyzing one million\nReddit comments. The Big Five, particularly Agreeableness, Conscientiousness,\nand Neuroticism, provided a far more powerful and interpretable description of\nthese online communities. In contrast, our machine-learning clusters provided\nno meaningful distinctions, failed to recover the Extraversion trait, and\nlacked the psychometric coherence of the Big Five. These results affirm the\nrobustness of the Big Five and suggest personality's semantic structure is\ncontext-dependent. Our findings show that while machine learning can help check\nthe ecological validity of established psychological theories, it may not be\nable to replace them.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u4ece\u7ecf\u5178\u5f62\u5bb9\u8bcd\u5217\u8868\u6784\u5efa\u81ea\u4e0b\u800c\u4e0a\u7684\u4eba\u683c\u6a21\u578b\uff0c\u5e76\u4e0e\u5927\u4e94\u4eba\u683c\u6a21\u578b\u5728100\u4e07\u6761Reddit\u8bc4\u8bba\u4e2d\u8fdb\u884c\u6bd4\u8f83\u3002\u7ed3\u679c\u663e\u793a\u5927\u4e94\u4eba\u683c\u6a21\u578b\uff08\u7279\u522b\u662f\u5b9c\u4eba\u6027\u3001\u5c3d\u8d23\u6027\u548c\u795e\u7ecf\u8d28\uff09\u6bd4\u673a\u5668\u5b66\u4e60\u805a\u7c7b\u6a21\u578b\u5177\u6709\u66f4\u5f3a\u7684\u63cf\u8ff0\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u9a8c\u8bc1\u8bcd\u6c47\u5047\u8bf4\uff0c\u63a2\u8ba8\u673a\u5668\u5b66\u4e60\u80fd\u5426\u66ff\u4ee3\u4f20\u7edf\u4eba\u683c\u5fc3\u7406\u5b66\u7406\u8bba\uff0c\u68c0\u9a8c\u5927\u4e94\u4eba\u683c\u6a21\u578b\u7684\u751f\u6001\u6548\u5ea6\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u4ece\u7ecf\u5178\u5f62\u5bb9\u8bcd\u5217\u8868\u6784\u5efa\u4eba\u683c\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u6790100\u4e07\u6761Reddit\u8bc4\u8bba\uff0c\u5c06\u65b0\u6a21\u578b\u4e0e\u5927\u4e94\u4eba\u683c\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5927\u4e94\u4eba\u683c\u6a21\u578b\u5728\u63cf\u8ff0\u5728\u7ebf\u793e\u533a\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u673a\u5668\u5b66\u4e60\u805a\u7c7b\u672a\u80fd\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u533a\u5206\uff0c\u672a\u80fd\u6062\u590d\u5916\u5411\u6027\u7279\u8d28\uff0c\u4e14\u7f3a\u4e4f\u5927\u4e94\u4eba\u683c\u7684\u5fc3\u7406\u6d4b\u91cf\u4e00\u81f4\u6027\u3002", "conclusion": "\u5927\u4e94\u4eba\u683c\u6a21\u578b\u5177\u6709\u7a33\u5065\u6027\uff0c\u4eba\u683c\u7684\u8bed\u4e49\u7ed3\u6784\u5177\u6709\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u673a\u5668\u5b66\u4e60\u53ef\u4ee5\u68c0\u9a8c\u5fc3\u7406\u5b66\u7406\u8bba\u7684\u751f\u6001\u6548\u5ea6\uff0c\u4f46\u53ef\u80fd\u65e0\u6cd5\u66ff\u4ee3\u4f20\u7edf\u7406\u8bba\u3002"}}
{"id": "2510.09752", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.09752", "abs": "https://arxiv.org/abs/2510.09752", "authors": ["Sai Krishna Reddy Mudhiganti", "Juanyan Wang", "Ruo Yang", "Manali Sharma"], "title": "Patentformer: A demonstration of AI-assisted automated patent drafting", "comment": null, "summary": "Patent drafting presents significant challenges due to its reliance on the\nextensive experience and specialized expertise of patent attorneys, who must\npossess both legal acumen and technical understanding of an invention to craft\npatent applications in a formal legal writing style. This paper presents a\ndemonstration of Patentformer, an AI-powered automated patent drafting platform\ndesigned to support patent attorneys by rapidly producing high-quality patent\napplications adhering to legal writing standards.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Patentformer\uff0c\u4e00\u4e2aAI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u4e13\u5229\u64b0\u5199\u5e73\u53f0\uff0c\u65e8\u5728\u901a\u8fc7\u5feb\u901f\u751f\u6210\u7b26\u5408\u6cd5\u5f8b\u5199\u4f5c\u6807\u51c6\u7684\u9ad8\u8d28\u91cf\u4e13\u5229\u7533\u8bf7\u6765\u652f\u6301\u4e13\u5229\u5f8b\u5e08\u3002", "motivation": "\u4e13\u5229\u64b0\u5199\u4e25\u91cd\u4f9d\u8d56\u4e13\u5229\u5f8b\u5e08\u7684\u4e30\u5bcc\u7ecf\u9a8c\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4ed6\u4eec\u9700\u8981\u540c\u65f6\u5177\u5907\u6cd5\u5f8b\u654f\u9510\u5ea6\u548c\u5bf9\u53d1\u660e\u7684\u6280\u672f\u7406\u89e3\uff0c\u8fd9\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86Patentformer\u5e73\u53f0\uff0c\u5229\u7528AI\u6280\u672f\u81ea\u52a8\u5316\u4e13\u5229\u64b0\u5199\u8fc7\u7a0b\uff0c\u786e\u4fdd\u751f\u6210\u7684\u4e13\u5229\u7533\u8bf7\u7b26\u5408\u6b63\u5f0f\u6cd5\u5f8b\u5199\u4f5c\u98ce\u683c\u3002", "result": "Patentformer\u80fd\u591f\u5feb\u901f\u751f\u6210\u9ad8\u8d28\u91cf\u4e13\u5229\u7533\u8bf7\uff0c\u6ee1\u8db3\u6cd5\u5f8b\u5199\u4f5c\u6807\u51c6\u8981\u6c42\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u4e13\u5229\u64b0\u5199\u5e73\u53f0Patentformer\u53ef\u4ee5\u6709\u6548\u652f\u6301\u4e13\u5229\u5f8b\u5e08\u5de5\u4f5c\uff0c\u63d0\u9ad8\u4e13\u5229\u64b0\u5199\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2510.09762", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09762", "abs": "https://arxiv.org/abs/2510.09762", "authors": ["Ruo Yang", "Sai Krishna Reddy Mudhiganti", "Manali Sharma"], "title": "PatentVision: A multimodal method for drafting patent applications", "comment": null, "summary": "Patent drafting is complex due to its need for detailed technical\ndescriptions, legal compliance, and visual elements. Although Large Vision\nLanguage Models (LVLMs) show promise across various tasks, their application in\nautomating patent writing remains underexplored. In this paper, we present\nPatentVision, a multimodal framework that integrates textual and visual inputs\nsuch as patent claims and drawings to generate complete patent specifications.\nBuilt on advanced LVLMs, PatentVision enhances accuracy by combining fine tuned\nvision language models with domain specific training tailored to patents.\nExperiments reveal it surpasses text only methods, producing outputs with\ngreater fidelity and alignment with human written standards. Its incorporation\nof visual data allows it to better represent intricate design features and\nfunctional connections, leading to richer and more precise results. This study\nunderscores the value of multimodal techniques in patent automation, providing\na scalable tool to reduce manual workloads and improve consistency.\nPatentVision not only advances patent drafting but also lays the groundwork for\nbroader use of LVLMs in specialized areas, potentially transforming\nintellectual property management and innovation processes.", "AI": {"tldr": "PatentVision\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6574\u5408\u4e13\u5229\u6743\u5229\u8981\u6c42\u548c\u56fe\u7eb8\u7b49\u6587\u672c\u548c\u89c6\u89c9\u8f93\u5165\uff0c\u81ea\u52a8\u751f\u6210\u5b8c\u6574\u7684\u4e13\u5229\u8bf4\u660e\u4e66\uff0c\u5728\u51c6\u786e\u6027\u548c\u4e0e\u4eba\u5de5\u64b0\u5199\u6807\u51c6\u7684\u4e00\u81f4\u6027\u65b9\u9762\u4f18\u4e8e\u7eaf\u6587\u672c\u65b9\u6cd5\u3002", "motivation": "\u4e13\u5229\u64b0\u5199\u590d\u6742\u4e14\u9700\u8981\u8be6\u7ec6\u6280\u672f\u63cf\u8ff0\u3001\u6cd5\u5f8b\u5408\u89c4\u6027\u548c\u89c6\u89c9\u5143\u7d20\uff0c\u800c\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u4e13\u5229\u5199\u4f5c\u65b9\u9762\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u57fa\u4e8e\u5148\u8fdb\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6784\u5efaPatentVision\u6846\u67b6\uff0c\u7ed3\u5408\u5fae\u8c03\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u9488\u5bf9\u4e13\u5229\u9886\u57df\u7684\u7279\u5b9a\u8bad\u7ec3\uff0c\u6574\u5408\u6587\u672c\u548c\u89c6\u89c9\u8f93\u5165\u6765\u751f\u6210\u4e13\u5229\u8bf4\u660e\u4e66\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePatentVision\u8d85\u8d8a\u4e86\u7eaf\u6587\u672c\u65b9\u6cd5\uff0c\u4ea7\u751f\u5177\u6709\u66f4\u9ad8\u4fdd\u771f\u5ea6\u548c\u4e0e\u4eba\u5de5\u64b0\u5199\u6807\u51c6\u66f4\u4e00\u81f4\u7684\u7ed3\u679c\uff0c\u901a\u8fc7\u89c6\u89c9\u6570\u636e\u66f4\u597d\u5730\u8868\u793a\u590d\u6742\u8bbe\u8ba1\u7279\u5f81\u548c\u529f\u80fd\u8fde\u63a5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u591a\u6a21\u6001\u6280\u672f\u5728\u4e13\u5229\u81ea\u52a8\u5316\u4e2d\u7684\u4ef7\u503c\uff0c\u4e3a\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u548c\u63d0\u9ad8\u4e00\u81f4\u6027\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u5de5\u5177\uff0c\u4e3aLVLMs\u5728\u4e13\u4e1a\u9886\u57df\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.09764", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09764", "abs": "https://arxiv.org/abs/2510.09764", "authors": ["Wanting Mao", "Maxwell A Xu", "Harish Haresamudram", "Mithun Saha", "Santosh Kumar", "James Matthew Rehg"], "title": "Leveraging Shared Prototypes for a Multimodal Pulse Motion Foundation Model", "comment": null, "summary": "Modeling multi-modal time-series data is critical for capturing system-level\ndynamics, particularly in biosignals where modalities such as ECG, PPG, EDA,\nand accelerometry provide complementary perspectives on interconnected\nphysiological processes. While recent self-supervised learning (SSL) advances\nhave improved unimodal representation learning, existing multi-modal approaches\noften rely on CLIP-style contrastive objectives that overfit to easily aligned\nfeatures and misclassify valid cross-modal relationships as negatives,\nresulting in fragmented and non-generalizable embeddings. To overcome these\nlimitations, we propose ProtoMM, a novel SSL framework that introduces a shared\nprototype dictionary to anchor heterogeneous modalities in a common embedding\nspace. By clustering representations around shared prototypes rather than\nexplicit negative sampling, our method captures complementary information\nacross modalities and provides a coherent \"common language\" for physiological\nsignals. In this work, we focus on developing a Pulse Motion foundation model\nwith ProtoMM and demonstrate that our approach outperforms contrastive-only and\nprior multimodal SSL methods, achieving state-of-the-art performance while\noffering improved interpretability of learned features.", "AI": {"tldr": "\u63d0\u51faProtoMM\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u539f\u578b\u5b57\u5178\u5728\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u8868\u793a\u5b66\u4e60\uff0c\u907f\u514d\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u751f\u7406\u4fe1\u53f7\u5206\u6790\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56CLIP\u98ce\u683c\u5bf9\u6bd4\u76ee\u6807\uff0c\u5bb9\u6613\u8fc7\u62df\u5408\u5230\u6613\u5bf9\u9f50\u7279\u5f81\uff0c\u5e76\u5c06\u6709\u6548\u7684\u8de8\u6a21\u6001\u5173\u7cfb\u8bef\u5206\u7c7b\u4e3a\u8d1f\u6837\u672c\uff0c\u5bfc\u81f4\u7247\u6bb5\u5316\u4e14\u4e0d\u53ef\u6cdb\u5316\u7684\u5d4c\u5165\u8868\u793a\u3002", "method": "\u5f15\u5165\u5171\u4eab\u539f\u578b\u5b57\u5178\uff0c\u5c06\u5f02\u6784\u6a21\u6001\u951a\u5b9a\u5728\u5171\u540c\u5d4c\u5165\u7a7a\u95f4\u4e2d\uff0c\u901a\u8fc7\u56f4\u7ed5\u5171\u4eab\u539f\u578b\u805a\u7c7b\u8868\u793a\u800c\u975e\u663e\u5f0f\u8d1f\u91c7\u6837\uff0c\u6355\u83b7\u8de8\u6a21\u6001\u4e92\u8865\u4fe1\u606f\u3002", "result": "ProtoMM\u5728Pulse Motion\u57fa\u7840\u6a21\u578b\u5f00\u53d1\u4e2d\u4f18\u4e8e\u4ec5\u5bf9\u6bd4\u5b66\u4e60\u548c\u73b0\u6709\u591a\u6a21\u6001SSL\u65b9\u6cd5\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u66f4\u597d\u7684\u5b66\u4e60\u7279\u5f81\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "ProtoMM\u6846\u67b6\u901a\u8fc7\u5171\u4eab\u539f\u578b\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u751f\u7406\u4fe1\u53f7\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09768", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.09768", "abs": "https://arxiv.org/abs/2510.09768", "authors": ["Khang Ngo", "Siamak Ravanbakhsh"], "title": "Scaling Laws and Symmetry, Evidence from Neural Force Fields", "comment": "22 pages, 10 figures", "summary": "We present an empirical study in the geometric task of learning interatomic\npotentials, which shows equivariance matters even more at larger scales; we\nshow a clear power-law scaling behaviour with respect to data, parameters and\ncompute with ``architecture-dependent exponents''. In particular, we observe\nthat equivariant architectures, which leverage task symmetry, scale better than\nnon-equivariant models. Moreover, among equivariant architectures, higher-order\nrepresentations translate to better scaling exponents. Our analysis also\nsuggests that for compute-optimal training, the data and model sizes should\nscale in tandem regardless of the architecture. At a high level, these results\nsuggest that, contrary to common belief, we should not leave it to the model to\ndiscover fundamental inductive biases such as symmetry, especially as we scale,\nbecause they change the inherent difficulty of the task and its scaling laws.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\u5728\u5b66\u4e60\u539f\u5b50\u95f4\u52bf\u80fd\u7684\u51e0\u4f55\u4efb\u52a1\u4e2d\uff0c\u7b49\u53d8\u6027\u67b6\u6784\u6bd4\u975e\u7b49\u53d8\u6027\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u6269\u5c55\u6027\uff0c\u4e14\u9ad8\u9636\u8868\u793a\u5bf9\u5e94\u66f4\u597d\u7684\u6269\u5c55\u6307\u6570\u3002\u8ba1\u7b97\u6700\u4f18\u8bad\u7ec3\u65f6\uff0c\u6570\u636e\u548c\u6a21\u578b\u5927\u5c0f\u5e94\u540c\u6b65\u6269\u5c55\u3002", "motivation": "\u7814\u7a76\u7b49\u53d8\u6027\u5728\u66f4\u5927\u5c3a\u5ea6\u4e0b\u5bf9\u5b66\u4e60\u539f\u5b50\u95f4\u52bf\u80fd\u7684\u5f71\u54cd\uff0c\u63a2\u7d22\u67b6\u6784\u76f8\u5173\u7684\u6269\u5c55\u89c4\u5f8b\uff0c\u9a8c\u8bc1\u5bf9\u79f0\u6027\u7b49\u5f52\u7eb3\u504f\u7f6e\u5728\u6a21\u578b\u6269\u5c55\u4e2d\u7684\u91cd\u8981\u6027\u3002", "method": "\u901a\u8fc7\u7ecf\u9a8c\u7814\u7a76\u5206\u6790\u7b49\u53d8\u6027\u548c\u975e\u7b49\u53d8\u6027\u67b6\u6784\u5728\u6570\u636e\u3001\u53c2\u6570\u548c\u8ba1\u7b97\u65b9\u9762\u7684\u6269\u5c55\u884c\u4e3a\uff0c\u6bd4\u8f83\u4e0d\u540c\u9636\u6570\u8868\u793a\u7684\u6269\u5c55\u6307\u6570\u3002", "result": "\u53d1\u73b0\u7b49\u53d8\u6027\u67b6\u6784\u6bd4\u975e\u7b49\u53d8\u6027\u6a21\u578b\u6269\u5c55\u6027\u66f4\u597d\uff0c\u9ad8\u9636\u8868\u793a\u5bf9\u5e94\u66f4\u597d\u7684\u6269\u5c55\u6307\u6570\u3002\u8ba1\u7b97\u6700\u4f18\u8bad\u7ec3\u9700\u8981\u6570\u636e\u548c\u6a21\u578b\u5927\u5c0f\u540c\u6b65\u6269\u5c55\u3002", "conclusion": "\u5728\u6a21\u578b\u6269\u5c55\u65f6\u4e0d\u5e94\u8ba9\u6a21\u578b\u81ea\u884c\u53d1\u73b0\u5bf9\u79f0\u6027\u7b49\u57fa\u672c\u5f52\u7eb3\u504f\u7f6e\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u504f\u7f6e\u4f1a\u6539\u53d8\u4efb\u52a1\u7684\u56fa\u6709\u96be\u5ea6\u548c\u6269\u5c55\u89c4\u5f8b\u3002"}}
{"id": "2510.09775", "categories": ["cs.LG", "cs.CR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09775", "abs": "https://arxiv.org/abs/2510.09775", "authors": ["Alex Hiles", "Bashar I. Ahmad"], "title": "A Generic Machine Learning Framework for Radio Frequency Fingerprinting", "comment": null, "summary": "Fingerprinting Radio Frequency (RF) emitters typically involves finding\nunique emitter characteristics that are featured in their transmitted signals.\nThese fingerprints are nuanced but sufficiently detailed, motivating the\npursuit of methods that can successfully extract them. The most granular\ndownstream task is known as Specific Emitter Identification (SEI), which\nrequires a well informed RF fingerprinting (RFF) approach for it to be\nsuccessful. RFF and SEI have a long history, with numerous application areas in\ndefence and civilian contexts such as signal intelligence, electronic\nsurveillance, physical-layer authentication of wireless communication devices,\nto name a few. RFF methods also support many other downstream tasks such as\nEmitter Data Association (EDA) and RF Emitter Clustering (RFEC) and are\napplicable to a range of transmission types. In recent years, data-driven\napproaches have become popular in the RFF domain due to their ability to\nautomatically learn intricate fingerprints from raw data. These methods\ngenerally deliver superior performance when compared to traditional techniques.\nThe more traditional approaches are often labour-intensive, inflexible and only\napplicable to a particular emitter type or transmission scheme. Therefore, we\nconsider data-driven Machine Learning (ML)-enabled RFF. In particular, we\npropose a generic framework for ML-enabled RFF which is inclusive of several\npopular downstream tasks such as SEI, EDA and RFEC. Each task is formulated as\na RF fingerprint-dependent task. A variety of use cases using real RF datasets\nare presented here to demonstrate the framework for a range of tasks and\napplication areas, such as spaceborne surveillance, signal intelligence and\ncountering drones.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u6846\u67b6\uff0c\u652f\u6301\u7279\u5b9a\u53d1\u5c04\u5668\u8bc6\u522b\u3001\u53d1\u5c04\u5668\u6570\u636e\u5173\u8054\u548c\u5c04\u9891\u53d1\u5c04\u5668\u805a\u7c7b\u7b49\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff0c\u5e76\u5728\u7a7a\u95f4\u76d1\u89c6\u3001\u4fe1\u53f7\u60c5\u62a5\u548c\u53cd\u65e0\u4eba\u673a\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\u901a\u5e38\u52b3\u52a8\u5bc6\u96c6\u3001\u7075\u6d3b\u6027\u5dee\u4e14\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u53d1\u5c04\u5668\u7c7b\u578b\u6216\u4f20\u8f93\u65b9\u6848\uff0c\u800c\u6570\u636e\u9a71\u52a8\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u81ea\u52a8\u4ece\u539f\u59cb\u6570\u636e\u4e2d\u5b66\u4e60\u590d\u6742\u6307\u7eb9\uff0c\u6027\u80fd\u66f4\u4f18\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u6846\u67b6\uff0c\u5c06\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\uff08SEI\u3001EDA\u3001RFEC\uff09\u7edf\u4e00\u8868\u8ff0\u4e3a\u5c04\u9891\u6307\u7eb9\u4f9d\u8d56\u4efb\u52a1\uff0c\u5e76\u4f7f\u7528\u771f\u5b9e\u5c04\u9891\u6570\u636e\u96c6\u8fdb\u884c\u591a\u4efb\u52a1\u9a8c\u8bc1\u3002", "result": "\u6846\u67b6\u5728\u591a\u4e2a\u5e94\u7528\u573a\u666f\u4e2d\uff08\u7a7a\u95f4\u76d1\u89c6\u3001\u4fe1\u53f7\u60c5\u62a5\u3001\u53cd\u65e0\u4eba\u673a\uff09\u5f97\u5230\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u9886\u57df\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u6846\u67b6\u4e3a\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u4e86\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u7075\u6d3b\u6027\u548c\u6027\u80fd\uff0c\u5728\u56fd\u9632\u548c\u6c11\u7528\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.09776", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09776", "abs": "https://arxiv.org/abs/2510.09776", "authors": ["Yufa Zhou", "Yixiao Wang", "Surbhi Goel", "Anru R. Zhang"], "title": "Why Do Transformers Fail to Forecast Time Series In-Context?", "comment": "Code: https://github.com/MasterZhou1/ICL-Time-Series", "summary": "Time series forecasting (TSF) remains a challenging and largely unsolved\nproblem in machine learning, despite significant recent efforts leveraging\nLarge Language Models (LLMs), which predominantly rely on Transformer\narchitectures. Empirical evidence consistently shows that even powerful\nTransformers often fail to outperform much simpler models, e.g., linear models,\non TSF tasks; however, a rigorous theoretical understanding of this phenomenon\nremains limited. In this paper, we provide a theoretical analysis of\nTransformers' limitations for TSF through the lens of In-Context Learning (ICL)\ntheory. Specifically, under AR($p$) data, we establish that: (1) Linear\nSelf-Attention (LSA) models $\\textit{cannot}$ achieve lower expected MSE than\nclassical linear models for in-context forecasting; (2) as the context length\napproaches to infinity, LSA asymptotically recovers the optimal linear\npredictor; and (3) under Chain-of-Thought (CoT) style inference, predictions\ncollapse to the mean exponentially. We empirically validate these findings\nthrough carefully designed experiments. Our theory not only sheds light on\nseveral previously underexplored phenomena but also offers practical insights\nfor designing more effective forecasting architectures. We hope our work\nencourages the broader research community to revisit the fundamental\ntheoretical limitations of TSF and to critically evaluate the direct\napplication of increasingly sophisticated architectures without deeper\nscrutiny.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86Transformer\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u8bc1\u660e\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u6a21\u578b\u65e0\u6cd5\u8d85\u8d8a\u7ecf\u5178\u7ebf\u6027\u6a21\u578b\uff0c\u5e76\u5206\u6790\u4e86\u5176\u5728\u65e0\u9650\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u7684\u6e10\u8fd1\u884c\u4e3a\u548cCoT\u63a8\u7406\u4e2d\u7684\u9884\u6d4b\u5d29\u6e83\u73b0\u8c61\u3002", "motivation": "\u5c3d\u7ba1\u8fd1\u671f\u5927\u91cf\u7814\u7a76\u5c1d\u8bd5\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u4f46\u5b9e\u8bc1\u8868\u660e\u8fd9\u4e9b\u590d\u6742\u6a21\u578b\u5f80\u5f80\u65e0\u6cd5\u8d85\u8d8a\u7b80\u5355\u7684\u7ebf\u6027\u6a21\u578b\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u89d2\u5ea6\u6df1\u5165\u7406\u89e3\u8fd9\u4e00\u73b0\u8c61\uff0c\u586b\u8865\u73b0\u6709\u7406\u8bba\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7In-Context Learning\u7406\u8bba\u6846\u67b6\uff0c\u5728AR(p)\u6570\u636e\u5047\u8bbe\u4e0b\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u5305\u62ec\uff1a\u8bc1\u660e\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u6a21\u578b\u5728\u671f\u671bMSE\u4e0a\u65e0\u6cd5\u8d85\u8d8a\u7ecf\u5178\u7ebf\u6027\u6a21\u578b\uff1b\u5206\u6790\u65e0\u9650\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u7684\u6e10\u8fd1\u884c\u4e3a\uff1b\u7814\u7a76CoT\u98ce\u683c\u63a8\u7406\u4e2d\u7684\u9884\u6d4b\u5d29\u6e83\u73b0\u8c61\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff1a(1) \u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u6a21\u578b\u65e0\u6cd5\u5728\u671f\u671bMSE\u4e0a\u8d85\u8d8a\u7ecf\u5178\u7ebf\u6027\u6a21\u578b\uff1b(2) \u5f53\u4e0a\u4e0b\u6587\u957f\u5ea6\u8d8b\u4e8e\u65e0\u7a77\u65f6\uff0c\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\u6e10\u8fd1\u6062\u590d\u6700\u4f18\u7ebf\u6027\u9884\u6d4b\u5668\uff1b(3) \u5728CoT\u98ce\u683c\u63a8\u7406\u4e0b\uff0c\u9884\u6d4b\u4f1a\u6307\u6570\u7ea7\u5d29\u6e83\u5230\u5747\u503c\u3002\u8fd9\u4e9b\u53d1\u73b0\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5b9e\u9a8c\u5f97\u5230\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86Transformer\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6839\u672c\u7406\u8bba\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u5728\u5e94\u7528\u590d\u6742\u67b6\u6784\u524d\u8fdb\u884c\u6df1\u5165\u7406\u8bba\u5206\u6790\u7684\u91cd\u8981\u6027\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u9884\u6d4b\u67b6\u6784\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u5e76\u9f13\u52b1\u7814\u7a76\u754c\u91cd\u65b0\u5ba1\u89c6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684\u57fa\u672c\u7406\u8bba\u9650\u5236\u3002"}}
{"id": "2510.09780", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09780", "abs": "https://arxiv.org/abs/2510.09780", "authors": ["ChengAo Shen", "Ziming Zhao", "Hanghang Tong", "Dongjin Song", "Dongsheng Luo", "Qingsong Wen", "Jingchao Ni"], "title": "SVTime: Small Time Series Forecasting Models Informed by \"Physics\" of Large Vision Model Forecasters", "comment": null, "summary": "Time series AI is crucial for analyzing dynamic web content, driving a surge\nof pre-trained large models known for their strong knowledge encoding and\ntransfer capabilities across diverse tasks. However, given their\nenergy-intensive training, inference, and hardware demands, using large models\nas a one-fits-all solution raises serious concerns about carbon footprint and\nsustainability. For a specific task, a compact yet specialized, high-performing\nmodel may be more practical and affordable, especially for resource-constrained\nusers such as small businesses. This motivates the question: Can we build\ncost-effective lightweight models with large-model-like performance on core\ntasks such as forecasting? This paper addresses this question by introducing\nSVTime, a novel Small model inspired by large Vision model (LVM) forecasters\nfor long-term Time series forecasting (LTSF). Recently, LVMs have been shown as\npowerful tools for LTSF. We identify a set of key inductive biases of LVM\nforecasters -- analogous to the \"physics\" governing their behaviors in LTSF --\nand design small models that encode these biases through meticulously crafted\nlinear layers and constraint functions. Across 21 baselines spanning\nlightweight, complex, and pre-trained large models on 8 benchmark datasets,\nSVTime outperforms state-of-the-art (SOTA) lightweight models and rivals large\nmodels with 10^3 fewer parameters than LVMs, while enabling efficient training\nand inference in low-resource settings.", "AI": {"tldr": "SVTime\u662f\u4e00\u4e2a\u53d7\u5927\u578b\u89c6\u89c9\u6a21\u578b\u542f\u53d1\u7684\u5c0f\u578b\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u7f16\u7801\u5173\u952e\u5f52\u7eb3\u504f\u7f6e\u5b9e\u73b0\u9ad8\u6027\u80fd\u957f\u671f\u9884\u6d4b\uff0c\u53c2\u6570\u6bd4\u5927\u578b\u6a21\u578b\u5c1110^3\u500d\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u4ecd\u80fd\u9ad8\u6548\u8fd0\u884c\u3002", "motivation": "\u5927\u578bAI\u6a21\u578b\u867d\u7136\u6027\u80fd\u5f3a\u5927\u4f46\u80fd\u8017\u9ad8\u3001\u6210\u672c\u5927\uff0c\u4e0d\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u7528\u6237\u3002\u9700\u8981\u5f00\u53d1\u65e2\u7d27\u51d1\u53c8\u4e13\u4e1a\u7684\u9ad8\u6027\u80fd\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u5728\u6838\u5fc3\u4efb\u52a1\u4e0a\u8fbe\u5230\u7c7b\u4f3c\u5927\u578b\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u8bc6\u522b\u5927\u578b\u89c6\u89c9\u6a21\u578b\u9884\u6d4b\u5668\u7684\u5173\u952e\u5f52\u7eb3\u504f\u7f6e\uff08\u7c7b\u4f3c\"\u7269\u7406\u89c4\u5f8b\"\uff09\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7ebf\u6027\u5c42\u548c\u7ea6\u675f\u51fd\u6570\u5728\u5c0f\u6a21\u578b\u4e2d\u7f16\u7801\u8fd9\u4e9b\u504f\u7f6e\uff0c\u6784\u5efaSVTime\u6a21\u578b\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4e0e21\u4e2a\u57fa\u7ebf\u6a21\u578b\u5bf9\u6bd4\uff0cSVTime\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u6027\u80fd\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u53c2\u6570\u6570\u91cf\u5c1110^3\u500d\uff0c\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u548c\u63a8\u7406\u3002", "conclusion": "SVTime\u8bc1\u660e\u4e86\u53ef\u4ee5\u6784\u5efa\u6210\u672c\u6548\u76ca\u9ad8\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u5728\u6838\u5fc3\u9884\u6d4b\u4efb\u52a1\u4e0a\u8fbe\u5230\u5927\u578b\u6a21\u578b\u7ea7\u522b\u7684\u6027\u80fd\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7528\u6237\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09781", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09781", "abs": "https://arxiv.org/abs/2510.09781", "authors": ["Yue Huang", "Hang Hua", "Yujun Zhou", "Pengcheng Jing", "Manish Nagireddy", "Inkit Padhi", "Greta Dolcetti", "Zhangchen Xu", "Subhajit Chaudhury", "Ambrish Rawat", "Liubov Nedoshivina", "Pin-Yu Chen", "Prasanna Sattigeri", "Xiangliang Zhang"], "title": "Building a Foundational Guardrail for General Agentic Systems via Synthetic Data", "comment": null, "summary": "While LLM agents can plan multi-step tasks, intervening at the planning\nstage-before any action is executed-is often the safest way to prevent harm,\nsince certain risks can lead to severe consequences once carried out. However,\nexisting guardrails mostly operate post-execution, which is difficult to scale\nand leaves little room for controllable supervision at the plan level. To\naddress this challenge, we highlight three critical gaps in current research:\ndata gap, model gap, and evaluation gap. To close the data gap, we introduce\nAuraGen, a controllable engine that (i) synthesizes benign trajectories, (ii)\ninjects category-labeled risks with calibrated difficulty, and (iii) filters\noutputs via an automated reward model, producing large and reliable corpora for\npre-execution safety. To close the guardian model gap, we propose a\nfoundational guardrail Safiron, combining a cross-planner adapter with a\ncompact guardian model. The adapter unifies different input formats, while\nSafiron flags risky cases, assigns risk types, and generates rationales;\ntrained in two stages with a broadly explored data recipe, Safiron achieves\nrobust transfer across settings. To close the evaluation gap, we release\nPre-Exec Bench, a realistic benchmark covering diverse tools and branching\ntrajectories, which measures detection, fine-grained categorization,\nexplanation, and cross-planner generalization in human-verified scenarios.\nExtensive experiments demonstrate consistent gains of the proposed guardrail\nover strong baselines on Pre-Exec Bench, and ablations further distill\nactionable practices, providing a practical template for safer agentic systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9884\u6267\u884c\u5b89\u5168\u9632\u62a4\u6846\u67b6\uff0c\u901a\u8fc7AuraGen\u751f\u6210\u98ce\u9669\u6570\u636e\u3001Safiron\u9632\u62a4\u6a21\u578b\u548cPre-Exec Bench\u8bc4\u4f30\u57fa\u51c6\uff0c\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4f53\u5728\u8ba1\u5212\u9636\u6bb5\u7684\u5b89\u5168\u9632\u62a4\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u9632\u62a4\u63aa\u65bd\u4e3b\u8981\u5728\u52a8\u4f5c\u6267\u884c\u540e\u8fd0\u4f5c\uff0c\u96be\u4ee5\u6269\u5c55\u4e14\u7f3a\u4e4f\u5bf9\u8ba1\u5212\u5c42\u9762\u7684\u53ef\u63a7\u76d1\u7763\u3002\u67d0\u4e9b\u98ce\u9669\u4e00\u65e6\u6267\u884c\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\uff0c\u56e0\u6b64\u5728\u8ba1\u5212\u9636\u6bb5\u4ecb\u5165\u662f\u6700\u5b89\u5168\u7684\u9632\u62a4\u65b9\u5f0f\u3002", "method": "1) AuraGen\u53ef\u63a7\u5f15\u64ce\u5408\u6210\u826f\u6027\u8f68\u8ff9\u3001\u6ce8\u5165\u5206\u7c7b\u98ce\u9669\u5e76\u8fc7\u6ee4\u8f93\u51fa\uff1b2) Safiron\u9632\u62a4\u6a21\u578b\u7ed3\u5408\u8de8\u89c4\u5212\u5668\u9002\u914d\u5668\u548c\u7d27\u51d1\u9632\u62a4\u6a21\u578b\uff1b3) Pre-Exec Bench\u8bc4\u4f30\u57fa\u51c6\u8986\u76d6\u591a\u6837\u5316\u5de5\u5177\u548c\u5206\u652f\u8f68\u8ff9\u3002", "result": "\u5728Pre-Exec Bench\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u9632\u62a4\u6846\u67b6\u5728\u68c0\u6d4b\u3001\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3001\u89e3\u91ca\u548c\u8de8\u89c4\u5212\u5668\u6cdb\u5316\u65b9\u9762\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u66f4\u5b89\u5168\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6a21\u677f\uff0c\u901a\u8fc7\u586b\u8865\u6570\u636e\u3001\u6a21\u578b\u548c\u8bc4\u4f30\u4e09\u4e2a\u5173\u952e\u7a7a\u767d\uff0c\u5b9e\u73b0\u4e86\u5728\u8ba1\u5212\u9636\u6bb5\u7684\u53ef\u9760\u5b89\u5168\u9632\u62a4\u3002"}}
{"id": "2510.09784", "categories": ["cs.LG", "cond-mat.stat-mech", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.09784", "abs": "https://arxiv.org/abs/2510.09784", "authors": ["Richard John", "Yunrui Qiu", "Lukas Herron", "Pratyush Tiwary"], "title": "Combined Representation and Generation with Diffusive State Predictive Information Bottleneck", "comment": null, "summary": "Generative modeling becomes increasingly data-intensive in high-dimensional\nspaces. In molecular science, where data collection is expensive and important\nevents are rare, compression to lower-dimensional manifolds is especially\nimportant for various downstream tasks, including generation. We combine a\ntime-lagged information bottleneck designed to characterize molecular important\nrepresentations and a diffusion model in one joint training objective. The\nresulting protocol, which we term Diffusive State Predictive Information\nBottleneck (D-SPIB), enables the balancing of representation learning and\ngeneration aims in one flexible architecture. Additionally, the model is\ncapable of combining temperature information from different molecular\nsimulation trajectories to learn a coherent and useful internal representation\nof thermodynamics. We benchmark D-SPIB on multiple molecular tasks and showcase\nits potential for exploring physical conditions outside the training set.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u65f6\u95f4\u6ede\u540e\u4fe1\u606f\u74f6\u9888\u548c\u6269\u6563\u6a21\u578b\u7684\u8054\u5408\u8bad\u7ec3\u65b9\u6cd5D-SPIB\uff0c\u7528\u4e8e\u5206\u5b50\u79d1\u5b66\u4e2d\u7684\u8868\u793a\u5b66\u4e60\u548c\u751f\u6210\u4efb\u52a1\uff0c\u80fd\u591f\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5e73\u8861\u8868\u793a\u5b66\u4e60\u548c\u751f\u6210\u76ee\u6807\uff0c\u5e76\u80fd\u6574\u5408\u4e0d\u540c\u6e29\u5ea6\u4e0b\u7684\u5206\u5b50\u6a21\u62df\u8f68\u8ff9\u6570\u636e\u3002", "motivation": "\u5728\u9ad8\u7ef4\u5206\u5b50\u79d1\u5b66\u4e2d\uff0c\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u4e14\u91cd\u8981\u4e8b\u4ef6\u7a00\u5c11\uff0c\u9700\u8981\u5c06\u6570\u636e\u538b\u7f29\u5230\u4f4e\u7ef4\u6d41\u5f62\u4ee5\u652f\u6301\u4e0b\u6e38\u751f\u6210\u4efb\u52a1\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5e73\u8861\u8868\u793a\u5b66\u4e60\u548c\u751f\u6210\u76ee\u6807\u3002", "method": "\u7ed3\u5408\u65f6\u95f4\u6ede\u540e\u4fe1\u606f\u74f6\u9888\u548c\u6269\u6563\u6a21\u578b\uff0c\u8bbe\u8ba1\u8054\u5408\u8bad\u7ec3\u76ee\u6807\uff0c\u5f62\u6210D-SPIB\u534f\u8bae\u3002\u8be5\u67b6\u6784\u80fd\u591f\u6574\u5408\u4e0d\u540c\u6e29\u5ea6\u4e0b\u7684\u5206\u5b50\u6a21\u62df\u8f68\u8ff9\u6570\u636e\uff0c\u5b66\u4e60\u4e00\u81f4\u7684\u5185\u90e8\u70ed\u529b\u5b66\u8868\u793a\u3002", "result": "\u5728\u591a\u4e2a\u5206\u5b50\u4efb\u52a1\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u5916\u7269\u7406\u6761\u4ef6\u63a2\u7d22\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "D-SPIB\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u67b6\u6784\uff0c\u80fd\u591f\u6709\u6548\u5e73\u8861\u5206\u5b50\u79d1\u5b66\u4e2d\u7684\u8868\u793a\u5b66\u4e60\u548c\u751f\u6210\u4efb\u52a1\uff0c\u5e76\u5177\u6709\u6269\u5c55\u5230\u8bad\u7ec3\u96c6\u5916\u7269\u7406\u6761\u4ef6\u7684\u80fd\u529b\u3002"}}
{"id": "2510.09792", "categories": ["cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.09792", "abs": "https://arxiv.org/abs/2510.09792", "authors": ["Vahidreza Jahanmard", "Ali Ramezani-Kebrya", "Robinson Hordoir"], "title": "Principled Operator Learning in Ocean Dynamics: The Role of Temporal Structure", "comment": "Accepted at NeurIPS ML4PS 2025", "summary": "Neural operators are becoming the default tools to learn solutions to\ngoverning partial differential equations (PDEs) in weather and ocean\nforecasting applications. Despite early promising achievements, significant\nchallenges remain, including long-term prediction stability and adherence to\nphysical laws, particularly for high-frequency processes. In this paper, we\ntake a step toward addressing these challenges in high-resolution ocean\nprediction by incorporating temporal Fourier modes, demonstrating how this\nmodification enhances physical fidelity. This study compares the standard\nFourier Neural Operator (FNO) with its variant, FNOtD, which has been modified\nto internalize the dispersion relation while learning the solution operator for\nocean PDEs. The results demonstrate that entangling space and time in the\ntraining of integral kernels enables the model to capture multiscale wave\npropagation and effectively learn ocean dynamics. FNOtD substantially improves\nlong-term prediction stability and consistency with underlying physical\ndynamics in challenging high-frequency settings compared to the standard FNO.\nIt also provides competitive predictive skill relative to a state-of-the-art\nnumerical ocean model, while requiring significantly lower computational cost.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50FNOtD\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u5085\u91cc\u53f6\u6a21\u6001\u6765\u589e\u5f3a\u6d77\u6d0b\u504f\u5fae\u5206\u65b9\u7a0b\u6c42\u89e3\u7684\u7269\u7406\u4fdd\u771f\u5ea6\uff0c\u76f8\u6bd4\u6807\u51c6FNO\u5728\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u795e\u7ecf\u7b97\u5b50\u5728\u6d77\u6d0b\u548c\u5929\u6c14\u9884\u62a5\u5e94\u7528\u4e2d\u9762\u4e34\u957f\u671f\u9884\u6d4b\u4e0d\u7a33\u5b9a\u548c\u7269\u7406\u89c4\u5f8b\u9075\u5faa\u4e0d\u8db3\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u9ad8\u9891\u8fc7\u7a0b\u5efa\u6a21\u65b9\u9762\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6539\u8fdbFNO\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faFNOtD\u53d8\u4f53\uff0c\u901a\u8fc7\u5c06\u8272\u6563\u5173\u7cfb\u5185\u5316\u5230\u7b97\u5b50\u4e2d\uff0c\u5728\u79ef\u5206\u6838\u8bad\u7ec3\u4e2d\u7ea0\u7f20\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\uff0c\u4ece\u800c\u6355\u6349\u591a\u5c3a\u5ea6\u6ce2\u4f20\u64ad\u548c\u6d77\u6d0b\u52a8\u529b\u5b66\u3002", "result": "FNOtD\u76f8\u6bd4\u6807\u51c6FNO\u663e\u8457\u63d0\u9ad8\u4e86\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\uff0c\u5728\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\u7684\u60c5\u51b5\u4e0b\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u6570\u503c\u6d77\u6d0b\u6a21\u578b\u5177\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u80fd\u529b\u3002", "conclusion": "\u5728\u79ef\u5206\u6838\u8bad\u7ec3\u4e2d\u7ea0\u7f20\u7a7a\u95f4\u548c\u65f6\u95f4\u7ef4\u5ea6\u80fd\u591f\u6709\u6548\u5b66\u4e60\u6d77\u6d0b\u52a8\u529b\u5b66\uff0cFNOtD\u4e3a\u9ad8\u9891\u6d77\u6d0b\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u7269\u7406\u4fdd\u771f\u5ea6\u66f4\u9ad8\u3001\u8ba1\u7b97\u6548\u7387\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09845", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.09845", "abs": "https://arxiv.org/abs/2510.09845", "authors": ["Nicholas LaHaye", "Thilanka Munashinge", "Hugo Lee", "Xiaohua Pan", "Gonzalo Gonzalez Abad", "Hazem Mahmoud", "Jennifer Wei"], "title": "Harnessing Self-Supervised Deep Learning and Geostationary Remote Sensing for Advancing Wildfire and Associated Air Quality Monitoring: Improved Smoke and Fire Front Masking using GOES and TEMPO Radiance Data", "comment": "https://2025.ieeeigarss.org/view_paper.php?PaperNum=6389&SessionID=1611", "summary": "This work demonstrates the possibilities for improving wildfire and air\nquality management in the western United States by leveraging the unprecedented\nhourly data from NASA's TEMPO satellite mission and advances in self-supervised\ndeep learning. Here we demonstrate the efficacy of deep learning for mapping\nthe near real-time hourly spread of wildfire fronts and smoke plumes using an\ninnovative self-supervised deep learning-system: successfully distinguishing\nsmoke plumes from clouds using GOES-18 and TEMPO data, strong agreement across\nthe smoke and fire masks generated from different sensing modalities as well as\nsignificant improvement over operational products for the same cases.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528NASA TEMPO\u536b\u661f\u7684\u6bcf\u5c0f\u65f6\u6570\u636e\u548c\u81ea\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u6539\u8fdb\u4e86\u7f8e\u56fd\u897f\u90e8\u91ce\u706b\u548c\u7a7a\u6c14\u8d28\u91cf\u7ba1\u7406\u7684\u5b9e\u65f6\u76d1\u6d4b\u80fd\u529b\u3002", "motivation": "\u5229\u7528TEMPO\u536b\u661f\u524d\u6240\u672a\u6709\u7684\u6bcf\u5c0f\u65f6\u6570\u636e\u4ee5\u53ca\u81ea\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u63d0\u5347\u91ce\u706b\u548c\u7a7a\u6c14\u8d28\u91cf\u7ba1\u7406\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u521b\u65b0\u7684\u81ea\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\uff0c\u7ed3\u5408GOES-18\u548cTEMPO\u6570\u636e\uff0c\u5b9e\u65f6\u7ed8\u5236\u6bcf\u5c0f\u65f6\u91ce\u706b\u524d\u6cbf\u548c\u70df\u7fbd\u6269\u6563\u56fe\uff0c\u6210\u529f\u533a\u5206\u70df\u7fbd\u4e0e\u4e91\u5c42\u3002", "result": "\u4e0d\u540c\u4f20\u611f\u6a21\u5f0f\u751f\u6210\u7684\u70df\u7fbd\u548c\u706b\u707e\u63a9\u6a21\u5177\u6709\u9ad8\u5ea6\u4e00\u81f4\u6027\uff0c\u76f8\u6bd4\u76f8\u540c\u6848\u4f8b\u7684\u64cd\u4f5c\u4ea7\u54c1\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u81ea\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\u591a\u6e90\u536b\u661f\u6570\u636e\u80fd\u591f\u6709\u6548\u63d0\u5347\u91ce\u706b\u548c\u7a7a\u6c14\u8d28\u91cf\u7684\u5b9e\u65f6\u76d1\u6d4b\u4e0e\u7ba1\u7406\u80fd\u529b\u3002"}}
{"id": "2510.09846", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09846", "abs": "https://arxiv.org/abs/2510.09846", "authors": ["Zhenjiang Fan", "Zengyi Qin", "Yuanning Zheng", "Bo Xiong", "Summer Han"], "title": "CALM: A Causal Analysis Language Model for Tabular Data in Complex Systems with Local Scores, Conditional Independence Tests, and Relation Attributes", "comment": null, "summary": "Causal discovery from observational data is fundamental to scientific fields\nlike biology, where controlled experiments are often impractical. However,\nexisting methods, including constraint-based (e.g., PC, causalMGM) and\nscore-based approaches (e.g., NOTEARS), face significant limitations. These\ninclude an inability to resolve causal direction, restrictions to linear\nassociations, sensitivity to violations of the faithfulness assumption, and\ninefficiency in searching vast hypothesis spaces. While large language models\n(LLMs) offer powerful reasoning capabilities, their application is hindered by\na fundamental discrepancy: they are designed for text, while most causal data\nis tabular. To address these challenges, we introduce CALM, a novel causal\nanalysis language model specifically designed for tabular data in complex\nsystems. CALM leverages a Mamba-based architecture to classify causal patterns\nfrom pairwise variable relationships. It integrates a comprehensive suite of\nevidence, including local causal scores, conditional independence tests, and\nrelational attributes, to capture a wide spectrum of linear, nonlinear, and\nconditional causal mechanisms. Trained on a diverse corpus of synthetic data\n(from linear, mixed, and nonlinear models) and 10 real-world biological\ndatasets with rigorously validated causal relationships, our model ensures\nrobustness and generalizability. Empirical evaluation demonstrates that CALM\nsignificantly outperforms existing methods in both simulation studies,\nachieving over 91% accuracy, and in a real-world application identifying causal\nfactors in Hepatitis C virus progression. This work represents a significant\nstep towards accurate and generalizable causal discovery by successfully\nadapting the pattern recognition capabilities of language models to the\nintricacies of tabular data.", "AI": {"tldr": "CALM\u662f\u4e00\u4e2a\u4e13\u95e8\u4e3a\u8868\u683c\u6570\u636e\u8bbe\u8ba1\u7684\u56e0\u679c\u5206\u6790\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7Mamba\u67b6\u6784\u548c\u591a\u79cd\u8bc1\u636e\u6574\u5408\uff0c\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u51c6\u786e\u8bc6\u522b\u56e0\u679c\u6a21\u5f0f\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u65e0\u6cd5\u786e\u5b9a\u56e0\u679c\u65b9\u5411\u3001\u4ec5\u9650\u4e8e\u7ebf\u6027\u5173\u8054\u3001\u5bf9\u5fe0\u5b9e\u6027\u5047\u8bbe\u654f\u611f\u4ee5\u53ca\u641c\u7d22\u6548\u7387\u4f4e\u7b49\u95ee\u9898\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u867d\u5177\u5907\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u4f46\u4e0d\u9002\u7528\u4e8e\u8868\u683c\u6570\u636e\u3002", "method": "CALM\u91c7\u7528\u57fa\u4e8eMamba\u7684\u67b6\u6784\uff0c\u6574\u5408\u5c40\u90e8\u56e0\u679c\u5206\u6570\u3001\u6761\u4ef6\u72ec\u7acb\u6027\u68c0\u9a8c\u548c\u5173\u7cfb\u5c5e\u6027\u7b49\u591a\u79cd\u8bc1\u636e\uff0c\u5728\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u751f\u7269\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u6355\u6349\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u56e0\u679c\u673a\u5236\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0cCALM\u5728\u6a21\u62df\u7814\u7a76\u4e2d\u51c6\u786e\u7387\u8d85\u8fc791%\uff0c\u5728\u4e19\u578b\u809d\u708e\u75c5\u6bd2\u8fdb\u5c55\u7684\u56e0\u679c\u56e0\u7d20\u8bc6\u522b\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u6a21\u5f0f\u8bc6\u522b\u80fd\u529b\u6210\u529f\u5e94\u7528\u4e8e\u8868\u683c\u6570\u636e\u7684\u590d\u6742\u6027\uff0c\u4e3a\u5b9e\u73b0\u51c6\u786e\u4e14\u53ef\u63a8\u5e7f\u7684\u56e0\u679c\u53d1\u73b0\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2510.09852", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09852", "abs": "https://arxiv.org/abs/2510.09852", "authors": ["Shivam Patel", "Neharika Jali", "Ankur Mallick", "Gauri Joshi"], "title": "ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to Outliers", "comment": null, "summary": "Large language model (LLM) query routers are critical to modern AI platforms\nas they seek to improve efficiency by assigning inference queries to accurate,\nyet low-cost models. Parametric routers typically use trained neural networks\nfor LLM selection but suffer from retraining and maintenance overheads.\nNonparametric routers are training-free, instead estimating LLM accuracy and\ncost via similarity between encodings of the input query and training set\nqueries. However, like their parametric counterparts, nonparametric routers\nstruggle to generalize to outlier queries, an issue exacerbated by limited\ndiversity in training sets which are costly to expand and difficult to keep\ncurrent with ever-evolving use cases. We propose ProxRouter, which applies an\nexponentially tilted aggregation mechanism to balance bias and variance in\nnonparametric routers, improving their robustness to outliers. Experiments show\nProxRouter enhances outlier routing while preserving inlier performance with\nminimal overhead.", "AI": {"tldr": "ProxRouter\u662f\u4e00\u79cd\u975e\u53c2\u6570\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u67e5\u8be2\u8def\u7531\u5668\uff0c\u901a\u8fc7\u6307\u6570\u503e\u659c\u805a\u5408\u673a\u5236\u5e73\u8861\u504f\u5dee\u548c\u65b9\u5dee\uff0c\u63d0\u9ad8\u5bf9\u5f02\u5e38\u67e5\u8be2\u7684\u8def\u7531\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6b63\u5e38\u67e5\u8be2\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u6570\u5316\u8def\u7531\u5668\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u548c\u7ef4\u62a4\uff0c\u975e\u53c2\u6570\u5316\u8def\u7531\u5668\u867d\u7136\u65e0\u9700\u8bad\u7ec3\uff0c\u4f46\u5728\u5904\u7406\u5f02\u5e38\u67e5\u8be2\u65f6\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u8bad\u7ec3\u96c6\u591a\u6837\u6027\u6709\u9650\u3001\u66f4\u65b0\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51faProxRouter\u65b9\u6cd5\uff0c\u91c7\u7528\u6307\u6570\u503e\u659c\u805a\u5408\u673a\u5236\u6765\u5e73\u8861\u975e\u53c2\u6570\u5316\u8def\u7531\u5668\u4e2d\u7684\u504f\u5dee\u548c\u65b9\u5dee\uff0c\u4ece\u800c\u63d0\u9ad8\u5bf9\u5f02\u5e38\u67e5\u8be2\u7684\u8def\u7531\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660eProxRouter\u80fd\u591f\u589e\u5f3a\u5f02\u5e38\u67e5\u8be2\u7684\u8def\u7531\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6b63\u5e38\u67e5\u8be2\u7684\u8def\u7531\u6027\u80fd\uff0c\u4e14\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "ProxRouter\u901a\u8fc7\u5e73\u8861\u504f\u5dee\u548c\u65b9\u5dee\uff0c\u6709\u6548\u63d0\u5347\u4e86\u975e\u53c2\u6570\u5316\u8def\u7531\u5668\u5bf9\u5f02\u5e38\u67e5\u8be2\u7684\u5904\u7406\u80fd\u529b\uff0c\u4e3aLLM\u67e5\u8be2\u8def\u7531\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09884", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09884", "abs": "https://arxiv.org/abs/2510.09884", "authors": ["Soheila Farokhi", "Xiaojun Qi", "Hamid Karimi"], "title": "TAWRMAC: A Novel Dynamic Graph Representation Learning Method", "comment": null, "summary": "Dynamic graph representation learning has become essential for analyzing\nevolving networks in domains such as social network analysis, recommendation\nsystems, and traffic analysis. However, existing continuous-time methods face\nthree key challenges: (1) some methods depend solely on node-specific memory\nwithout effectively incorporating information from neighboring nodes, resulting\nin embedding staleness; (2) most fail to explicitly capture correlations\nbetween node neighborhoods, limiting contextual awareness; and (3) many fail to\nfully capture the structural dynamics of evolving graphs, especially in absence\nof rich link attributes. To address these limitations, we introduce TAWRMAC-a\nnovel framework that integrates Temporal Anonymous Walks with Restart, Memory\nAugmentation, and Neighbor Co-occurrence embedding. TAWRMAC enhances embedding\nstability through a memory-augmented GNN with fixedtime encoding and improves\ncontextual representation by explicitly capturing neighbor correlations.\nAdditionally, its Temporal Anonymous Walks with Restart mechanism distinguishes\nbetween nodes exhibiting repetitive interactions and those forming new\nconnections beyond their immediate neighborhood. This approach captures\nstructural dynamics better and supports strong inductive learning. Extensive\nexperiments on multiple benchmark datasets demonstrate that TAWRMAC\nconsistently outperforms state-of-the-art methods in dynamic link prediction\nand node classification under both transductive and inductive settings across\nthree different negative sampling strategies. By providing stable,\ngeneralizable, and context-aware embeddings, TAWRMAC advances the state of the\nart in continuous-time dynamic graph learning. The code is available at\nhttps://anonymous.4open.science/r/tawrmac-A253 .", "AI": {"tldr": "TAWRMAC\u662f\u4e00\u4e2a\u7528\u4e8e\u52a8\u6001\u56fe\u8868\u793a\u5b66\u4e60\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u65f6\u95f4\u533f\u540d\u6e38\u8d70\u91cd\u542f\u3001\u8bb0\u5fc6\u589e\u5f3a\u548c\u90bb\u5c45\u5171\u73b0\u5d4c\u5165\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5d4c\u5165\u7a33\u5b9a\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u7ed3\u6784\u52a8\u6001\u6355\u6349\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\u56fe\u5b66\u4e60\u65b9\u6cd5\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a(1)\u4ec5\u4f9d\u8d56\u8282\u70b9\u7279\u5b9a\u8bb0\u5fc6\u800c\u672a\u80fd\u6709\u6548\u6574\u5408\u90bb\u5c45\u4fe1\u606f\uff0c\u5bfc\u81f4\u5d4c\u5165\u9648\u65e7\uff1b(2)\u672a\u80fd\u663e\u5f0f\u6355\u6349\u8282\u70b9\u90bb\u5c45\u95f4\u7684\u76f8\u5173\u6027\uff0c\u9650\u5236\u4e0a\u4e0b\u6587\u611f\u77e5\uff1b(3)\u65e0\u6cd5\u5145\u5206\u6355\u6349\u6f14\u5316\u56fe\u7684\u7ed3\u6784\u52a8\u6001\uff0c\u7279\u522b\u662f\u5728\u7f3a\u4e4f\u4e30\u5bcc\u94fe\u63a5\u5c5e\u6027\u65f6\u3002", "method": "TAWRMAC\u6846\u67b6\u6574\u5408\u4e86\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u65f6\u95f4\u533f\u540d\u6e38\u8d70\u91cd\u542f\u673a\u5236\u3001\u8bb0\u5fc6\u589e\u5f3a\u7684GNN\u4e0e\u56fa\u5b9a\u65f6\u95f4\u7f16\u7801\u3001\u90bb\u5c45\u5171\u73b0\u5d4c\u5165\u3002\u901a\u8fc7\u8bb0\u5fc6\u589e\u5f3aGNN\u63d0\u9ad8\u5d4c\u5165\u7a33\u5b9a\u6027\uff0c\u663e\u5f0f\u6355\u6349\u90bb\u5c45\u76f8\u5173\u6027\u6539\u5584\u4e0a\u4e0b\u6587\u8868\u793a\uff0c\u65f6\u95f4\u533f\u540d\u6e38\u8d70\u91cd\u542f\u673a\u5236\u533a\u5206\u91cd\u590d\u4ea4\u4e92\u8282\u70b9\u4e0e\u5f62\u6210\u65b0\u8fde\u63a5\u7684\u8282\u70b9\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTAWRMAC\u5728\u52a8\u6001\u94fe\u63a5\u9884\u6d4b\u548c\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u5728\u8f6c\u5bfc\u548c\u5f52\u7eb3\u8bbe\u7f6e\u4e0b\uff0c\u8de8\u4e09\u79cd\u4e0d\u540c\u8d1f\u91c7\u6837\u7b56\u7565\uff0c\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "TAWRMAC\u901a\u8fc7\u63d0\u4f9b\u7a33\u5b9a\u3001\u53ef\u6cdb\u5316\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5d4c\u5165\uff0c\u63a8\u8fdb\u4e86\u8fde\u7eed\u65f6\u95f4\u52a8\u6001\u56fe\u5b66\u4e60\u7684\u6280\u672f\u6c34\u5e73\uff0c\u652f\u6301\u5f3a\u5927\u7684\u5f52\u7eb3\u5b66\u4e60\u80fd\u529b\u3002"}}
{"id": "2510.09888", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09888", "abs": "https://arxiv.org/abs/2510.09888", "authors": ["Yunlong Feng", "Qiang Wu"], "title": "Understanding Robust Machine Learning for Nonparametric Regression with Heavy-Tailed Noise", "comment": null, "summary": "We investigate robust nonparametric regression in the presence of\nheavy-tailed noise, where the hypothesis class may contain unbounded functions\nand robustness is ensured via a robust loss function $\\ell_\\sigma$. Using Huber\nregression as a close-up example within Tikhonov-regularized risk minimization\nin reproducing kernel Hilbert spaces (RKHS), we address two central challenges:\n(i) the breakdown of standard concentration tools under weak moment\nassumptions, and (ii) the analytical difficulties introduced by unbounded\nhypothesis spaces. Our first message is conceptual: conventional\ngeneralization-error bounds for robust losses do not faithfully capture\nout-of-sample performance. We argue that learnability should instead be\nquantified through prediction error, namely the $L_2$-distance to the truth\n$f^\\star$, which is $\\sigma$-independent and directly reflects the target of\nrobust estimation. To make this workable under unboundedness, we introduce a\n\\emph{probabilistic effective hypothesis space} that confines the estimator\nwith high probability and enables a meaningful bias--variance decomposition\nunder weak $(1+\\epsilon)$-moment conditions. Technically, we establish new\ncomparison theorems linking the excess robust risk to the $L_2$ prediction\nerror up to a residual of order $\\mathcal{O}(\\sigma^{-2\\epsilon})$, clarifying\nthe robustness--bias trade-off induced by the scale parameter $\\sigma$.\nBuilding on this, we derive explicit finite-sample error bounds and convergence\nrates for Huber regression in RKHS that hold without uniform boundedness and\nunder heavy-tailed noise. Our study delivers principled tuning rules, extends\nbeyond Huber to other robust losses, and highlights prediction error, not\nexcess generalization risk, as the fundamental lens for analyzing robust\nlearning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u91cd\u5c3e\u566a\u58f0\u5b58\u5728\u4e0b\u7684\u7a33\u5065\u975e\u53c2\u6570\u56de\u5f52\u95ee\u9898\uff0c\u4f7f\u7528Huber\u56de\u5f52\u4f5c\u4e3a\u4f8b\u5b50\uff0c\u5728\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u8fdb\u884cTikhonov\u6b63\u5219\u5316\u98ce\u9669\u6700\u5c0f\u5316\u3002\u63d0\u51fa\u4e86\u4f7f\u7528\u9884\u6d4b\u8bef\u5dee\u800c\u975e\u6cdb\u5316\u8bef\u5dee\u6765\u91cf\u5316\u53ef\u5b66\u4e60\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u6982\u7387\u6709\u6548\u5047\u8bbe\u7a7a\u95f4\u6765\u5904\u7406\u65e0\u754c\u51fd\u6570\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7a33\u5065\u635f\u5931\u7684\u6cdb\u5316\u8bef\u5dee\u754c\u9650\u4e0d\u80fd\u771f\u5b9e\u53cd\u6620\u6837\u672c\u5916\u6027\u80fd\uff0c\u4e14\u5728\u5f31\u77e9\u5047\u8bbe\u4e0b\u6807\u51c6\u96c6\u4e2d\u5de5\u5177\u5931\u6548\uff0c\u65e0\u754c\u5047\u8bbe\u7a7a\u95f4\u5e26\u6765\u5206\u6790\u56f0\u96be\u3002\u9700\u8981\u627e\u5230\u66f4\u5408\u9002\u7684\u91cf\u5316\u5b66\u4e60\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Huber\u56de\u5f52\u5728RKHS\u4e2d\u8fdb\u884cTikhonov\u6b63\u5219\u5316\u98ce\u9669\u6700\u5c0f\u5316\uff1b\u5f15\u5165\u6982\u7387\u6709\u6548\u5047\u8bbe\u7a7a\u95f4\u6765\u9650\u5236\u4f30\u8ba1\u5668\uff1b\u5efa\u7acb\u6bd4\u8f83\u5b9a\u7406\u5c06\u8d85\u989d\u7a33\u5065\u98ce\u9669\u4e0eL2\u9884\u6d4b\u8bef\u5dee\u8054\u7cfb\u8d77\u6765\uff1b\u5728\u5f31(1+\u03b5)-\u77e9\u6761\u4ef6\u4e0b\u8fdb\u884c\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\u3002", "result": "\u5efa\u7acb\u4e86\u5c06\u8d85\u989d\u7a33\u5065\u98ce\u9669\u4e0eL2\u9884\u6d4b\u8bef\u5dee\u8054\u7cfb\u8d77\u6765\u7684\u6bd4\u8f83\u5b9a\u7406\uff0c\u6b8b\u5dee\u4e3aO(\u03c3^{-2\u03b5})\uff1b\u5bfc\u51fa\u4e86Huber\u56de\u5f52\u5728RKHS\u4e2d\u7684\u663e\u5f0f\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\u9650\u548c\u6536\u655b\u901f\u7387\uff1b\u8fd9\u4e9b\u7ed3\u679c\u5728\u65e0\u4e00\u81f4\u6709\u754c\u6027\u548c\u91cd\u5c3e\u566a\u58f0\u4e0b\u6210\u7acb\u3002", "conclusion": "\u9884\u6d4b\u8bef\u5dee\u800c\u975e\u8d85\u989d\u6cdb\u5316\u98ce\u9669\u662f\u5206\u6790\u7a33\u5065\u5b66\u4e60\u7684\u57fa\u672c\u89c6\u89d2\uff1b\u7814\u7a76\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8c03\u53c2\u89c4\u5219\uff1b\u65b9\u6cd5\u53ef\u6269\u5c55\u5230Huber\u4ee5\u5916\u7684\u5176\u4ed6\u7a33\u5065\u635f\u5931\u51fd\u6570\uff1b\u9610\u660e\u4e86\u7531\u5c3a\u5ea6\u53c2\u6570\u03c3\u5f15\u8d77\u7684\u7a33\u5065\u6027-\u504f\u5dee\u6743\u8861\u3002"}}
{"id": "2510.09891", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09891", "abs": "https://arxiv.org/abs/2510.09891", "authors": ["Parsa Gooya", "Reinel Sospedra-Alfonso"], "title": "Probabilistic bias adjustment of seasonal predictions of Arctic Sea Ice Concentration", "comment": null, "summary": "Seasonal forecast of Arctic sea ice concentration is key to mitigate the\nnegative impact and assess potential opportunities posed by the rapid decline\nof sea ice coverage. Seasonal prediction systems based on climate models often\nshow systematic biases and complex spatio-temporal errors that grow with the\nforecasts. Consequently, operational predictions are routinely bias corrected\nand calibrated using retrospective forecasts. For predictions of Arctic sea ice\nconcentration, error corrections are mainly based on one-to-one post-processing\nmethods including climatological mean or linear regression correction and, more\nrecently, machine learning. Such deterministic adjustments are confined at best\nto the limited number of costly-to-run ensemble members of the raw forecast.\nHowever, decision-making requires proper quantification of uncertainty and\nlikelihood of events, particularly of extremes. We introduce a probabilistic\nerror correction framework based on a conditional Variational Autoencoder model\nto map the conditional distribution of observations given the biased model\nprediction. This method naturally allows for generating large ensembles of\nadjusted forecasts. We evaluate our model using deterministic and probabilistic\nmetrics and show that the adjusted forecasts are better calibrated, closer to\nthe observational distribution, and have smaller errors than climatological\nmean adjusted forecasts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u6982\u7387\u8bef\u5dee\u6821\u6b63\u6846\u67b6\uff0c\u7528\u4e8e\u6539\u8fdb\u5317\u6781\u6d77\u51b0\u6d53\u5ea6\u7684\u5b63\u8282\u6027\u9884\u6d4b\uff0c\u80fd\u591f\u751f\u6210\u5927\u91cf\u8c03\u6574\u540e\u7684\u9884\u6d4b\u96c6\u5408\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5317\u6781\u6d77\u51b0\u6d53\u5ea6\u5b63\u8282\u6027\u9884\u6d4b\u5bf9\u7f13\u89e3\u6d77\u51b0\u5feb\u901f\u51cf\u5c11\u7684\u8d1f\u9762\u5f71\u54cd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u9884\u6d4b\u7cfb\u7edf\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\u548c\u590d\u6742\u65f6\u7a7a\u8bef\u5dee\uff0c\u4f20\u7edf\u786e\u5b9a\u6027\u8bef\u5dee\u6821\u6b63\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6a21\u578b\uff0c\u5c06\u89c2\u6d4b\u6570\u636e\u7684\u6761\u4ef6\u5206\u5e03\u6620\u5c04\u5230\u6709\u504f\u5dee\u7684\u6a21\u578b\u9884\u6d4b\u4e0a\uff0c\u4ece\u800c\u751f\u6210\u5927\u91cf\u8c03\u6574\u540e\u7684\u9884\u6d4b\u96c6\u5408\u3002", "result": "\u8c03\u6574\u540e\u7684\u9884\u6d4b\u5728\u6821\u51c6\u6027\u3001\u4e0e\u89c2\u6d4b\u5206\u5e03\u7684\u63a5\u8fd1\u7a0b\u5ea6\u4ee5\u53ca\u8bef\u5dee\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u6c14\u5019\u5e73\u5747\u8c03\u6574\u9884\u6d4b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5317\u6781\u6d77\u51b0\u6d53\u5ea6\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u4e8b\u4ef6\u6982\u7387\u8bc4\u4f30\u80fd\u529b\uff0c\u5bf9\u51b3\u7b56\u5236\u5b9a\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.09895", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09895", "abs": "https://arxiv.org/abs/2510.09895", "authors": ["Yubo Li", "Rema Padman"], "title": "Chain-of-Influence: Tracing Interdependencies Across Time and Features in Clinical Predictive Modelings", "comment": null, "summary": "Modeling clinical time-series data is hampered by the challenge of capturing\nlatent, time-varying dependencies among features. State-of-the-art approaches\noften rely on black-box mechanisms or simple aggregation, failing to explicitly\nmodel how the influence of one clinical variable propagates through others over\ntime. We propose $\\textbf{Chain-of-Influence (CoI)}$, an interpretable deep\nlearning framework that constructs an explicit, time-unfolded graph of feature\ninteractions. CoI leverages a multi-level attention architecture: first, a\ntemporal attention layer identifies critical time points in a patient's record;\nsecond, a cross-feature attention layer models the directed influence from\nfeatures at these time points to subsequent features. This design enables the\ntracing of influence pathways, providing a granular audit trail that shows how\nany feature at any time contributes to the final prediction, both directly and\nthrough its influence on other variables. We evaluate CoI on mortality and\ndisease progression tasks using the MIMIC-IV dataset and a private chronic\nkidney disease cohort. Our framework significantly outperforms existing methods\nin predictive accuracy. More importantly, through case studies, we show that\nCoI can uncover clinically meaningful, patient-specific patterns of disease\nprogression that are opaque to other models, offering unprecedented\ntransparency into the temporal and cross-feature dependencies that inform\nclinical decision-making.", "AI": {"tldr": "\u63d0\u51faChain-of-Influence (CoI)\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u663e\u5f0f\u7684\u65f6\u95f4\u5c55\u5f00\u7279\u5f81\u4ea4\u4e92\u56fe\u6765\u5efa\u6a21\u4e34\u5e8a\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u6f5c\u5728\u65f6\u53d8\u4f9d\u8d56\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u663e\u5f0f\u5efa\u6a21\u4e34\u5e8a\u53d8\u91cf\u4e4b\u95f4\u968f\u65f6\u95f4\u4f20\u64ad\u7684\u5f71\u54cd\u5173\u7cfb\uff0c\u7f3a\u4e4f\u5bf9\u7279\u5f81\u4ea4\u4e92\u7684\u900f\u660e\u89e3\u91ca\u3002", "method": "\u4f7f\u7528\u591a\u5c42\u6ce8\u610f\u529b\u67b6\u6784\uff1a\u65f6\u95f4\u6ce8\u610f\u529b\u5c42\u8bc6\u522b\u5173\u952e\u65f6\u95f4\u70b9\uff0c\u8de8\u7279\u5f81\u6ce8\u610f\u529b\u5c42\u5efa\u6a21\u8fd9\u4e9b\u65f6\u95f4\u70b9\u7279\u5f81\u5bf9\u540e\u7eed\u7279\u5f81\u7684\u5b9a\u5411\u5f71\u54cd\uff0c\u6784\u5efa\u53ef\u8ffd\u6eaf\u7684\u5f71\u54cd\u8def\u5f84\u56fe\u3002", "result": "\u5728MIMIC-IV\u6570\u636e\u96c6\u548c\u6162\u6027\u80be\u75c5\u961f\u5217\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cCoI\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u63ed\u793a\u5177\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u60a3\u8005\u7279\u5f02\u6027\u75be\u75c5\u8fdb\u5c55\u6a21\u5f0f\u3002", "conclusion": "CoI\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u66f4\u91cd\u8981\u7684\u662f\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u900f\u660e\u5ea6\uff0c\u80fd\u591f\u8ffd\u8e2a\u4efb\u4f55\u7279\u5f81\u5728\u4efb\u4f55\u65f6\u95f4\u5bf9\u6700\u7ec8\u9884\u6d4b\u7684\u8d21\u732e\u8def\u5f84\uff0c\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u53ef\u89e3\u91ca\u4f9d\u636e\u3002"}}
{"id": "2510.09898", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09898", "abs": "https://arxiv.org/abs/2510.09898", "authors": ["Hung Phan", "Son Le Vu", "Ali Jannesari"], "title": "Learning Bug Context for PyTorch-to-JAX Translation with LLMs", "comment": null, "summary": "Despite recent progress of large language models (LLMs) on code translation\namong mainstream languages, translating PyTorch to JAX remains nontrivial. The\ntwo libraries, though both embedded in Python, differ in core design, execution\nsemantics, and ecosystem maturity; JAX is newer and comparatively\nunderrepresented in public code, and parallel PyTorch--JAX corpora are limited.\nWeaknesses in existing evaluation further complicate cross-framework\nbenchmarking. We present T2J, a prompt-augmentation framework that strengthens\nLLM-based PyTorch to JAX translation. Our pipeline (i) assembles two PyTorch\nsources -- the problem-solving set from TorchLeet (Aroori & Chien, 2025) and a\nGitHub-derived set from CodeParrot (Wolf et al., 2022) -- and uses GPT-4o-mini\nto produce initial JAX drafts; (ii) engages two professional developers to\niteratively repair those drafts until functional equivalence, yielding a\ncurated fixed-bug dataset of common errors and patches; and (iii) constructs\naugmented prompts that inject structured guidance from these fixes to steer\nlightweight LLMs (e.g., GPT-4o-mini). We also introduce three metrics tailored\nto PyTorch to JAX: T2J CodeTrans Score, T2J FixCost Score (an LLM-based\nestimate of bug-fix effort), and T2J Comparison Score (LLM-as-judge).\nEmpirically, T2J raises GPT-4o-mini performance by up to 10% on CodeBLEU, 50%\non T2J FixCost Score, 1.33 points on T2J CodeTrans Score (0--4 scale), and 100%\non T2J Comparison Score; moreover, the generated code runs up to 2.5x faster\nthan the baseline.", "AI": {"tldr": "T2J\u662f\u4e00\u4e2a\u901a\u8fc7\u63d0\u793a\u589e\u5f3a\u6846\u67b6\u6765\u6539\u8fdbLLM\u4ecePyTorch\u5230JAX\u4ee3\u7801\u7ffb\u8bd1\u6027\u80fd\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6784\u5efa\u4fee\u590d\u6570\u636e\u96c6\u548c\u7ed3\u6784\u5316\u6307\u5bfc\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "PyTorch\u548cJAX\u867d\u7136\u90fd\u5d4c\u5165\u5728Python\u4e2d\uff0c\u4f46\u5728\u6838\u5fc3\u8bbe\u8ba1\u3001\u6267\u884c\u8bed\u4e49\u548c\u751f\u6001\u7cfb\u7edf\u6210\u719f\u5ea6\u4e0a\u5b58\u5728\u5dee\u5f02\uff0cJAX\u8f83\u65b0\u4e14\u516c\u5f00\u4ee3\u7801\u8f83\u5c11\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5728\u8de8\u6846\u67b6\u57fa\u51c6\u6d4b\u8bd5\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u6784\u5efa\u5305\u542bTorchLeet\u548cGitHub\u4ee3\u7801\u7684\u6570\u636e\u96c6\uff0c\u4f7f\u7528GPT-4o-mini\u751f\u6210\u521d\u59cbJAX\u8349\u7a3f\uff0c\u7531\u4e13\u4e1a\u5f00\u53d1\u8005\u8fed\u4ee3\u4fee\u590d\u4ee5\u521b\u5efa\u4fee\u590d\u6570\u636e\u96c6\uff0c\u7136\u540e\u6784\u5efa\u5305\u542b\u7ed3\u6784\u5316\u6307\u5bfc\u7684\u589e\u5f3a\u63d0\u793a\u6765\u5f15\u5bfc\u8f7b\u91cf\u7ea7LLM\u3002", "result": "T2J\u5c06GPT-4o-mini\u5728CodeBLEU\u4e0a\u7684\u6027\u80fd\u63d0\u5347\u8fbe10%\uff0cT2J\u4fee\u590d\u6210\u672c\u5f97\u5206\u63d0\u534750%\uff0cT2J\u4ee3\u7801\u7ffb\u8bd1\u5f97\u5206\u63d0\u53471.33\u5206\uff080-4\u5206\u5236\uff09\uff0cT2J\u6bd4\u8f83\u5f97\u5206\u63d0\u5347100%\uff0c\u751f\u6210\u4ee3\u7801\u8fd0\u884c\u901f\u5ea6\u6bd4\u57fa\u7ebf\u5feb2.5\u500d\u3002", "conclusion": "T2J\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u63d0\u793a\u589e\u5f3a\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86PyTorch\u5230JAX\u4ee3\u7801\u7ffb\u8bd1\u7684\u6311\u6218\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u8d28\u91cf\u548c\u6548\u7387\uff0c\u4e3a\u8de8\u6846\u67b6\u4ee3\u7801\u7ffb\u8bd1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09904", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.09904", "abs": "https://arxiv.org/abs/2510.09904", "authors": ["Kelvin Kan", "Xingjian Li", "Benjamin J. Zhang", "Tuhin Sahai", "Stanley Osher", "Krishna Kumar", "Markos A. Katsoulakis"], "title": "Stability of Transformers under Layer Normalization", "comment": null, "summary": "Despite their widespread use, training deep Transformers can be unstable.\nLayer normalization, a standard component, improves training stability, but its\nplacement has often been ad-hoc. In this paper, we conduct a principled study\non the forward (hidden states) and backward (gradient) stability of\nTransformers under different layer normalization placements. Our theory\nprovides key insights into the training dynamics: whether training drives\nTransformers toward regular solutions or pathological behaviors. For forward\nstability, we derive explicit bounds on the growth of hidden states in trained\nTransformers. For backward stability, we analyze how layer normalization\naffects the backpropagation of gradients, thereby explaining the training\ndynamics of each layer normalization placement. Our analysis also guides the\nscaling of residual steps in Transformer blocks, where appropriate choices can\nfurther improve stability and performance. Our numerical results corroborate\nour theoretical findings. Beyond these results, our framework provides a\nprincipled way to sanity-check the stability of Transformers under new\narchitectural modifications, offering guidance for future designs.", "AI": {"tldr": "\u672c\u6587\u5bf9Transformer\u4e2dLayer Normalization\u7684\u4e0d\u540c\u653e\u7f6e\u4f4d\u7f6e\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u7814\u7a76\u4e86\u524d\u5411\uff08\u9690\u85cf\u72b6\u6001\uff09\u548c\u540e\u5411\uff08\u68af\u5ea6\uff09\u7a33\u5b9a\u6027\uff0c\u4e3a\u8bad\u7ec3\u52a8\u6001\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\u3002", "motivation": "\u5c3d\u7ba1Transformer\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u8bad\u7ec3\u53ef\u80fd\u4e0d\u7a33\u5b9a\u3002Layer Normalization\u4f5c\u4e3a\u6807\u51c6\u7ec4\u4ef6\u80fd\u6539\u5584\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u4f46\u5176\u653e\u7f6e\u4f4d\u7f6e\u5f80\u5f80\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u63a8\u5bfc\u4e86\u8bad\u7ec3\u540eTransformer\u9690\u85cf\u72b6\u6001\u589e\u957f\u7684\u524d\u5411\u7a33\u5b9a\u6027\u8fb9\u754c\uff0c\u4ee5\u53caLayer Normalization\u5982\u4f55\u5f71\u54cd\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u7684\u540e\u5411\u7a33\u5b9a\u6027\u3002\u8fd8\u6307\u5bfc\u4e86Transformer\u5757\u4e2d\u6b8b\u5dee\u6b65\u957f\u7684\u7f29\u653e\u9009\u62e9\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\uff0c\u8868\u660e\u9002\u5f53\u7684Layer Normalization\u653e\u7f6e\u548c\u6b8b\u5dee\u6b65\u957f\u7f29\u653e\u80fd\u8fdb\u4e00\u6b65\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u68c0\u67e5\u65b0\u67b6\u6784\u4fee\u6539\u4e0bTransformer\u7684\u7a33\u5b9a\u6027\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u4e3a\u672a\u6765\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2510.09914", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.09914", "abs": "https://arxiv.org/abs/2510.09914", "authors": ["Aditya Malusare", "Vineet Punyamoorty", "Vaneet Aggarwal"], "title": "Augmenting generative models with biomedical knowledge graphs improves targeted drug discovery", "comment": "This paper has been accepted for publication in the IEEE Transactions\n  on Artificial Intelligence, October 2025", "summary": "Recent breakthroughs in generative modeling have demonstrated remarkable\ncapabilities in molecular generation, yet the integration of comprehensive\nbiomedical knowledge into these models has remained an untapped frontier. In\nthis study, we introduce K-DREAM (Knowledge-Driven Embedding-Augmented Model),\na novel framework that leverages knowledge graphs to augment diffusion-based\ngenerative models for drug discovery. By embedding structured information from\nlarge-scale knowledge graphs, K-DREAM directs molecular generation toward\ncandidates with higher biological relevance and therapeutic suitability. This\nintegration ensures that the generated molecules are aligned with specific\ntherapeutic targets, moving beyond traditional heuristic-driven approaches. In\ntargeted drug design tasks, K-DREAM generates drug candidates with improved\nbinding affinities and predicted efficacy, surpassing current state-of-the-art\ngenerative models. It also demonstrates flexibility by producing molecules\ndesigned for multiple targets, enabling applications to complex disease\nmechanisms. These results highlight the utility of knowledge-enhanced\ngenerative models in rational drug design and their relevance to practical\ntherapeutic development.", "AI": {"tldr": "K-DREAM\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u6269\u6563\u751f\u6210\u6a21\u578b\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u836f\u7269\u53d1\u73b0\uff0c\u901a\u8fc7\u6574\u5408\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u751f\u6210\u5177\u6709\u66f4\u9ad8\u751f\u7269\u76f8\u5173\u6027\u548c\u6cbb\u7597\u9002\u7528\u6027\u7684\u5206\u5b50\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u5206\u5b50\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5168\u9762\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u7684\u6574\u5408\uff0c\u9650\u5236\u4e86\u751f\u6210\u5206\u5b50\u7684\u751f\u7269\u76f8\u5173\u6027\u548c\u6cbb\u7597\u6f5c\u529b\u3002", "method": "\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u7ed3\u6784\u5316\u4fe1\u606f\uff0c\u589e\u5f3a\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\uff0c\u4f7f\u5206\u5b50\u751f\u6210\u4e0e\u7279\u5b9a\u6cbb\u7597\u9776\u70b9\u5bf9\u9f50\uff0c\u8d85\u8d8a\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "\u5728\u9776\u5411\u836f\u7269\u8bbe\u8ba1\u4efb\u52a1\u4e2d\uff0cK-DREAM\u751f\u6210\u7684\u5019\u9009\u836f\u7269\u5177\u6709\u6539\u8fdb\u7684\u7ed3\u5408\u4eb2\u548c\u529b\u548c\u9884\u6d4b\u7597\u6548\uff0c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\uff0c\u5e76\u80fd\u8bbe\u8ba1\u9488\u5bf9\u591a\u4e2a\u9776\u70b9\u7684\u5206\u5b50\u3002", "conclusion": "\u77e5\u8bc6\u589e\u5f3a\u7684\u751f\u6210\u6a21\u578b\u5728\u5408\u7406\u836f\u7269\u8bbe\u8ba1\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u5bf9\u5b9e\u9645\u6cbb\u7597\u5f00\u53d1\u5177\u6709\u76f8\u5173\u6027\u3002"}}
{"id": "2510.09916", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09916", "abs": "https://arxiv.org/abs/2510.09916", "authors": ["Manuel Segura", "Pere Verg\u00e9s", "Richard Ky", "Ramesh Arangott", "Angela Kristine Garcia", "Thang Dihn Trong", "Makoto Hyodo", "Alexandru Nicolau", "Tony Givargis", "Sergio Gago-Masague"], "title": "Advancing Intoxication Detection: A Smartwatch-Based Approach", "comment": null, "summary": "Excess alcohol consumption leads to serious health risks and severe\nconsequences for both individuals and their communities. To advocate for\nhealthier drinking habits, we introduce a groundbreaking mobile smartwatch\napplication approach to just-in-time interventions for intoxication warnings.\nIn this work, we have created a dataset gathering TAC, accelerometer,\ngyroscope, and heart rate data from the participants during a period of three\nweeks. This is the first study to combine accelerometer, gyroscope, and heart\nrate smartwatch data collected over an extended monitoring period to classify\nintoxication levels. Previous research had used limited smartphone motion data\nand conventional machine learning (ML) algorithms to classify heavy drinking\nepisodes; in this work, we use smartwatch data and perform a thorough\nevaluation of different state-of-the-art classifiers such as the Transformer,\nBidirectional Long Short-Term Memory (bi-LSTM), Gated Recurrent Unit (GRU),\nOne-Dimensional Convolutional Neural Networks (1D-CNN), and Hyperdimensional\nComputing (HDC). We have compared performance metrics for the algorithms and\nassessed their efficiency on resource-constrained environments like mobile\nhardware. The HDC model achieved the best balance between accuracy and\nefficiency, demonstrating its practicality for smartwatch-based applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u624b\u8868\u7684\u79fb\u52a8\u5e94\u7528\u7a0b\u5e8f\uff0c\u7528\u4e8e\u5b9e\u65f6\u5e72\u9884\u9152\u7cbe\u4e2d\u6bd2\u8b66\u544a\u3002\u901a\u8fc7\u6536\u96c6\u4e09\u5468\u7684TAC\u3001\u52a0\u901f\u5ea6\u8ba1\u3001\u9640\u87ba\u4eea\u548c\u5fc3\u7387\u6570\u636e\uff0c\u9996\u6b21\u7ed3\u5408\u8fd9\u4e9b\u4f20\u611f\u5668\u6570\u636e\u6765\u5206\u7c7b\u4e2d\u6bd2\u6c34\u5e73\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd\u5148\u8fdb\u5206\u7c7b\u5668\u7684\u6027\u80fd\u3002", "motivation": "\u8fc7\u91cf\u996e\u9152\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u5065\u5eb7\u98ce\u9669\u548c\u4e2a\u4eba\u53ca\u793e\u533a\u7684\u4e25\u91cd\u540e\u679c\u3002\u4e3a\u4e86\u5021\u5bfc\u66f4\u5065\u5eb7\u7684\u996e\u9152\u4e60\u60ef\uff0c\u9700\u8981\u5f00\u53d1\u53ca\u65f6\u5e72\u9884\u7684\u9189\u9152\u8b66\u544a\u7cfb\u7edf\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542bTAC\u3001\u52a0\u901f\u5ea6\u8ba1\u3001\u9640\u87ba\u4eea\u548c\u5fc3\u7387\u6570\u636e\u7684\u6570\u636e\u5e93\uff0c\u6536\u96c6\u4e86\u4e09\u5468\u7684\u6570\u636e\u3002\u8bc4\u4f30\u4e86Transformer\u3001bi-LSTM\u3001GRU\u30011D-CNN\u548cHDC\u7b49\u591a\u79cd\u5148\u8fdb\u5206\u7c7b\u5668\uff0c\u5e76\u6bd4\u8f83\u4e86\u5b83\u4eec\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u6027\u80fd\u3002", "result": "HDC\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u57fa\u4e8e\u667a\u80fd\u624b\u8868\u7684\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8d85\u7ef4\u8ba1\u7b97\uff08HDC\uff09\u6a21\u578b\u6700\u9002\u5408\u7528\u4e8e\u667a\u80fd\u624b\u8868\u5e94\u7528\u7684\u9189\u9152\u68c0\u6d4b\uff0c\u56e0\u4e3a\u5b83\u63d0\u4f9b\u4e86\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7684\u6700\u4f73\u5e73\u8861\u3002"}}
{"id": "2510.09923", "categories": ["cs.LG", "math.OC", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09923", "abs": "https://arxiv.org/abs/2510.09923", "authors": ["Nikola Surjanovic", "Alexandre Bouchard-C\u00f4t\u00e9", "Trevor Campbell"], "title": "AutoGD: Automatic Learning Rate Selection for Gradient Descent", "comment": null, "summary": "The performance of gradient-based optimization methods, such as standard\ngradient descent (GD), greatly depends on the choice of learning rate. However,\nit can require a non-trivial amount of user tuning effort to select an\nappropriate learning rate schedule. When such methods appear as inner loops of\nother algorithms, expecting the user to tune the learning rates may be\nimpractical. To address this, we introduce AutoGD: a gradient descent method\nthat automatically determines whether to increase or decrease the learning rate\nat a given iteration. We establish the convergence of AutoGD, and show that we\ncan recover the optimal rate of GD (up to a constant) for a broad class of\nfunctions without knowledge of smoothness constants. Experiments on a variety\nof traditional problems and variational inference optimization tasks\ndemonstrate strong performance of the method, along with its extensions to\nAutoBFGS and AutoLBFGS.", "AI": {"tldr": "AutoGD\u662f\u4e00\u79cd\u81ea\u52a8\u8c03\u6574\u5b66\u4e60\u7387\u7684\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\uff0c\u65e0\u9700\u7528\u6237\u624b\u52a8\u8c03\u53c2\uff0c\u80fd\u591f\u81ea\u52a8\u5224\u65ad\u4f55\u65f6\u589e\u52a0\u6216\u51cf\u5c11\u5b66\u4e60\u7387\uff0c\u9002\u7528\u4e8e\u4f5c\u4e3a\u5176\u4ed6\u7b97\u6cd5\u7684\u5185\u5faa\u73af\u3002", "motivation": "\u4f20\u7edf\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u7684\u5b66\u4e60\u7387\u9009\u62e9\u9700\u8981\u5927\u91cf\u7528\u6237\u8c03\u53c2\u5de5\u4f5c\uff0c\u7279\u522b\u662f\u5728\u4f5c\u4e3a\u5176\u4ed6\u7b97\u6cd5\u5185\u5faa\u73af\u65f6\uff0c\u624b\u52a8\u8c03\u53c2\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u63d0\u51faAutoGD\u65b9\u6cd5\uff0c\u81ea\u52a8\u786e\u5b9a\u5728\u7ed9\u5b9a\u8fed\u4ee3\u4e2d\u662f\u5426\u589e\u52a0\u6216\u51cf\u5c11\u5b66\u4e60\u7387\uff0c\u65e0\u9700\u77e5\u9053\u5e73\u6ed1\u5ea6\u5e38\u6570\u3002", "result": "\u7406\u8bba\u8bc1\u660eAutoGD\u7684\u6536\u655b\u6027\uff0c\u80fd\u591f\u6062\u590dGD\u7684\u6700\u4f18\u901f\u7387\uff08\u8fbe\u5230\u5e38\u6570\u500d\uff09\uff0c\u5728\u4f20\u7edf\u95ee\u9898\u548c\u53d8\u5206\u63a8\u65ad\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "AutoGD\u53ca\u5176\u6269\u5c55AutoBFGS\u548cAutoLBFGS\u5728\u5404\u79cd\u4f18\u5316\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u5b66\u4e60\u7387\u81ea\u52a8\u8c03\u6574\u7684\u95ee\u9898\u3002"}}
{"id": "2510.09930", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09930", "abs": "https://arxiv.org/abs/2510.09930", "authors": ["Ching Chang", "Ming-Chih Lo", "Chiao-Tung Chan", "Wen-Chih Peng", "Tien-Fu Chen"], "title": "MemPromptTSS: Persistent Prompt Memory for Iterative Multi-Granularity Time Series State Segmentation", "comment": "This paper is currently under review. The code will be made available\n  upon acceptance", "summary": "Web platforms, mobile applications, and connected sensing systems generate\nmultivariate time series with states at multiple levels of granularity, from\ncoarse regimes to fine-grained events. Effective segmentation in these settings\nrequires integrating across granularities while supporting iterative refinement\nthrough sparse prompt signals, which provide a compact mechanism for injecting\ndomain knowledge. Yet existing prompting approaches for time series\nsegmentation operate only within local contexts, so the effect of a prompt\nquickly fades and cannot guide predictions across the entire sequence. To\novercome this limitation, we propose MemPromptTSS, a framework for iterative\nmulti-granularity segmentation that introduces persistent prompt memory. A\nmemory encoder transforms prompts and their surrounding subsequences into\nmemory tokens stored in a bank. This persistent memory enables each new\nprediction to condition not only on local cues but also on all prompts\naccumulated across iterations, ensuring their influence persists across the\nentire sequence. Experiments on six datasets covering wearable sensing and\nindustrial monitoring show that MemPromptTSS achieves 23% and 85% accuracy\nimprovements over the best baseline in single- and multi-granularity\nsegmentation under single iteration inference, and provides stronger refinement\nin iterative inference with average per-iteration gains of 2.66 percentage\npoints compared to 1.19 for PromptTSS. These results highlight the importance\nof persistent memory for prompt-guided segmentation, establishing MemPromptTSS\nas a practical and effective framework for real-world applications.", "AI": {"tldr": "MemPromptTSS\u662f\u4e00\u4e2a\u7528\u4e8e\u591a\u7c92\u5ea6\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u6301\u4e45\u63d0\u793a\u8bb0\u5fc6\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e2d\u63d0\u793a\u5f71\u54cd\u5feb\u901f\u8870\u51cf\u7684\u95ee\u9898\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u8bb0\u5fc6\u7f16\u7801\u5668\u5c06\u63d0\u793a\u53ca\u5176\u5468\u56f4\u5b50\u5e8f\u5217\u8f6c\u6362\u4e3a\u5b58\u50a8\u5728\u8bb0\u5fc6\u5e93\u4e2d\u7684\u8bb0\u5fc6\u4ee4\u724c\uff0c\u786e\u4fdd\u6240\u6709\u7d2f\u79ef\u63d0\u793a\u7684\u5f71\u54cd\u5728\u6574\u4e2a\u5e8f\u5217\u4e2d\u6301\u7eed\u5b58\u5728\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u63d0\u793a\u65b9\u6cd5\u4ec5\u5728\u5c40\u90e8\u4e0a\u4e0b\u6587\u4e2d\u64cd\u4f5c\uff0c\u5bfc\u81f4\u63d0\u793a\u7684\u5f71\u54cd\u5feb\u901f\u8870\u51cf\uff0c\u65e0\u6cd5\u5728\u6574\u4e2a\u5e8f\u5217\u4e2d\u6307\u5bfc\u9884\u6d4b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8de8\u6574\u4e2a\u5e8f\u5217\u4fdd\u6301\u63d0\u793a\u5f71\u54cd\u7684\u673a\u5236\u3002", "method": "\u63d0\u51faMemPromptTSS\u6846\u67b6\uff0c\u5f15\u5165\u6301\u4e45\u63d0\u793a\u8bb0\u5fc6\u3002\u4f7f\u7528\u8bb0\u5fc6\u7f16\u7801\u5668\u5c06\u63d0\u793a\u53ca\u5176\u5468\u56f4\u5b50\u5e8f\u5217\u8f6c\u6362\u4e3a\u8bb0\u5fc6\u4ee4\u724c\u5b58\u50a8\u5728\u8bb0\u5fc6\u5e93\u4e2d\uff0c\u4f7f\u6bcf\u4e2a\u65b0\u9884\u6d4b\u4e0d\u4ec5\u57fa\u4e8e\u5c40\u90e8\u7ebf\u7d22\uff0c\u8fd8\u57fa\u4e8e\u6240\u6709\u8fed\u4ee3\u4e2d\u7d2f\u79ef\u7684\u63d0\u793a\u3002", "result": "\u57286\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cMemPromptTSS\u5728\u5355\u6b21\u8fed\u4ee3\u63a8\u7406\u4e2d\u5355\u7c92\u5ea6\u548c\u591a\u7c92\u5ea6\u5206\u5272\u7684\u51c6\u786e\u7387\u5206\u522b\u6bd4\u6700\u4f73\u57fa\u7ebf\u63d0\u9ad823%\u548c85%\uff0c\u5728\u8fed\u4ee3\u63a8\u7406\u4e2d\u5e73\u5747\u6bcf\u6b21\u8fed\u4ee3\u589e\u76ca\u4e3a2.66\u4e2a\u767e\u5206\u70b9\uff0c\u800cPromptTSS\u4ec5\u4e3a1.19\u3002", "conclusion": "\u6301\u4e45\u8bb0\u5fc6\u5bf9\u4e8e\u63d0\u793a\u5f15\u5bfc\u7684\u5206\u5272\u81f3\u5173\u91cd\u8981\uff0cMemPromptTSS\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u6709\u6548\u7684\u6846\u67b6\u3002"}}
{"id": "2510.09942", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.09942", "abs": "https://arxiv.org/abs/2510.09942", "authors": ["Payel Bhattacharjee", "Fengwei Tian", "Meiyu Zhong", "Guangyi Zhang", "Osvaldo Simeone", "Ravi Tandon"], "title": "Conformal Sparsification for Bandwidth-Efficient Edge-Cloud Speculative Decoding", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop: AI and ML for Next-Generation Wireless Communications and\n  Networking (AI4NextG)", "summary": "Edge-cloud speculative decoding (SD) accelerates inference by having a\ncloud-based large language model (LLM) that verifies draft tokens generated by\na resource-constrained small language model (SLM) at the edge. A central\nbottleneck is the limited bandwidth of the edge-cloud link, which necessitates\nefficient compression of draft token distributions. We first derive an\ninformation-theoretic bound that decomposes the token rejection rate into\ncontributions from SLM-LLM distribution mismatch and from quantization\ndistortion. Guided by this analysis, we propose the Sparse Quantize-and-Sample\nSD (SQS-SD) framework, which exploits distributional sparsity through\nstructured sparsification and lattice-based quantization. Within this\nframework, K-SQS applies fixed top-K truncation, while C-SQS adaptively adjusts\nthe retained token set via online conformal prediction to ensure bounded\ndeviation from the dense distribution. Empirical results confirm that both\napproaches improve end-to-end latency and rejection rates in complimentary\noperating regimes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7a00\u758f\u91cf\u5316\u91c7\u6837\u8fb9\u7f18\u4e91\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7a00\u758f\u5316\u548c\u57fa\u4e8e\u683c\u70b9\u7684\u91cf\u5316\u6765\u538b\u7f29\u8349\u7a3f\u4ee4\u724c\u5206\u5e03\uff0c\u89e3\u51b3\u8fb9\u7f18-\u4e91\u94fe\u8def\u5e26\u5bbd\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u8fb9\u7f18\u4e91\u63a8\u6d4b\u89e3\u7801\u4e2d\uff0c\u8fb9\u7f18-\u4e91\u94fe\u8def\u7684\u6709\u9650\u5e26\u5bbd\u6210\u4e3a\u5173\u952e\u74f6\u9888\uff0c\u9700\u8981\u9ad8\u6548\u538b\u7f29\u8349\u7a3f\u4ee4\u724c\u5206\u5e03\u4ee5\u52a0\u901f\u63a8\u7406\u3002", "method": "\u63d0\u51faSQS-SD\u6846\u67b6\uff0c\u5229\u7528\u5206\u5e03\u7a00\u758f\u6027\u8fdb\u884c\u7ed3\u6784\u5316\u7a00\u758f\u5316\u548c\u683c\u70b9\u91cf\u5316\u3002\u5176\u4e2dK-SQS\u91c7\u7528\u56fa\u5b9atop-K\u622a\u65ad\uff0cC-SQS\u901a\u8fc7\u5728\u7ebf\u7b26\u5408\u9884\u6d4b\u81ea\u9002\u5e94\u8c03\u6574\u4fdd\u7559\u4ee4\u724c\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u4e24\u79cd\u65b9\u6cd5\u5728\u4e92\u8865\u7684\u64cd\u4f5c\u673a\u5236\u4e0b\u90fd\u80fd\u6539\u5584\u7aef\u5230\u7aef\u5ef6\u8fdf\u548c\u62d2\u7edd\u7387\u3002", "conclusion": "\u4fe1\u606f\u8bba\u5206\u6790\u63ed\u793a\u4e86\u4ee4\u724c\u62d2\u7edd\u7387\u7684\u5206\u89e3\uff0c\u6307\u5bfc\u63d0\u51fa\u7684\u7a00\u758f\u91cf\u5316\u91c7\u6837\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18\u4e91\u63a8\u6d4b\u89e3\u7801\u4e2d\u7684\u5e26\u5bbd\u9650\u5236\u95ee\u9898\u3002"}}
{"id": "2510.09959", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09959", "abs": "https://arxiv.org/abs/2510.09959", "authors": ["Jun Yin", "Runcheng Cai", "Shiliang Sun"], "title": "Clustering Result Re-guided Incomplete Multi-view Spectral Clustering", "comment": null, "summary": "Incomplete multi-view spectral clustering generalizes spectral clustering to\nmulti-view data and simultaneously realizes the partition of multi-view data\nwith missing views. For this category of method, K-means algorithm needs to be\nperformed to generate the clustering result after the procedure of feature\nextraction. More importantly, the connectivity of samples reflected by the\nclustering result is not utilized effectively. To overcome these defects, we\npropose Clustering Result re-Guided Incomplete Multi-view Spectral Clustering\n(CRG_IMSC). CRG_IMSC obtains the clustering result directly by imposing\nnonnegative constraint to the extracted feature. Furthermore, it constructs the\nconnectivity matrix according to the result of spectral clustering, and\nminimizes the residual of self-representation based on the connectivity matrix.\nA novel iterative algorithm using multiplicative update is developed to solve\nthe optimization problem of CRG_IMSC, and its convergence is proved rigorously.\nOn benchmark datasets, for multi-view data, CRG_IMSC performs better than\nstate-of-the-art clustering methods, and the experimental results also\ndemonstrate the convergence of CRG_IMSC algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCRG_IMSC\u7684\u4e0d\u5b8c\u6574\u591a\u89c6\u56fe\u8c31\u805a\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u65bd\u52a0\u975e\u8d1f\u7ea6\u675f\u76f4\u63a5\u83b7\u5f97\u805a\u7c7b\u7ed3\u679c\uff0c\u5e76\u5229\u7528\u805a\u7c7b\u7ed3\u679c\u6784\u5efa\u8fde\u901a\u6027\u77e9\u9635\u6765\u6539\u8fdb\u81ea\u8868\u793a\u6b8b\u5dee\u6700\u5c0f\u5316\u3002", "motivation": "\u4f20\u7edf\u4e0d\u5b8c\u6574\u591a\u89c6\u56fe\u8c31\u805a\u7c7b\u65b9\u6cd5\u5728\u7279\u5f81\u63d0\u53d6\u540e\u9700\u8981\u6267\u884cK-means\u7b97\u6cd5\u751f\u6210\u805a\u7c7b\u7ed3\u679c\uff0c\u4e14\u672a\u80fd\u6709\u6548\u5229\u7528\u6837\u672c\u8fde\u901a\u6027\u4fe1\u606f\u3002", "method": "CRG_IMSC\u901a\u8fc7\u5bf9\u63d0\u53d6\u7279\u5f81\u65bd\u52a0\u975e\u8d1f\u7ea6\u675f\u76f4\u63a5\u83b7\u5f97\u805a\u7c7b\u7ed3\u679c\uff0c\u6839\u636e\u8c31\u805a\u7c7b\u7ed3\u679c\u6784\u5efa\u8fde\u901a\u6027\u77e9\u9635\uff0c\u5e76\u57fa\u4e8e\u8be5\u77e9\u9635\u6700\u5c0f\u5316\u81ea\u8868\u793a\u6b8b\u5dee\u3002\u4f7f\u7528\u4e58\u6cd5\u66f4\u65b0\u8fed\u4ee3\u7b97\u6cd5\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cCRG_IMSC\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u4e5f\u8bc1\u660e\u4e86\u7b97\u6cd5\u7684\u6536\u655b\u6027\u3002", "conclusion": "CRG_IMSC\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4e0d\u5b8c\u6574\u591a\u89c6\u56fe\u8c31\u805a\u7c7b\u7684\u7f3a\u9677\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u805a\u7c7b\u6027\u80fd\u3002"}}
{"id": "2510.09965", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.09965", "abs": "https://arxiv.org/abs/2510.09965", "authors": ["Shuo Zhao", "Yongqiang Li", "Yu Feng", "Zhongsheng Hou", "Yuanjing Feng"], "title": "Homomorphic Mappings for Value-Preserving State Aggregation in Markov Decision Processes", "comment": null, "summary": "State aggregation aims to reduce the computational complexity of solving\nMarkov Decision Processes (MDPs) while preserving the performance of the\noriginal system. A fundamental challenge lies in optimizing policies within the\naggregated, or abstract, space such that the performance remains optimal in the\nground MDP-a property referred to as {\"}optimal policy equivalence {\"}.\n  This paper presents an abstraction framework based on the notion of\nhomomorphism, in which two Markov chains are deemed homomorphic if their value\nfunctions exhibit a linear relationship. Within this theoretical framework, we\nestablish a sufficient condition for the equivalence of optimal policy.\n  We further examine scenarios where the sufficient condition is not met and\nderive an upper bound on the approximation error and a performance lower bound\nfor the objective function under the ground MDP. We propose Homomorphic Policy\nGradient (HPG), which guarantees optimal policy equivalence under sufficient\nconditions, and its extension, Error-Bounded HPG (EBHPG), which balances\ncomputational efficiency and the performance loss induced by aggregation. In\nthe experiments, we validated the theoretical results and conducted comparative\nevaluations against seven algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u540c\u6001\u6982\u5ff5\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u72b6\u6001\u805a\u5408\u6846\u67b6\uff0c\u5efa\u7acb\u4e86\u6700\u4f18\u7b56\u7565\u7b49\u4ef7\u6027\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u4fdd\u8bc1\u6700\u4f18\u7b56\u7565\u7b49\u4ef7\u7684\u540c\u6001\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u53ca\u5176\u8bef\u5dee\u6709\u754c\u6269\u5c55\u7248\u672c\u3002", "motivation": "\u72b6\u6001\u805a\u5408\u65e8\u5728\u964d\u4f4e\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u59cb\u7cfb\u7edf\u7684\u6027\u80fd\u3002\u6838\u5fc3\u6311\u6218\u662f\u5728\u805a\u5408\u7a7a\u95f4\u4e2d\u4f18\u5316\u7b56\u7565\uff0c\u4f7f\u5176\u5728\u539f\u59cbMDP\u4e2d\u4ecd\u4fdd\u6301\u6700\u4f18\u6027\u80fd\uff0c\u5373\u6700\u4f18\u7b56\u7565\u7b49\u4ef7\u6027\u3002", "method": "\u57fa\u4e8e\u540c\u6001\u6982\u5ff5\u6784\u5efa\u62bd\u8c61\u6846\u67b6\uff0c\u5b9a\u4e49\u4e24\u4e2a\u9a6c\u5c14\u53ef\u592b\u94fe\u540c\u6001\u7684\u6761\u4ef6\u662f\u5b83\u4eec\u7684\u503c\u51fd\u6570\u5b58\u5728\u7ebf\u6027\u5173\u7cfb\u3002\u63d0\u51fa\u4e86\u540c\u6001\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u53ca\u5176\u8bef\u5dee\u6709\u754c\u6269\u5c55\u7248\u672cEBHPG\uff0c\u5728\u5145\u5206\u6761\u4ef6\u4e0b\u4fdd\u8bc1\u6700\u4f18\u7b56\u7565\u7b49\u4ef7\u3002", "result": "\u5efa\u7acb\u4e86\u6700\u4f18\u7b56\u7565\u7b49\u4ef7\u6027\u7684\u5145\u5206\u6761\u4ef6\uff0c\u63a8\u5bfc\u4e86\u5f53\u5145\u5206\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\u7684\u8fd1\u4f3c\u8bef\u5dee\u4e0a\u754c\u548c\u6027\u80fd\u4e0b\u754c\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u5e76\u4e0e\u4e03\u79cd\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u8bc4\u4f30\u3002", "conclusion": "\u63d0\u51fa\u7684\u540c\u6001\u62bd\u8c61\u6846\u67b6\u548c\u7b97\u6cd5\u80fd\u591f\u5728\u4fdd\u8bc1\u6700\u4f18\u7b56\u7565\u7b49\u4ef7\u6027\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0cEBHPG\u7248\u672c\u5728\u8ba1\u7b97\u6548\u7387\u548c\u805a\u5408\u5f15\u8d77\u7684\u6027\u80fd\u635f\u5931\u4e4b\u95f4\u5b9e\u73b0\u4e86\u5e73\u8861\u3002"}}
{"id": "2510.09977", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09977", "abs": "https://arxiv.org/abs/2510.09977", "authors": ["Frida Cantu", "Salomon Ibarra", "Arturo Gonzales", "Jesus Barreda", "Chenang Liu", "Li Zhang"], "title": "An Unsupervised Time Series Anomaly Detection Approach for Efficient Online Process Monitoring of Additive Manufacturing", "comment": "2025 IEEE 21st International Conference on Automation Science and\n  Engineering", "summary": "Online sensing plays an important role in advancing modern manufacturing. The\nreal-time sensor signals, which can be stored as high-resolution time series\ndata, contain rich information about the operation status. One of its popular\nusages is online process monitoring, which can be achieved by effective anomaly\ndetection from the sensor signals. However, most existing approaches either\nheavily rely on labeled data for training supervised models, or are designed to\ndetect only extreme outliers, thus are ineffective at identifying subtle\nsemantic off-track anomalies to capture where new regimes or unexpected\nroutines start. To address this challenge, we propose an matrix profile-based\nunsupervised anomaly detection algorithm that captures fabrication cycle\nsimilarity and performs semantic segmentation to precisely identify the onset\nof defect anomalies in additive manufacturing. The effectiveness of the\nproposed method is demonstrated by the experiments on real-world sensor data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e9\u9635\u8f6e\u5ed3\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u7ebf\u5236\u9020\u8fc7\u7a0b\u76d1\u63a7\uff0c\u80fd\u591f\u7cbe\u786e\u8bc6\u522b\u589e\u6750\u5236\u9020\u4e2d\u7f3a\u9677\u5f02\u5e38\u7684\u8d77\u59cb\u70b9\u3002", "motivation": "\u5728\u7ebf\u4f20\u611f\u5728\u73b0\u4ee3\u5236\u9020\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u76d1\u7763\u8bad\u7ec3\uff0c\u8981\u4e48\u53ea\u80fd\u68c0\u6d4b\u6781\u7aef\u5f02\u5e38\uff0c\u65e0\u6cd5\u6709\u6548\u8bc6\u522b\u7ec6\u5fae\u7684\u8bed\u4e49\u504f\u79bb\u5f02\u5e38\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u77e9\u9635\u8f6e\u5ed3\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\uff0c\u6355\u6349\u5236\u9020\u5468\u671f\u76f8\u4f3c\u6027\u5e76\u8fdb\u884c\u8bed\u4e49\u5206\u5272\u3002", "result": "\u5728\u771f\u5b9e\u4f20\u611f\u5668\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u7cbe\u786e\u8bc6\u522b\u5236\u9020\u8fc7\u7a0b\u4e2d\u7f3a\u9677\u5f02\u5e38\u7684\u8d77\u59cb\u70b9\uff0c\u4e3a\u5728\u7ebf\u8fc7\u7a0b\u76d1\u63a7\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10023", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10023", "abs": "https://arxiv.org/abs/2510.10023", "authors": ["Yinghui He", "Abhishek Panigrahi", "Yong Lin", "Sanjeev Arora"], "title": "Skill-Targeted Adaptive Training", "comment": null, "summary": "Language models often show little to no improvement (i.e., \"saturation\") when\ntrained via vanilla supervised fine-tuning (SFT) on data similar to what they\nsaw in their training set (e.g., MATH). We introduce a new fine-tuning\nstrategy, STAT, to train such a student model by using the metacognition\nability of a stronger large language model (LLM) as the teacher. The teacher\nuses the task dataset to create a list of skills needed for the task, and then\nlabels each data point with its required skills (Didolkar et al., 2024). By\nmonitoring the student's answers, the teacher creates a Missing-Skill-Profile\nfor the student, tracking how often they failed to apply each skill in their\nresponses. We use this idea to build a modified training set in one of two\nways. In STAT-Sel, the teacher uses an existing set of training examples but\nadaptively reweights them according to the Missing-Skill-Profile. In STAT-Syn,\nthe teacher synthesizes additional examples involving missing skills. Across\nextensive experiments on Llama and Qwen models, our methods yield improvements\nof up to 7.5% on MATH, whereas SFT provides only limited gains. Furthermore,\nSTAT enhances performance on out-of-distribution benchmarks (e.g., AIME24/25,\nAMC23, etc.) by an average of 4.6%. Crucially, we find that STAT is\ncomplementary to RL via GRPO (Shao et al., 2024): after the model is improved\nusing STAT to address skill gaps, GRPO continues to add further gains. We\nconclude that skill-targeted adaptive training should broadly improve current\ntraining pipelines. Our code is available at:\nhttps://github.com/princeton-pli/STAT.", "AI": {"tldr": "STAT\u662f\u4e00\u79cd\u65b0\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u5229\u7528\u66f4\u5f3aLLM\u7684\u5143\u8ba4\u77e5\u80fd\u529b\u4f5c\u4e3a\u6559\u5e08\uff0c\u901a\u8fc7\u8bc6\u522b\u5b66\u751f\u6a21\u578b\u7684\u7f3a\u5931\u6280\u80fd\u5e76\u9488\u5bf9\u6027\u8c03\u6574\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5728MATH\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u9ad8\u8fbe7.5%\u7684\u6539\u8fdb\u3002", "motivation": "\u4f20\u7edf\u76d1\u7763\u5fae\u8c03\u5728\u8bad\u7ec3\u6570\u636e\u4e0e\u9884\u8bad\u7ec3\u6570\u636e\u76f8\u4f3c\u65f6\uff08\u5982MATH\u6570\u636e\u96c6\uff09\u5f80\u5f80\u6548\u679c\u6709\u9650\uff0c\u5b58\u5728\"\u9971\u548c\"\u73b0\u8c61\uff0c\u9700\u8981\u65b0\u7684\u8bad\u7ec3\u7b56\u7565\u6765\u7a81\u7834\u8fd9\u4e00\u74f6\u9888\u3002", "method": "STAT\u65b9\u6cd5\u4f7f\u7528\u5f3aLLM\u6559\u5e08\u8bc6\u522b\u4efb\u52a1\u6240\u9700\u6280\u80fd\u5e76\u6807\u8bb0\u6570\u636e\u70b9\uff0c\u901a\u8fc7\u76d1\u63a7\u5b66\u751f\u56de\u7b54\u521b\u5efa\u7f3a\u5931\u6280\u80fd\u6863\u6848\uff0c\u91c7\u7528\u4e24\u79cd\u65b9\u5f0f\u6784\u5efa\u8bad\u7ec3\u96c6\uff1aSTAT-Sel\u6839\u636e\u7f3a\u5931\u6280\u80fd\u6863\u6848\u81ea\u9002\u5e94\u91cd\u52a0\u6743\u73b0\u6709\u8bad\u7ec3\u6837\u672c\uff0cSTAT-Syn\u5408\u6210\u6d89\u53ca\u7f3a\u5931\u6280\u80fd\u7684\u65b0\u793a\u4f8b\u3002", "result": "\u5728Llama\u548cQwen\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0cSTAT\u5728MATH\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u9ad8\u8fbe7.5%\u7684\u6539\u8fdb\uff0c\u800c\u4f20\u7edfSFT\u4ec5\u63d0\u4f9b\u6709\u9650\u589e\u76ca\u3002\u6b64\u5916\uff0cSTAT\u5728\u5206\u5e03\u5916\u57fa\u51c6\uff08AIME24/25\u3001AMC23\u7b49\uff09\u4e0a\u5e73\u5747\u63d0\u53474.6%\uff0c\u4e14\u4e0eGRPO\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e92\u8865\u3002", "conclusion": "\u6280\u80fd\u5bfc\u5411\u7684\u81ea\u9002\u5e94\u8bad\u7ec3\u5e94\u5e7f\u6cdb\u6539\u8fdb\u5f53\u524d\u8bad\u7ec3\u6d41\u7a0b\uff0cSTAT\u65b9\u6cd5\u4e3a\u89e3\u51b3\u6a21\u578b\u6280\u80fd\u7f3a\u5931\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2510.10041", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10041", "abs": "https://arxiv.org/abs/2510.10041", "authors": ["Sahng-Min Han", "Minjae Kim", "Jinho Cha", "Se-woon Choe", "Eunchan Daniel Cha", "Jungwon Choi", "Kyudong Jung"], "title": "FOSSIL: Regret-Minimizing Curriculum Learning for Metadata-Free and Low-Data Mpox Diagnosis", "comment": "35 pages, 11 figures, submitted to Computers in Biology and Medicine\n  (Elsevier, under review)", "summary": "Deep learning in small and imbalanced biomedical datasets remains\nfundamentally constrained by unstable optimization and poor generalization. We\npresent the first biomedical implementation of FOSSIL (Flexible Optimization\nvia Sample-Sensitive Importance Learning), a regret-minimizing weighting\nframework that adaptively balances training emphasis according to sample\ndifficulty. Using softmax-based uncertainty as a continuous measure of\ndifficulty, we construct a four-stage curriculum (Easy-Very Hard) and integrate\nFOSSIL into both convolutional and transformer-based architectures for Mpox\nskin lesion diagnosis. Across all settings, FOSSIL substantially improves\ndiscrimination (AUC = 0.9573), calibration (ECE = 0.053), and robustness under\nreal-world perturbations, outperforming conventional baselines without\nmetadata, manual curation, or synthetic augmentation. The results position\nFOSSIL as a generalizable, data-efficient, and interpretable framework for\ndifficulty-aware learning in medical imaging under data scarcity.", "AI": {"tldr": "FOSSIL\u662f\u4e00\u79cd\u57fa\u4e8e\u9057\u61be\u6700\u5c0f\u5316\u7684\u52a0\u6743\u6846\u67b6\uff0c\u901a\u8fc7\u6837\u672c\u96be\u5ea6\u81ea\u9002\u5e94\u5e73\u8861\u8bad\u7ec3\u91cd\u70b9\uff0c\u5728\u5c0f\u89c4\u6a21\u4e0d\u5e73\u8861\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u4e2d\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5c0f\u89c4\u6a21\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u751f\u7269\u533b\u5b66\u6570\u636e\u96c6\u4e2d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4f18\u5316\u4e0d\u7a33\u5b9a\u548c\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u57fa\u4e8esoftmax\u7684\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u8fde\u7eed\u96be\u5ea6\u5ea6\u91cf\uff0c\u6784\u5efa\u56db\u9636\u6bb5\u8bfe\u7a0b\uff08\u7b80\u5355-\u975e\u5e38\u56f0\u96be\uff09\uff0c\u5c06FOSSIL\u96c6\u6210\u5230\u5377\u79ef\u548c\u57fa\u4e8etransformer\u7684\u67b6\u6784\u4e2d\u7528\u4e8eMpox\u76ae\u80a4\u75c5\u53d8\u8bca\u65ad\u3002", "result": "\u5728\u6240\u6709\u8bbe\u7f6e\u4e0b\uff0cFOSSIL\u663e\u8457\u6539\u5584\u4e86\u533a\u5206\u80fd\u529b\uff08AUC = 0.9573\uff09\u3001\u6821\u51c6\uff08ECE = 0.053\uff09\u4ee5\u53ca\u5728\u771f\u5b9e\u4e16\u754c\u6270\u52a8\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FOSSIL\u662f\u4e00\u4e2a\u53ef\u6cdb\u5316\u3001\u6570\u636e\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u533b\u5b66\u5f71\u50cf\u4e2d\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u7684\u96be\u5ea6\u611f\u77e5\u5b66\u4e60\u3002"}}
{"id": "2510.10057", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10057", "abs": "https://arxiv.org/abs/2510.10057", "authors": ["Lei Gao", "Shihong Huang", "Shengjie Wang", "Hong Ma", "Feng Zhang", "Hengda Bao", "Qichang Chen", "Weihua Zhou"], "title": "One4Many-StablePacker: An Efficient Deep Reinforcement Learning Framework for the 3D Bin Packing Problem", "comment": null, "summary": "The three-dimensional bin packing problem (3D-BPP) is widely applied in\nlogistics and warehousing. Existing learning-based approaches often neglect\npractical stability-related constraints and exhibit limitations in generalizing\nacross diverse bin dimensions. To address these limitations, we propose a novel\ndeep reinforcement learning framework, One4Many-StablePacker (O4M-SP). The\nprimary advantage of O4M-SP is its ability to handle various bin dimensions in\na single training process while incorporating support and weight constraints\ncommon in practice. Our training method introduces two innovative mechanisms.\nFirst, it employs a weighted reward function that integrates loading rate and a\nnew height difference metric for packing layouts, promoting improved bin\nutilization through flatter packing configurations. Second, it combines clipped\npolicy gradient optimization with a tailored policy drifting method to mitigate\npolicy entropy collapse, encouraging exploration at critical decision nodes\nduring packing to avoid suboptimal solutions. Extensive experiments demonstrate\nthat O4M-SP generalizes successfully across diverse bin dimensions and\nsignificantly outperforms baseline methods. Furthermore, O4M-SP exhibits strong\npractical applicability by effectively addressing packing scenarios with\nstability constraints.", "AI": {"tldr": "\u63d0\u51faOne4Many-StablePacker (O4M-SP)\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3\u4e09\u7ef4\u88c5\u7bb1\u95ee\u9898\uff0c\u80fd\u591f\u5904\u7406\u591a\u79cd\u7bb1\u5b50\u5c3a\u5bf8\u5e76\u8003\u8651\u5b9e\u9645\u7a33\u5b9a\u6027\u7ea6\u675f\u3002", "motivation": "\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u5ffd\u7565\u5b9e\u9645\u7a33\u5b9a\u6027\u7ea6\u675f\uff0c\u4e14\u5728\u4e0d\u540c\u7bb1\u5b50\u5c3a\u5bf8\u95f4\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u540c\u65f6\u5904\u7406\u591a\u79cd\u7bb1\u5b50\u5c3a\u5bf8\u5e76\u8003\u8651\u652f\u6491\u548c\u91cd\u91cf\u7ea6\u675f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u52a0\u6743\u5956\u52b1\u51fd\u6570\u6574\u5408\u88c5\u8f7d\u7387\u548c\u9ad8\u5ea6\u5dee\u6307\u6807\uff0c\u7ed3\u5408\u88c1\u526a\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u548c\u5b9a\u5236\u7b56\u7565\u6f02\u79fb\u65b9\u6cd5\uff0c\u9632\u6b62\u7b56\u7565\u71b5\u5d29\u6e83\u5e76\u4fc3\u8fdb\u63a2\u7d22\u3002", "result": "\u5b9e\u9a8c\u8868\u660eO4M-SP\u5728\u4e0d\u540c\u7bb1\u5b50\u5c3a\u5bf8\u95f4\u6210\u529f\u6cdb\u5316\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u6709\u6548\u5904\u7406\u5e26\u7a33\u5b9a\u6027\u7ea6\u675f\u7684\u88c5\u7bb1\u573a\u666f\u3002", "conclusion": "O4M-SP\u6846\u67b6\u5728\u4e09\u7ef4\u88c5\u7bb1\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u9002\u7528\u6027\uff0c\u4e3a\u7269\u6d41\u4ed3\u50a8\u4e2d\u7684\u88c5\u7bb1\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10060", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.10060", "abs": "https://arxiv.org/abs/2510.10060", "authors": ["Hehe Fan", "Yi Yang", "Mohan Kankanhalli", "Fei Wu"], "title": "Translution: Unifying Self-attention and Convolution for Adaptive and Relative Modeling", "comment": "technical report", "summary": "When modeling a given type of data, we consider it to involve two key\naspects: 1) identifying relevant elements (e.g., image pixels or textual words)\nto a central element, as in a convolutional receptive field, or to a query\nelement, as in self-attention, and 2) encoding these tokens effectively.\nSelf-attention can adaptively identify these elements but relies on absolute\npositional embedding for structural representation learning. In contrast,\nconvolution encodes elements in a relative manner, yet their fixed kernel size\nlimits their ability to adaptively select the relevant elements. In this paper,\nwe introduce Translution, an operation that unifies the adaptive identification\ncapability of self-attention and the relative encoding advantage of\nconvolution. However, this integration leads to a substantial increase in the\nnumber of parameters, exceeding most currently available computational\nresources. Therefore, we propose a lightweight variant of Translution, named\n{\\alpha}-Translution. Experiments on computer vision and natural language\nprocessing tasks show that Translution (including {\\alpha}-Translution)\nachieves superior accuracy compared to self-attention. The code is available at\nhttps://github.com/hehefan/Translution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Translution\u64cd\u4f5c\uff0c\u7edf\u4e00\u4e86\u81ea\u6ce8\u610f\u529b\u7684\u81ea\u9002\u5e94\u8bc6\u522b\u80fd\u529b\u548c\u5377\u79ef\u7684\u76f8\u5bf9\u7f16\u7801\u4f18\u52bf\uff0c\u5e76\u63d0\u51fa\u4e86\u8f7b\u91cf\u7ea7\u53d8\u4f53\u03b1-Translution\uff0c\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u81ea\u6ce8\u610f\u529b\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u81ea\u6ce8\u610f\u529b\u867d\u7136\u80fd\u81ea\u9002\u5e94\u8bc6\u522b\u76f8\u5173\u5143\u7d20\uff0c\u4f46\u4f9d\u8d56\u7edd\u5bf9\u4f4d\u7f6e\u5d4c\u5165\u8fdb\u884c\u7ed3\u6784\u8868\u793a\u5b66\u4e60\uff1b\u5377\u79ef\u80fd\u4ee5\u76f8\u5bf9\u65b9\u5f0f\u7f16\u7801\u5143\u7d20\uff0c\u4f46\u56fa\u5b9a\u6838\u5927\u5c0f\u9650\u5236\u4e86\u5176\u81ea\u9002\u5e94\u9009\u62e9\u76f8\u5173\u5143\u7d20\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u7edf\u4e00\u4e24\u79cd\u4f18\u52bf\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faTranslution\u64cd\u4f5c\uff0c\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u7684\u81ea\u9002\u5e94\u8bc6\u522b\u80fd\u529b\u548c\u5377\u79ef\u7684\u76f8\u5bf9\u7f16\u7801\u4f18\u52bf\u3002\u7531\u4e8e\u53c2\u6570\u8fc7\u591a\uff0c\u8fdb\u4e00\u6b65\u63d0\u51fa\u8f7b\u91cf\u7ea7\u53d8\u4f53\u03b1-Translution\u3002", "result": "\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTranslution\uff08\u5305\u62ec\u03b1-Translution\uff09\u76f8\u6bd4\u81ea\u6ce8\u610f\u529b\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u3002", "conclusion": "Translution\u6210\u529f\u7edf\u4e00\u4e86\u81ea\u6ce8\u610f\u529b\u548c\u5377\u79ef\u7684\u4f18\u52bf\uff0c\u5728\u4fdd\u6301\u81ea\u9002\u5e94\u8bc6\u522b\u80fd\u529b\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u76f8\u5bf9\u7f16\u7801\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.10071", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10071", "abs": "https://arxiv.org/abs/2510.10071", "authors": ["Jinyang Zhang", "Yue Fang", "Hongxin Ding", "Weibin Liao", "Muyang Ye", "Xu Chu", "Junfeng Zhao", "Yasha Wang"], "title": "ADEPT: Continual Pretraining via Adaptive Expansion and Dynamic Decoupled Tuning", "comment": null, "summary": "Conventional continual pretraining (CPT) for large language model (LLM)\ndomain adaptation often suffers from catastrophic forgetting and limited domain\ncapacity. Existing strategies adopt layer expansion, introducing additional\ntrainable parameters to accommodate new knowledge. However, the uniform\nexpansion and updates still entangle general and domain learning, undermining\nits effectiveness. Our pilot studies reveal that LLMs exhibit functional\nspecialization, where layers and units differentially encode general-critical\ncapabilities, suggesting that parameter expansion and optimization should be\nfunction-aware. We then propose ADEPT, Adaptive Expansion and Dynamic Decoupled\nTuning for continual pretraining, a two-stage framework for domain-adaptive\nCPT. ADEPT first performs General-Competence Guided Selective Layer Expansion,\nduplicating layers least critical for the general domain to increase\nrepresentational capacity while minimizing interference with general knowledge.\nIt then applies Adaptive Unit-Wise Decoupled Tuning, disentangling parameter\nunits within expanded layers according to their general-domain importance and\nassigning asymmetric learning rates to balance knowledge injection and\nretention. Experiments on mathematical and medical benchmarks show that ADEPT\noutperforms full-parameter CPT by up to 5.76% on the general domain and 5.58%\non the target domain with only 15% of parameters tuned and less than 50%\ntraining time. Ablation studies, theoretical analysis, and extended\ninvestigations further demonstrate the necessity of targeted expansion and\ndecoupled optimization, providing new principles for efficient and robust\ndomain-adaptive CPT. Our code is open-sourced at\nhttps://github.com/PuppyKnightUniversity/ADEPT", "AI": {"tldr": "ADEPT\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u9884\u8bad\u7ec3\u7684\u81ea\u9002\u5e94\u6269\u5c55\u548c\u89e3\u8026\u8c03\u4f18\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5c42\u6269\u5c55\u548c\u5355\u5143\u7ea7\u89e3\u8026\u8c03\u4f18\uff0c\u5728\u4fdd\u6301\u901a\u7528\u80fd\u529b\u7684\u540c\u65f6\u6709\u6548\u9002\u5e94\u76ee\u6807\u9886\u57df\uff0c\u4ec5\u970015%\u53c2\u6570\u548c\u4e0d\u523050%\u8bad\u7ec3\u65f6\u95f4\u5373\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6301\u7eed\u9884\u8bad\u7ec3\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u548c\u9886\u57df\u5bb9\u91cf\u6709\u9650\u7684\u95ee\u9898\uff0c\u73b0\u6709\u5c42\u6269\u5c55\u7b56\u7565\u4ecd\u4f1a\u7ea0\u7f20\u901a\u7528\u548c\u9886\u57df\u5b66\u4e60\uff0c\u9700\u8981\u529f\u80fd\u611f\u77e5\u7684\u53c2\u6570\u6269\u5c55\u548c\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u901a\u7528\u80fd\u529b\u5f15\u5bfc\u7684\u9009\u62e9\u6027\u5c42\u6269\u5c55\uff0c\u590d\u5236\u5bf9\u901a\u7528\u9886\u57df\u6700\u4e0d\u5173\u952e\u7684\u5c42\uff1b2\uff09\u81ea\u9002\u5e94\u5355\u5143\u7ea7\u89e3\u8026\u8c03\u4f18\uff0c\u6839\u636e\u901a\u7528\u9886\u57df\u91cd\u8981\u6027\u5206\u79bb\u53c2\u6570\u5355\u5143\u5e76\u5206\u914d\u975e\u5bf9\u79f0\u5b66\u4e60\u7387\u3002", "result": "\u5728\u6570\u5b66\u548c\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cADEPT\u5728\u901a\u7528\u9886\u57df\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe5.76%\uff0c\u76ee\u6807\u9886\u57df\u63d0\u53475.58%\uff0c\u4ec5\u8c03\u4f1815%\u53c2\u6570\u4e14\u8bad\u7ec3\u65f6\u95f4\u4e0d\u523050%\u3002", "conclusion": "\u5b9a\u5411\u6269\u5c55\u548c\u89e3\u8026\u4f18\u5316\u662f\u9ad8\u6548\u7a33\u5065\u9886\u57df\u81ea\u9002\u5e94\u6301\u7eed\u9884\u8bad\u7ec3\u7684\u5fc5\u8981\u539f\u5219\uff0c\u4e3aLLM\u9886\u57df\u9002\u5e94\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.10089", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10089", "abs": "https://arxiv.org/abs/2510.10089", "authors": ["Zixuan Gong", "Jiaye Teng", "Yong Liu"], "title": "What Makes Looped Transformers Perform Better Than Non-Recursive Ones (Provably)", "comment": null, "summary": "While looped transformers (termed as Looped-Attn) often outperform standard\ntransformers (termed as Single-Attn) on complex reasoning tasks, the\ntheoretical basis for this advantage remains underexplored. In this paper, we\nexplain this phenomenon through the lens of loss landscape geometry, inspired\nby empirical observations of their distinct dynamics at both sample and Hessian\nlevels. To formalize this, we extend the River-Valley landscape model by\ndistinguishing between U-shaped valleys (flat) and V-shaped valleys (steep).\nBased on empirical observations, we conjecture that the recursive architecture\nof Looped-Attn induces a landscape-level inductive bias towards River-V-Valley.\nTheoretical derivations based on this inductive bias guarantee a better loss\nconvergence along the river due to valley hopping, and further encourage\nlearning about complex patterns compared to the River-U-Valley induced by\nSingle-Attn. Building on this insight, we propose SHIFT (Staged HIerarchical\nFramework for Progressive Training), a staged training framework that\naccelerates the training process of Looped-Attn while achieving comparable\nperformances.", "AI": {"tldr": "\u672c\u6587\u4ece\u635f\u5931\u51fd\u6570\u51e0\u4f55\u89d2\u5ea6\u89e3\u91ca\u4e86\u5faa\u73af\u6ce8\u610f\u529b\u673a\u5236\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6807\u51c6\u6ce8\u610f\u529b\u7684\u539f\u56e0\uff0c\u63d0\u51fa\u4e86River-Valley\u666f\u89c2\u6a21\u578b\u533a\u5206U\u578b\u548cV\u578b\u5c71\u8c37\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86SHIFT\u5206\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\u3002", "motivation": "\u5faa\u73af\u6ce8\u610f\u529b\u673a\u5236\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f46\u5176\u7406\u8bba\u4f18\u52bf\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u672c\u6587\u65e8\u5728\u4ece\u635f\u5931\u51fd\u6570\u51e0\u4f55\u89d2\u5ea6\u89e3\u91ca\u8fd9\u4e00\u73b0\u8c61\u3002", "method": "\u6269\u5c55River-Valley\u666f\u89c2\u6a21\u578b\uff0c\u533a\u5206U\u578b\u548cV\u578b\u5c71\u8c37\uff1b\u7406\u8bba\u63a8\u5bfc\u5faa\u73af\u6ce8\u610f\u529b\u673a\u5236\u7684\u666f\u89c2\u7ea7\u5f52\u7eb3\u504f\u7f6e\uff1b\u63d0\u51faSHIFT\u5206\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\u3002", "result": "\u5faa\u73af\u6ce8\u610f\u529b\u673a\u5236\u8bf1\u5bfc\u51faRiver-V-Valley\u666f\u89c2\uff0c\u76f8\u6bd4\u6807\u51c6\u6ce8\u610f\u529b\u7684River-U-Valley\u5177\u6709\u66f4\u597d\u7684\u635f\u5931\u6536\u655b\u6027\u548c\u590d\u6742\u6a21\u5f0f\u5b66\u4e60\u80fd\u529b\uff1bSHIFT\u6846\u67b6\u80fd\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\u5e76\u4fdd\u6301\u53ef\u6bd4\u6027\u80fd\u3002", "conclusion": "\u5faa\u73af\u6ce8\u610f\u529b\u673a\u5236\u901a\u8fc7\u666f\u89c2\u7ea7\u5f52\u7eb3\u504f\u7f6e\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5177\u6709\u7406\u8bba\u4f18\u52bf\uff0cSHIFT\u6846\u67b6\u4e3a\u9ad8\u6548\u8bad\u7ec3\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10116", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.10116", "abs": "https://arxiv.org/abs/2510.10116", "authors": ["Xing Wei", "Chunchun Chen", "Rui Fan", "Xiaofeng Cao", "Sourav Medya", "Wei Ye"], "title": "Preference-driven Knowledge Distillation for Few-shot Node Classification", "comment": "Accepted at NeurIPS 2025", "summary": "Graph neural networks (GNNs) can efficiently process text-attributed graphs\n(TAGs) due to their message-passing mechanisms, but their training heavily\nrelies on the human-annotated labels. Moreover, the complex and diverse local\ntopologies of nodes of real-world TAGs make it challenging for a single\nmechanism to handle. Large language models (LLMs) perform well in\nzero-/few-shot learning on TAGs but suffer from a scalability challenge.\nTherefore, we propose a preference-driven knowledge distillation (PKD)\nframework to synergize the complementary strengths of LLMs and various GNNs for\nfew-shot node classification. Specifically, we develop a GNN-preference-driven\nnode selector that effectively promotes prediction distillation from LLMs to\nteacher GNNs. To further tackle nodes' intricate local topologies, we develop a\nnode-preference-driven GNN selector that identifies the most suitable teacher\nGNN for each node, thereby facilitating tailored knowledge distillation from\nteacher GNNs to the student GNN. Extensive experiments validate the efficacy of\nour proposed framework in few-shot node classification on real-world TAGs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u504f\u597d\u9a71\u52a8\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u7ed3\u5408LLMs\u548cGNNs\u7684\u4f18\u52bf\u8fdb\u884c\u5c11\u6837\u672c\u8282\u70b9\u5206\u7c7b\uff0c\u901a\u8fc7GNN\u504f\u597d\u9a71\u52a8\u7684\u8282\u70b9\u9009\u62e9\u5668\u548c\u8282\u70b9\u504f\u597d\u9a71\u52a8\u7684GNN\u9009\u62e9\u5668\u5b9e\u73b0\u9ad8\u6548\u77e5\u8bc6\u84b8\u998f\u3002", "motivation": "GNNs\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6807\u7b7e\u4e14\u96be\u4ee5\u5904\u7406\u590d\u6742\u591a\u6837\u7684\u5c40\u90e8\u62d3\u6251\u7ed3\u6784\uff0cLLMs\u5728\u5c11\u6837\u672c\u5b66\u4e60\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u5b58\u5728\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u9700\u8981\u7ed3\u5408\u4e24\u8005\u7684\u4e92\u8865\u4f18\u52bf\u3002", "method": "\u5f00\u53d1\u4e86GNN\u504f\u597d\u9a71\u52a8\u7684\u8282\u70b9\u9009\u62e9\u5668\u4fc3\u8fdbLLMs\u5230\u6559\u5e08GNNs\u7684\u9884\u6d4b\u84b8\u998f\uff0c\u4ee5\u53ca\u8282\u70b9\u504f\u597d\u9a71\u52a8\u7684GNN\u9009\u62e9\u5668\u4e3a\u6bcf\u4e2a\u8282\u70b9\u8bc6\u522b\u6700\u5408\u9002\u7684\u6559\u5e08GNN\uff0c\u5b9e\u73b0\u4ece\u6559\u5e08GNNs\u5230\u5b66\u751fGNN\u7684\u5b9a\u5236\u5316\u77e5\u8bc6\u84b8\u998f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6587\u672c\u5c5e\u6027\u56fe\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u5c11\u6837\u672c\u8282\u70b9\u5206\u7c7b\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u504f\u597d\u9a71\u52a8\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86LLMs\u548cGNNs\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5c11\u6837\u672c\u8282\u70b9\u5206\u7c7b\u95ee\u9898\u3002"}}
{"id": "2510.10129", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10129", "abs": "https://arxiv.org/abs/2510.10129", "authors": ["Bin Yang", "Qiuyu Leng", "Jun Zeng", "Zhenhua Wu"], "title": "CacheClip: Accelerating RAG with Effective KV Cache Reuse", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems suffer from severe\ntime-to-first-token (TTFT) bottlenecks due to long input sequences. Existing KV\ncache reuse methods face a fundamental trade-off: prefix caching requires\nidentical prefixes that rarely occur in RAG scenarios, while direct\nprecomputation sacrifices quality due to missing inter-chunk attention and\nrepeated attention sinks. Recent methods like APE and CacheBlend partially\naddress these issues but remain inadequate for robust RAG applications. This\npaper presents CacheClip, a novel framework that achieves both fast TTFT and\nhigh generation quality. Our key insight is that small auxiliary LLMs exhibit\nsimilar last-layer attention distributions to primary LLMs (the target model\nfor generation), enabling efficient identification of tokens critical for\nrestoring inter-chunk attention, thereby significantly improving response\nquality on cross-chunk reasoning tasks. CacheClip integrates three techniques:\n(1) auxiliary-model-guided token selection for selective KV cache\nrecomputation, where the auxiliary model is finetuned to improve selection\naccuracy, (2) shared prefixes to eliminate redundant attention sinks, and (3)\ngrouping strategy to maintain local coherence during partial KV cache updates.\nExperiments show CacheClip retains up to 94.8% and 85.0% of full-attention\nperformance on NIAH and LongBench, outperforming APE and CacheBlend by 25.2%\nand 35.1% on NIAH (with reomp% = 20%). Meanwhile, CacheClip accelerates LLM\ninference by up to 1.92x in prefill time, providing a practical solution to the\nefficiency-quality trade-off in RAG systems.", "AI": {"tldr": "CacheClip\u662f\u4e00\u4e2a\u89e3\u51b3RAG\u7cfb\u7edf\u4e2dTTFT\u74f6\u9888\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8f85\u52a9LLM\u8bc6\u522b\u5173\u952etoken\u6765\u9009\u62e9\u6027\u91cd\u65b0\u8ba1\u7b97KV\u7f13\u5b58\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u52a0\u901f\u63a8\u7406\u3002", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u91cd\u7528\u65b9\u6cd5\u5728RAG\u573a\u666f\u4e2d\u5b58\u5728\u57fa\u672c\u6743\u8861\uff1a\u524d\u7f00\u7f13\u5b58\u9700\u8981\u76f8\u540c\u524d\u7f00\u4f46RAG\u4e2d\u5f88\u5c11\u51fa\u73b0\uff0c\u76f4\u63a5\u9884\u8ba1\u7b97\u56e0\u7f3a\u5c11\u8de8\u5757\u6ce8\u610f\u529b\u548c\u91cd\u590d\u6ce8\u610f\u529bsink\u800c\u727a\u7272\u8d28\u91cf\u3002APE\u548cCacheBlend\u7b49\u65b9\u6cd5\u4ecd\u4e0d\u8db3\u4ee5\u652f\u6301\u9c81\u68d2\u7684RAG\u5e94\u7528\u3002", "method": "CacheClip\u96c6\u6210\u4e09\u79cd\u6280\u672f\uff1a(1)\u8f85\u52a9\u6a21\u578b\u5f15\u5bfc\u7684token\u9009\u62e9\u7528\u4e8e\u9009\u62e9\u6027KV\u7f13\u5b58\u91cd\u65b0\u8ba1\u7b97\uff0c\u8f85\u52a9\u6a21\u578b\u7ecf\u8fc7\u5fae\u8c03\u4ee5\u63d0\u9ad8\u9009\u62e9\u51c6\u786e\u6027\uff1b(2)\u5171\u4eab\u524d\u7f00\u4ee5\u6d88\u9664\u5197\u4f59\u6ce8\u610f\u529bsink\uff1b(3)\u5206\u7ec4\u7b56\u7565\u5728\u90e8\u5206KV\u7f13\u5b58\u66f4\u65b0\u671f\u95f4\u4fdd\u6301\u5c40\u90e8\u8fde\u8d2f\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793aCacheClip\u5728NIAH\u548cLongBench\u4e0a\u5206\u522b\u4fdd\u6301\u9ad8\u8fbe94.8%\u548c85.0%\u7684\u5168\u6ce8\u610f\u529b\u6027\u80fd\uff0c\u5728NIAH\u4e0a\u6bd4APE\u548cCacheBlend\u5206\u522b\u9ad8\u51fa25.2%\u548c35.1%\uff08reomp%=20%\uff09\u3002\u540c\u65f6\uff0cCacheClip\u5c06LLM\u63a8\u7406\u7684\u9884\u586b\u5145\u65f6\u95f4\u52a0\u901f\u9ad8\u8fbe1.92\u500d\u3002", "conclusion": "CacheClip\u4e3aRAG\u7cfb\u7edf\u4e2d\u7684\u6548\u7387-\u8d28\u91cf\u6743\u8861\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u5feb\u901fTTFT\u548c\u9ad8\u751f\u6210\u8d28\u91cf\u7684\u5e73\u8861\u3002"}}
{"id": "2510.10136", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10136", "abs": "https://arxiv.org/abs/2510.10136", "authors": ["Lancheng Zou", "Shuo Yin", "Zehua Pei", "Tsung-Yi Ho", "Farzan Farnia", "Bei Yu"], "title": "PermLLM: Learnable Channel Permutation for N:M Sparse Large Language Models", "comment": "Accepted by NeurIPS 2025", "summary": "Channel permutation is a powerful technique for enhancing the accuracy of N:M\nsparse models by reordering the channels of weight matrices to prioritize the\nretention of important weights. However, traditional channel permutation\nmethods rely on handcrafted quality metrics, which often fail to accurately\ncapture the true impact of pruning on model performance. To address this\nlimitation, we propose PermLLM, a novel post-training pruning framework that\nintroduces learnable channel permutation (LCP) for N:M sparsity. LCP leverages\nSinkhorn normalization to transform discrete permutation matrices into\ndifferentiable soft permutation matrices, enabling end-to-end optimization.\nAdditionally, PermLLM incorporates an efficient block-wise channel permutation\nstrategy, which significantly reduces the number of learnable parameters and\ncomputational complexity. PermLLM seamlessly integrates with existing one-shot\npruning methods to adaptively optimize channel permutations, effectively\nmitigating pruning-induced errors. Extensive experiments on the LLaMA series,\nQwen, and OPT models demonstrate that PermLLM achieves superior performance in\noptimizing N:M sparse models. The code is available at\nhttps://github.com/lanchengzou/PermLLM.", "AI": {"tldr": "PermLLM\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u540e\u8bad\u7ec3\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u901a\u9053\u7f6e\u6362(LCP)\u6280\u672f\u6765\u4f18\u5316N:M\u7a00\u758f\u6a21\u578b\uff0c\u4f7f\u7528Sinkhorn\u5f52\u4e00\u5316\u5b9e\u73b0\u79bb\u6563\u7f6e\u6362\u77e9\u9635\u7684\u53ef\u5fae\u4f18\u5316\uff0c\u5e76\u7ed3\u5408\u5757\u7ea7\u901a\u9053\u7f6e\u6362\u7b56\u7565\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edf\u901a\u9053\u7f6e\u6362\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u8d28\u91cf\u6307\u6807\uff0c\u5f80\u5f80\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u526a\u679d\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u771f\u5b9e\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u53ef\u5b66\u4e60\u7684\u901a\u9053\u7f6e\u6362(LCP)\uff0c\u5229\u7528Sinkhorn\u5f52\u4e00\u5316\u5c06\u79bb\u6563\u7f6e\u6362\u77e9\u9635\u8f6c\u6362\u4e3a\u53ef\u5fae\u7684\u8f6f\u7f6e\u6362\u77e9\u9635\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u4f18\u5316\uff1b\u540c\u65f6\u5f15\u5165\u9ad8\u6548\u7684\u5757\u7ea7\u901a\u9053\u7f6e\u6362\u7b56\u7565\u51cf\u5c11\u53ef\u5b66\u4e60\u53c2\u6570\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u5728LLaMA\u7cfb\u5217\u3001Qwen\u548cOPT\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPermLLM\u5728\u4f18\u5316N:M\u7a00\u758f\u6a21\u578b\u65b9\u9762\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "PermLLM\u80fd\u591f\u81ea\u9002\u5e94\u4f18\u5316\u901a\u9053\u7f6e\u6362\uff0c\u6709\u6548\u7f13\u89e3\u526a\u679d\u5f15\u8d77\u7684\u8bef\u5dee\uff0c\u4e3aN:M\u7a00\u758f\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u4f18\u5316\u6846\u67b6\u3002"}}
{"id": "2510.10140", "categories": ["cs.LG", "cs.CR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10140", "abs": "https://arxiv.org/abs/2510.10140", "authors": ["Yue Deng", "Francisco Santos", "Pang-Ning Tan", "Lifeng Luo"], "title": "Adversarial Attacks on Downstream Weather Forecasting Models: Application to Tropical Cyclone Trajectory Prediction", "comment": null, "summary": "Deep learning based weather forecasting (DLWF) models leverage past weather\nobservations to generate future forecasts, supporting a wide range of\ndownstream tasks, including tropical cyclone (TC) trajectory prediction. In\nthis paper, we investigate their vulnerability to adversarial attacks, where\nsubtle perturbations to the upstream weather forecasts can alter the downstream\nTC trajectory predictions. Although research on adversarial attacks in DLWF\nmodels has grown recently, generating perturbed upstream forecasts that\nreliably steer downstream output toward attacker-specified trajectories remains\na challenge. First, conventional TC detection systems are opaque,\nnon-differentiable black boxes, making standard gradient-based attacks\ninfeasible. Second, the extreme rarity of TC events leads to severe class\nimbalance problem, making it difficult to develop efficient attack methods that\nwill produce the attacker's target trajectories. Furthermore, maintaining\nphysical consistency in adversarially generated forecasts presents another\nsignificant challenge. To overcome these limitations, we propose Cyc-Attack, a\nnovel method that perturbs the upstream forecasts of DLWF models to generate\nadversarial trajectories. First, we pre-train a differentiable surrogate model\nto approximate the TC detector's output, enabling the construction of\ngradient-based attacks. Cyc-Attack also employs skewness-aware loss function\nwith kernel dilation strategy to address the imbalance problem. Finally, a\ndistance-based gradient weighting scheme and regularization are used to\nconstrain the perturbations and eliminate spurious trajectories to ensure the\nadversarial forecasts are realistic and not easily detectable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCyc-Attack\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6270\u52a8\u6df1\u5ea6\u5b66\u4e60\u5929\u6c14\u9884\u62a5\u6a21\u578b\u7684\u4e0a\u6e38\u9884\u62a5\u6765\u751f\u6210\u5bf9\u6297\u6027\u70ed\u5e26\u6c14\u65cb\u8f68\u8ff9\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u653b\u51fb\u65b9\u6cd5\u9762\u4e34\u7684\u975e\u53ef\u5fae\u6027\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u7269\u7406\u4e00\u81f4\u6027\u7b49\u6311\u6218\u3002", "motivation": "\u7814\u7a76\u6df1\u5ea6\u5b66\u4e60\u5929\u6c14\u9884\u62a5\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u7279\u522b\u662f\u9488\u5bf9\u70ed\u5e26\u6c14\u65cb\u8f68\u8ff9\u9884\u6d4b\u7684\u4e0b\u6e38\u4efb\u52a1\u3002\u4f20\u7edf\u65b9\u6cd5\u7531\u4e8eTC\u68c0\u6d4b\u7cfb\u7edf\u7684\u4e0d\u900f\u660e\u6027\u548c\u975e\u53ef\u5fae\u6027\u3001TC\u4e8b\u4ef6\u7684\u6781\u7aef\u7a00\u6709\u6027\u5bfc\u81f4\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u4ee5\u53ca\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\u7684\u6311\u6218\uff0c\u96be\u4ee5\u751f\u6210\u53ef\u9760\u7684\u5bf9\u6297\u6027\u8f68\u8ff9\u3002", "method": "\u63d0\u51faCyc-Attack\u65b9\u6cd5\uff1a1\uff09\u9884\u8bad\u7ec3\u53ef\u5fae\u66ff\u4ee3\u6a21\u578b\u6765\u8fd1\u4f3cTC\u68c0\u6d4b\u5668\u8f93\u51fa\uff1b2\uff09\u4f7f\u7528\u504f\u5ea6\u611f\u77e5\u635f\u5931\u51fd\u6570\u548c\u6838\u81a8\u80c0\u7b56\u7565\u89e3\u51b3\u4e0d\u5e73\u8861\u95ee\u9898\uff1b3\uff09\u91c7\u7528\u57fa\u4e8e\u8ddd\u79bb\u7684\u68af\u5ea6\u52a0\u6743\u65b9\u6848\u548c\u6b63\u5219\u5316\u6765\u7ea6\u675f\u6270\u52a8\u5e76\u6d88\u9664\u865a\u5047\u8f68\u8ff9\uff0c\u786e\u4fdd\u5bf9\u6297\u6027\u9884\u62a5\u7684\u903c\u771f\u6027\u3002", "result": "Cyc-Attack\u80fd\u591f\u6210\u529f\u751f\u6210\u5bf9\u6297\u6027\u70ed\u5e26\u6c14\u65cb\u8f68\u8ff9\uff0c\u901a\u8fc7\u6270\u52a8\u4e0a\u6e38\u5929\u6c14\u9884\u62a5\u53ef\u9760\u5730\u5f15\u5bfc\u4e0b\u6e38\u8f93\u51fa\u671d\u5411\u653b\u51fb\u8005\u6307\u5b9a\u7684\u8f68\u8ff9\uff0c\u540c\u65f6\u4fdd\u6301\u7269\u7406\u4e00\u81f4\u6027\u4e14\u4e0d\u6613\u88ab\u68c0\u6d4b\u3002", "conclusion": "Cyc-Attack\u65b9\u6cd5\u6709\u6548\u514b\u670d\u4e86\u6df1\u5ea6\u5b66\u4e60\u5929\u6c14\u9884\u62a5\u6a21\u578b\u5bf9\u6297\u653b\u51fb\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u6c14\u8c61\u9884\u6d4b\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2510.10145", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10145", "abs": "https://arxiv.org/abs/2510.10145", "authors": ["Cheng He", "Xijie Liang", "Zengrong Zheng", "Patrick P. C. Lee", "Xu Huang", "Zhaoyi Li", "Hong Xie", "Defu Lian", "Enhong Chen"], "title": "A Unified Frequency Domain Decomposition Framework for Interpretable and Robust Time Series Forecasting", "comment": null, "summary": "Current approaches for time series forecasting, whether in the time or\nfrequency domain, predominantly use deep learning models based on linear layers\nor transformers. They often encode time series data in a black-box manner and\nrely on trial-and-error optimization solely based on forecasting performance,\nleading to limited interpretability and theoretical understanding. Furthermore,\nthe dynamics in data distribution over time and frequency domains pose a\ncritical challenge to accurate forecasting. We propose FIRE, a unified\nfrequency domain decomposition framework that provides a mathematical\nabstraction for diverse types of time series, so as to achieve interpretable\nand robust time series forecasting. FIRE introduces several key innovations:\n(i) independent modeling of amplitude and phase components, (ii) adaptive\nlearning of weights of frequency basis components, (iii) a targeted loss\nfunction, and (iv) a novel training paradigm for sparse data. Extensive\nexperiments demonstrate that FIRE consistently outperforms state-of-the-art\nmodels on long-term forecasting benchmarks, achieving superior predictive\nperformance and significantly enhancing interpretability of time series", "AI": {"tldr": "FIRE\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u9891\u57df\u5206\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u72ec\u7acb\u5efa\u6a21\u632f\u5e45\u548c\u76f8\u4f4d\u5206\u91cf\u3001\u81ea\u9002\u5e94\u5b66\u4e60\u9891\u7387\u57fa\u5206\u91cf\u6743\u91cd\u3001\u9488\u5bf9\u6027\u635f\u5931\u51fd\u6570\u548c\u7a00\u758f\u6570\u636e\u8bad\u7ec3\u8303\u5f0f\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u591a\u4e3a\u57fa\u4e8e\u7ebf\u6027\u5c42\u6216Transformer\u7684\u9ed1\u76d2\u6a21\u578b\uff0c\u4f9d\u8d56\u8bd5\u9519\u4f18\u5316\uff0c\u53ef\u89e3\u91ca\u6027\u548c\u7406\u8bba\u7406\u89e3\u6709\u9650\uff0c\u4e14\u6570\u636e\u5206\u5e03\u5728\u65f6\u57df\u548c\u9891\u57df\u7684\u52a8\u6001\u53d8\u5316\u5bf9\u51c6\u786e\u9884\u6d4b\u6784\u6210\u6311\u6218\u3002", "method": "\u63d0\u51faFIRE\u6846\u67b6\uff0c\u5728\u9891\u57df\u8fdb\u884c\u5206\u89e3\uff0c\u72ec\u7acb\u5efa\u6a21\u632f\u5e45\u548c\u76f8\u4f4d\uff0c\u81ea\u9002\u5e94\u5b66\u4e60\u9891\u7387\u57fa\u5206\u91cf\u6743\u91cd\uff0c\u4f7f\u7528\u9488\u5bf9\u6027\u635f\u5931\u51fd\u6570\uff0c\u5e76\u91c7\u7528\u65b0\u9896\u7684\u7a00\u758f\u6570\u636e\u8bad\u7ec3\u8303\u5f0f\u3002", "result": "\u5728\u957f\u671f\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFIRE\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u663e\u8457\u589e\u5f3a\u4e86\u65f6\u95f4\u5e8f\u5217\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "FIRE\u901a\u8fc7\u9891\u57df\u5206\u89e3\u7684\u6570\u5b66\u62bd\u8c61\uff0c\u4e3a\u4e0d\u540c\u7c7b\u578b\u65f6\u95f4\u5e8f\u5217\u63d0\u4f9b\u7edf\u4e00\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u5728\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2510.10149", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10149", "abs": "https://arxiv.org/abs/2510.10149", "authors": ["Xin Chen", "Gillian Dobbie", "Xinyu Wang", "Feng Liu", "Di Wang", "Jingfeng Zhang"], "title": "Robust Learning of Diffusion Models with Extremely Noisy Conditions", "comment": null, "summary": "Conditional diffusion models have the generative controllability by\nincorporating external conditions. However, their performance significantly\ndegrades with noisy conditions, such as corrupted labels in the image\ngeneration or unreliable observations or states in the control policy\ngeneration. This paper introduces a robust learning framework to address\nextremely noisy conditions in conditional diffusion models. We empirically\ndemonstrate that existing noise-robust methods fail when the noise level is\nhigh. To overcome this, we propose learning pseudo conditions as surrogates for\nclean conditions and refining pseudo ones progressively via the technique of\ntemporal ensembling. Additionally, we develop a Reverse-time Diffusion\nCondition (RDC) technique, which diffuses pseudo conditions to reinforce the\nmemorization effect and further facilitate the refinement of the pseudo\nconditions. Experimentally, our approach achieves state-of-the-art performance\nacross a range of noise levels on both class-conditional image generation and\nvisuomotor policy generation tasks.The code can be accessible via the project\npage https://robustdiffusionpolicy.github.io", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u9c81\u68d2\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4f2a\u6761\u4ef6\u5b66\u4e60\u548c\u65f6\u95f4\u96c6\u6210\u6280\u672f\u5904\u7406\u6781\u7aef\u566a\u58f0\u6761\u4ef6\uff0c\u5728\u56fe\u50cf\u751f\u6210\u548c\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u73b0\u6709\u566a\u58f0\u9c81\u68d2\u65b9\u6cd5\u5728\u9ad8\u566a\u58f0\u6c34\u5e73\u4e0b\u5931\u6548\uff0c\u9700\u8981\u89e3\u51b3\u6781\u7aef\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u751f\u6210\u53ef\u63a7\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5b66\u4e60\u4f2a\u6761\u4ef6\u4f5c\u4e3a\u5e72\u51c0\u6761\u4ef6\u7684\u66ff\u4ee3\uff0c\u901a\u8fc7\u65f6\u95f4\u96c6\u6210\u6280\u672f\u9010\u6b65\u4f18\u5316\u4f2a\u6761\u4ef6\uff0c\u5e76\u5f00\u53d1\u4e86\u53cd\u5411\u65f6\u95f4\u6269\u6563\u6761\u4ef6\uff08RDC\uff09\u6280\u672f\u6765\u589e\u5f3a\u8bb0\u5fc6\u6548\u5e94\u548c\u4fc3\u8fdb\u4f2a\u6761\u4ef6\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u56fe\u50cf\u751f\u6210\u548c\u89c6\u89c9\u8fd0\u52a8\u7b56\u7565\u751f\u6210\u4efb\u52a1\u7684\u5404\u79cd\u566a\u58f0\u6c34\u5e73\u4e0b\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u9c81\u68d2\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5728\u6781\u7aef\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\uff0c\u4e3a\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u53ef\u63a7\u751f\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10150", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10150", "abs": "https://arxiv.org/abs/2510.10150", "authors": ["Zhezheng Hao", "Hong Wang", "Haoyang Liu", "Jian Luo", "Jiarui Yu", "Hande Dong", "Qiang Lin", "Can Wang", "Jiawei Chen"], "title": "Rethinking Entropy Interventions in RLVR: An Entropy Change Perspective", "comment": null, "summary": "While Reinforcement Learning with Verifiable Rewards (RLVR) can enhance LLM\nreasoning, its training process poses a critical risk: entropy collapse. This\nphenomenon is a rapid loss of policy diversity, stemming from the\nexploration-exploitation imbalance and leading to a lack of generalization.\nRecent entropy-intervention methods aim to prevent \\coloredtext{entropy\ncollapse}, yet their underlying mechanisms remain unclear. In this paper, we\nconduct a quantitative analysis to reveal token-level entropy changes and how\nexisting entropy intervention methods help avoid entropy collapse. Our findings\npoint out a fundamental limitation of existing methods: they attempt to control\nentropy dynamics indirectly. By only affecting related factors, such as the\nadvantage signal and generation probability, their effectiveness is inherently\nlimited and could potentially fail. To address this limitation, we introduce an\nentropy-change-aware reweighting scheme, namely Stabilizing Token-level\nEntropy-changE via Reweighting (STEER), that adaptively stabilizes entropy\ndynamics through fine-grained token-level adjustments. Our approach mitigates\nover-exploitation while fostering robust exploration. Extensive experiments\ndemonstrate that STEER significantly mitigates entropy collapse, stabilizes\nentropy dynamics, and achieves stronger downstream performance across various\nmathematical reasoning benchmarks \\footnote{Our code is available at\nhttps://github.com/zz-haooo/STEER.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u8bad\u7ec3\u4e2d\u7684\u71b5\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u71b5\u53d8\u5316\u611f\u77e5\u91cd\u52a0\u6743\u65b9\u6cd5STEER\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684token\u7ea7\u8c03\u6574\u6765\u7a33\u5b9a\u71b5\u52a8\u6001\uff0c\u6709\u6548\u7f13\u89e3\u71b5\u5d29\u6e83\u5e76\u63d0\u5347\u6570\u5b66\u63a8\u7406\u6027\u80fd\u3002", "motivation": "RLVR\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b58\u5728\u71b5\u5d29\u6e83\u98ce\u9669\uff0c\u5373\u7b56\u7565\u591a\u6837\u6027\u5feb\u901f\u4e27\u5931\uff0c\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002\u73b0\u6709\u71b5\u5e72\u9884\u65b9\u6cd5\u673a\u5236\u4e0d\u660e\u786e\u4e14\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u76f4\u63a5\u6709\u6548\u7684\u71b5\u52a8\u6001\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSTEER\u65b9\u6cd5\uff0c\u901a\u8fc7\u71b5\u53d8\u5316\u611f\u77e5\u7684\u91cd\u52a0\u6743\u65b9\u6848\uff0c\u5728token\u7ea7\u522b\u8fdb\u884c\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u7a33\u5b9a\u71b5\u52a8\u6001\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSTEER\u663e\u8457\u7f13\u89e3\u4e86\u71b5\u5d29\u6e83\uff0c\u7a33\u5b9a\u4e86\u71b5\u52a8\u6001\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u66f4\u5f3a\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "STEER\u901a\u8fc7\u76f4\u63a5\u63a7\u5236token\u7ea7\u71b5\u53d8\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3aRLVR\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u548c\u6709\u6548\u7684\u71b5\u52a8\u6001\u7ba1\u7406\u65b9\u6848\u3002"}}
{"id": "2510.10188", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.10188", "abs": "https://arxiv.org/abs/2510.10188", "authors": ["Linfei Li", "Fengyi Zhang", "Zhong Wang", "Lin Zhang", "Ying Shen"], "title": "INR-Bench: A Unified Benchmark for Implicit Neural Representations in Multi-Domain Regression and Reconstruction", "comment": null, "summary": "Implicit Neural Representations (INRs) have gained success in various signal\nprocessing tasks due to their advantages of continuity and infinite resolution.\nHowever, the factors influencing their effectiveness and limitations remain\nunderexplored. To better understand these factors, we leverage insights from\nNeural Tangent Kernel (NTK) theory to analyze how model architectures (classic\nMLP and emerging KAN), positional encoding, and nonlinear primitives affect the\nresponse to signals of varying frequencies. Building on this analysis, we\nintroduce INR-Bench, the first comprehensive benchmark specifically designed\nfor multimodal INR tasks. It includes 56 variants of Coordinate-MLP models\n(featuring 4 types of positional encoding and 14 activation functions) and 22\nCoordinate-KAN models with distinct basis functions, evaluated across 9\nimplicit multimodal tasks. These tasks cover both forward and inverse problems,\noffering a robust platform to highlight the strengths and limitations of\ndifferent neural models, thereby establishing a solid foundation for future\nresearch. The code and dataset are available at\nhttps://github.com/lif314/INR-Bench.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86INR-Bench\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u4e13\u95e8\u4e3a\u591a\u6a21\u6001\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u4efb\u52a1\u8bbe\u8ba1\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u901a\u8fc7NTK\u7406\u8bba\u5206\u6790\u6a21\u578b\u67b6\u6784\u3001\u4f4d\u7f6e\u7f16\u7801\u548c\u975e\u7ebf\u6027\u57fa\u5143\u5bf9\u4fe1\u53f7\u9891\u7387\u54cd\u5e94\u7684\u5f71\u54cd\uff0c\u5e76\u8bc4\u4f30\u4e8656\u4e2aCoordinate-MLP\u53d8\u4f53\u548c22\u4e2aCoordinate-KAN\u6a21\u578b\u57289\u4e2a\u9690\u5f0f\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u5728\u5404\u79cd\u4fe1\u53f7\u5904\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5f71\u54cd\u5176\u6709\u6548\u6027\u548c\u9650\u5236\u7684\u56e0\u7d20\u4ecd\u672a\u5145\u5206\u63a2\u7d22\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u56e0\u7d20\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u6a21\u578b\u67b6\u6784\u3001\u4f4d\u7f6e\u7f16\u7801\u548c\u975e\u7ebf\u6027\u57fa\u5143\u5982\u4f55\u5f71\u54cd\u5bf9\u4e0d\u540c\u9891\u7387\u4fe1\u53f7\u7684\u54cd\u5e94\u3002", "method": "\u5229\u7528\u795e\u7ecf\u6b63\u5207\u6838\u7406\u8bba\u5206\u6790\u6a21\u578b\u67b6\u6784\uff08\u7ecf\u5178MLP\u548c\u65b0\u5174KAN\uff09\u3001\u4f4d\u7f6e\u7f16\u7801\u548c\u975e\u7ebf\u6027\u57fa\u5143\u5bf9\u4fe1\u53f7\u9891\u7387\u54cd\u5e94\u7684\u5f71\u54cd\uff0c\u5e76\u5f15\u5165INR-Bench\u57fa\u51c6\uff0c\u5305\u542b56\u4e2aCoordinate-MLP\u6a21\u578b\u53d8\u4f53\uff084\u79cd\u4f4d\u7f6e\u7f16\u7801\u548c14\u79cd\u6fc0\u6d3b\u51fd\u6570\uff09\u548c22\u4e2aCoordinate-KAN\u6a21\u578b\uff0c\u57289\u4e2a\u9690\u5f0f\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5efa\u7acb\u4e86\u7b2c\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u591a\u6a21\u6001INR\u4efb\u52a1\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u63d0\u4f9b\u4e86\u8bc4\u4f30\u4e0d\u540c\u795e\u7ecf\u6a21\u578b\u4f18\u52bf\u548c\u5c40\u9650\u6027\u7684\u7a33\u5065\u5e73\u53f0\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002", "conclusion": "INR-Bench\u57fa\u51c6\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u6a21\u578b\u67b6\u6784\u3001\u4f4d\u7f6e\u7f16\u7801\u548c\u975e\u7ebf\u6027\u57fa\u5143\u5bf9\u4fe1\u53f7\u9891\u7387\u54cd\u5e94\u7684\u5f71\u54cd\uff0c\u4e3a\u7406\u89e3\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u7684\u6709\u6548\u6027\u548c\u9650\u5236\u56e0\u7d20\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2510.10201", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.10201", "abs": "https://arxiv.org/abs/2510.10201", "authors": ["Jinghao Zhang", "Naishan Zheng", "Ruilin Li", "Dongzhou Cheng", "Zheming Liang", "Feng Zhao", "Jiaqi Wang"], "title": "RLFR: Extending Reinforcement Learning for LLMs with Flow Environment", "comment": "Project Website: https://jinghaoleven.github.io/RLFR/", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as\na promising framework for improving reasoning abilities in Large Language\nModels (LLMs). However, policy optimized with binary verification prone to\noverlook potential valuable exploration in reasoning trajectory. In view of\nheavy annotation cost of golden Process Reward Models (PRMs), recent works\nattempt using auxiliary signals for reward shaping of process tokens, involving\nentropy and likelihood collected from logit space. In this work, we offer a\nnovel perspective on shaping RLVR with flow rewards derived from latent space,\nand propose RLFR, where the flow fields of model latents are constructed from\neither off-policy high-quality data and on-policy rejection sampling data, and\nthe velocity deviations of policy latents within it are quantified to serve as\na reward signal. RLFR first demonstrates that a well-established flow field can\nbe a sound environment for reward signal collection, highlighting the\nexpressive latent space is much underexplored. Moreover, RLFR is able to\ncompress any off-policy expert data as reference for constituting reward\nsignals, and we show that the efficient context dependence compressed within\nthe hidden states are utilized, rather than individual token-level denotation\nfor context comprehending. Experiments on both language and multimodal\nreasoning benchmarks demonstrate the reliability of flow rewards, and\nsuggesting a promising paradigm for reward shaping with auxiliary signals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRLFR\u65b9\u6cd5\uff0c\u5229\u7528\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u6d41\u573a\u6784\u5efa\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u91cf\u5316\u7b56\u7565\u6f5c\u5728\u5728\u6d41\u573a\u4e2d\u7684\u901f\u5ea6\u504f\u5dee\u6765\u6539\u8fdb\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u4e8c\u5143\u9a8c\u8bc1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5bb9\u6613\u5ffd\u89c6\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u6709\u4ef7\u503c\u63a2\u7d22\uff0c\u800c\u6784\u5efa\u9ec4\u91d1\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u71b5\u548c\u4f3c\u7136\u5ea6\u7b49\u8f85\u52a9\u4fe1\u53f7\u8fdb\u884c\u5956\u52b1\u5851\u9020\uff0c\u4f46\u6f5c\u5728\u7a7a\u95f4\u7684\u8868\u8fbe\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "RLFR\u4ece\u79bb\u7b56\u7565\u9ad8\u8d28\u91cf\u6570\u636e\u6216\u5728\u7ebf\u62d2\u7edd\u91c7\u6837\u6570\u636e\u6784\u5efa\u6a21\u578b\u6f5c\u5728\u6d41\u573a\uff0c\u91cf\u5316\u7b56\u7565\u6f5c\u5728\u5728\u6d41\u573a\u4e2d\u7684\u901f\u5ea6\u504f\u5dee\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u538b\u7f29\u4efb\u4f55\u79bb\u7b56\u7565\u4e13\u5bb6\u6570\u636e\u4f5c\u4e3a\u53c2\u8003\uff0c\u5229\u7528\u9690\u85cf\u72b6\u6001\u4e2d\u7684\u9ad8\u6548\u4e0a\u4e0b\u6587\u4f9d\u8d56\u800c\u975e\u5355\u4e2a\u8bcd\u5143\u7ea7\u8868\u793a\u3002", "result": "\u5728\u8bed\u8a00\u548c\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u6d41\u5956\u52b1\u7684\u53ef\u9760\u6027\uff0c\u8868\u660e\u6d41\u573a\u53ef\u4ee5\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u6536\u96c6\u7684\u826f\u597d\u73af\u5883\u3002", "conclusion": "RLFR\u4e3a\u4f7f\u7528\u8f85\u52a9\u4fe1\u53f7\u8fdb\u884c\u5956\u52b1\u5851\u9020\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u8303\u5f0f\uff0c\u5c55\u793a\u4e86\u6f5c\u5728\u7a7a\u95f4\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u672a\u5f00\u53d1\u6f5c\u529b\u3002"}}
{"id": "2510.10232", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10232", "abs": "https://arxiv.org/abs/2510.10232", "authors": ["Xuening Wu", "Shenqin Yin", "Yanlan Kang", "Xinhang Zhang", "Qianya Xu", "Zeping Chen", "Wenqiang Zhang"], "title": "SGM: A Statistical Godel Machine for Risk-Controlled Recursive Self-Modification", "comment": null, "summary": "Recursive self-modification is increasingly central in AutoML, neural\narchitecture search, and adaptive optimization, yet no existing framework\nensures that such changes are made safely. Godel machines offer a principled\nsafeguard by requiring formal proofs of improvement before rewriting code;\nhowever, such proofs are unattainable in stochastic, high-dimensional settings.\nWe introduce the Statistical Godel Machine (SGM), the first statistical safety\nlayer for recursive edits. SGM replaces proof-based requirements with\nstatistical confidence tests (e-values, Hoeffding bounds), admitting a\nmodification only when superiority is certified at a chosen confidence level,\nwhile allocating a global error budget to bound cumulative risk across\nrounds.We also propose Confirm-Triggered Harmonic Spending (CTHS), which\nindexes spending by confirmation events rather than rounds, concentrating the\nerror budget on promising edits while preserving familywise\nvalidity.Experiments across supervised learning, reinforcement learning, and\nblack-box optimization validate this role: SGM certifies genuine gains on\nCIFAR-100, rejects spurious improvement on ImageNet-100, and demonstrates\nrobustness on RL and optimization benchmarks.Together, these results position\nSGM as foundational infrastructure for continual, risk-aware self-modification\nin learning systems.Code is available at:\nhttps://github.com/gravitywavelet/sgm-anon.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7edf\u8ba1\u54e5\u5fb7\u5c14\u673a\uff08SGM\uff09\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u9012\u5f52\u7f16\u8f91\u7684\u7edf\u8ba1\u5b89\u5168\u5c42\uff0c\u7528\u7edf\u8ba1\u7f6e\u4fe1\u5ea6\u6d4b\u8bd5\u66ff\u4ee3\u8bc1\u660e\u8981\u6c42\uff0c\u5728\u9009\u5b9a\u7f6e\u4fe1\u6c34\u5e73\u4e0b\u8ba4\u8bc1\u6539\u8fdb\u540e\u624d\u5141\u8bb8\u4fee\u6539\uff0c\u540c\u65f6\u5206\u914d\u5168\u5c40\u9519\u8bef\u9884\u7b97\u6765\u9650\u5236\u591a\u8f6e\u7d2f\u79ef\u98ce\u9669\u3002", "motivation": "\u9012\u5f52\u81ea\u4fee\u6539\u5728AutoML\u3001\u795e\u7ecf\u67b6\u6784\u641c\u7d22\u548c\u81ea\u9002\u5e94\u4f18\u5316\u4e2d\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u6846\u67b6\u65e0\u6cd5\u786e\u4fdd\u6b64\u7c7b\u66f4\u6539\u7684\u5b89\u5168\u6027\u3002\u54e5\u5fb7\u5c14\u673a\u901a\u8fc7\u8981\u6c42\u5f62\u5f0f\u5316\u6539\u8fdb\u8bc1\u660e\u6765\u63d0\u4f9b\u539f\u5219\u6027\u4fdd\u62a4\uff0c\u4f46\u5728\u968f\u673a\u9ad8\u7ef4\u73af\u5883\u4e2d\u6b64\u7c7b\u8bc1\u660e\u65e0\u6cd5\u83b7\u5f97\u3002", "method": "SGM\u7528\u7edf\u8ba1\u7f6e\u4fe1\u5ea6\u6d4b\u8bd5\uff08e\u503c\u3001Hoeffding\u754c\uff09\u66ff\u4ee3\u57fa\u4e8e\u8bc1\u660e\u7684\u8981\u6c42\uff0c\u53ea\u6709\u5f53\u5728\u9009\u5b9a\u7f6e\u4fe1\u6c34\u5e73\u4e0b\u8ba4\u8bc1\u4e86\u4f18\u8d8a\u6027\u65f6\u624d\u5141\u8bb8\u4fee\u6539\u3002\u540c\u65f6\u63d0\u51fa\u786e\u8ba4\u89e6\u53d1\u8c03\u548c\u652f\u51fa\uff08CTHS\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u786e\u8ba4\u4e8b\u4ef6\u800c\u975e\u8f6e\u6b21\u6765\u7d22\u5f15\u652f\u51fa\uff0c\u5c06\u9519\u8bef\u9884\u7b97\u96c6\u4e2d\u5728\u6709\u524d\u9014\u7684\u7f16\u8f91\u4e0a\u3002", "result": "\u5728\u76d1\u7763\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u9ed1\u76d2\u4f18\u5316\u7684\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86SGM\u7684\u4f5c\u7528\uff1a\u5728CIFAR-100\u4e0a\u8ba4\u8bc1\u4e86\u771f\u5b9e\u589e\u76ca\uff0c\u5728ImageNet-100\u4e0a\u62d2\u7edd\u4e86\u865a\u5047\u6539\u8fdb\uff0c\u5728RL\u548c\u4f18\u5316\u57fa\u51c6\u4e0a\u5c55\u793a\u4e86\u9c81\u68d2\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u786e\u7acb\u4e86SGM\u4f5c\u4e3a\u5b66\u4e60\u7cfb\u7edf\u4e2d\u6301\u7eed\u3001\u98ce\u9669\u611f\u77e5\u81ea\u4fee\u6539\u7684\u57fa\u7840\u8bbe\u65bd\u5730\u4f4d\u3002"}}
{"id": "2510.10262", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10262", "abs": "https://arxiv.org/abs/2510.10262", "authors": ["Jingwen Li", "Zhiguang Cao", "Yaoxin Wu", "Tang Liu"], "title": "Enhancing the Cross-Size Generalization for Solving Vehicle Routing Problems via Continual Learning", "comment": null, "summary": "Exploring machine learning techniques for addressing vehicle routing problems\nhas attracted considerable research attention. To achieve decent and efficient\nsolutions, existing deep models for vehicle routing problems are typically\ntrained and evaluated using instances of a single size. This substantially\nlimits their ability to generalize across different problem sizes and thus\nhampers their practical applicability. To address the issue, we propose a\ncontinual learning based framework that sequentially trains a deep model with\ninstances of ascending problem sizes. Specifically, on the one hand, we design\nan inter-task regularization scheme to retain the knowledge acquired from\nsmaller problem sizes in the model training on a larger size. On the other\nhand, we introduce an intra-task regularization scheme to consolidate the model\nby imitating the latest desirable behaviors during training on each size.\nAdditionally, we exploit the experience replay to revisit instances of formerly\ntrained sizes for mitigating the catastrophic forgetting. Experimental results\nshow that our approach achieves predominantly superior performance across\nvarious problem sizes (either seen or unseen in the training), as compared to\nstate-of-the-art deep models including the ones specialized for\ngeneralizability enhancement. Meanwhile, the ablation studies on the key\ndesigns manifest their synergistic effect in the proposed framework.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6301\u7eed\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6309\u95ee\u9898\u89c4\u6a21\u9012\u589e\u7684\u987a\u5e8f\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6765\u89e3\u51b3\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u901a\u5e38\u9488\u5bf9\u5355\u4e00\u89c4\u6a21\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u8fd9\u4e25\u91cd\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u95ee\u9898\u89c4\u6a21\u95f4\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u963b\u788d\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u6309\u95ee\u9898\u89c4\u6a21\u9012\u589e\u987a\u5e8f\u8bad\u7ec3\u6a21\u578b\uff1b\u8bbe\u8ba1\u4efb\u52a1\u95f4\u6b63\u5219\u5316\u65b9\u6848\u4fdd\u7559\u5c0f\u89c4\u6a21\u77e5\u8bc6\uff1b\u5f15\u5165\u4efb\u52a1\u5185\u6b63\u5219\u5316\u65b9\u6848\u6a21\u4eff\u6700\u65b0\u7406\u60f3\u884c\u4e3a\uff1b\u5229\u7528\u7ecf\u9a8c\u56de\u653e\u673a\u5236\u56de\u987e\u5df2\u8bad\u7ec3\u89c4\u6a21\u5b9e\u4f8b\u4ee5\u51cf\u8f7b\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u95ee\u9898\u89c4\u6a21\uff08\u5305\u62ec\u8bad\u7ec3\u4e2d\u672a\u89c1\u8fc7\u7684\u89c4\u6a21\uff09\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5305\u62ec\u4e13\u95e8\u7528\u4e8e\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u7684\u6a21\u578b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6\u901a\u8fc7\u4efb\u52a1\u95f4\u548c\u4efb\u52a1\u5185\u6b63\u5219\u5316\u4ee5\u53ca\u7ecf\u9a8c\u56de\u653e\u7684\u534f\u540c\u4f5c\u7528\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u4e0d\u540c\u89c4\u6a21\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.10276", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.10276", "abs": "https://arxiv.org/abs/2510.10276", "authors": ["Nikolaus Salvatore", "Hao Wang", "Qiong Zhang"], "title": "Lost in the Middle: An Emergent Property from Information Retrieval Demands in LLMs", "comment": null, "summary": "The performance of Large Language Models (LLMs) often degrades when crucial\ninformation is in the middle of a long context, a \"lost-in-the-middle\"\nphenomenon that mirrors the primacy and recency effects in human memory. We\npropose that this behavior is not simply a flaw indicative of information loss\nbut an adaptation to different information retrieval demands during\npre-training: some tasks require uniform recall across the entire input (a\nlong-term memory demand), while others prioritize the most recent information\n(a short-term memory demand). Consistent with this view, we show that this\nU-shaped performance curve emerges when LLMs (GPT-2 and Llama variants) are\ntrained from scratch on two simple human memory paradigms simulating long-term\nand short-term memory demands. Our analysis reveals that while the recency\neffect directly aligns with short-term memory demand in the training data, the\nprimacy effect is induced by the uniform long-term memory demand and is\nadditionally influenced by the model's autoregressive properties and the\nformation of attention sinks. Our main findings from simple human memory\nparadigms also generalize to a sequence completion task, which more closely\nresembles the next-token prediction process in LLM pre-training. Together, our\nfindings reveal how information retrieval demands, model architecture, and\nstructural attention dynamics during model training can jointly produce\npositional bias observed in LLMs.", "AI": {"tldr": "\u8bba\u6587\u53d1\u73b0LLMs\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u5b58\u5728'\u4e2d\u95f4\u4fe1\u606f\u4e22\u5931'\u73b0\u8c61\uff0c\u8fd9\u4e0e\u4eba\u7c7b\u8bb0\u5fc6\u7684\u9996\u56e0\u548c\u8fd1\u56e0\u6548\u5e94\u76f8\u4f3c\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e0d\u662f\u7b80\u5355\u7684\u4fe1\u606f\u4e22\u5931\u7f3a\u9677\uff0c\u800c\u662fLLMs\u9002\u5e94\u4e0d\u540c\u4fe1\u606f\u68c0\u7d22\u9700\u6c42\u7684\u8bad\u7ec3\u7ed3\u679c\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u957f\u6587\u672c\u5904\u7406\u4e2d\u8868\u73b0\u4e0b\u964d\u7684\u539f\u56e0\uff0c\u7279\u522b\u662f\u4fe1\u606f\u5728\u4e2d\u95f4\u4f4d\u7f6e\u65f6\u6027\u80fd\u4e0b\u964d\u7684\u73b0\u8c61\uff0c\u63a2\u7d22\u8fd9\u4e0e\u4eba\u7c7b\u8bb0\u5fc6\u6548\u5e94\u7684\u76f8\u4f3c\u6027\u53ca\u5176\u8bad\u7ec3\u673a\u5236\u6839\u6e90\u3002", "method": "\u4f7f\u7528GPT-2\u548cLlama\u53d8\u4f53\u4ece\u5934\u8bad\u7ec3\uff0c\u91c7\u7528\u6a21\u62df\u4eba\u7c7b\u957f\u671f\u548c\u77ed\u671f\u8bb0\u5fc6\u9700\u6c42\u7684\u7b80\u5355\u8bb0\u5fc6\u8303\u5f0f\uff0c\u5206\u6790\u4f4d\u7f6e\u504f\u5dee\u7684\u4ea7\u751f\u673a\u5236\u3002", "result": "\u53d1\u73b0U\u5f62\u6027\u80fd\u66f2\u7ebf\u786e\u5b9e\u5728\u8bad\u7ec3\u4e2d\u51fa\u73b0\uff0c\u8fd1\u56e0\u6548\u5e94\u4e0e\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u77ed\u671f\u8bb0\u5fc6\u9700\u6c42\u76f4\u63a5\u76f8\u5173\uff0c\u800c\u9996\u56e0\u6548\u5e94\u7531\u5747\u5300\u7684\u957f\u671f\u8bb0\u5fc6\u9700\u6c42\u8bf1\u5bfc\uff0c\u5e76\u53d7\u81ea\u56de\u5f52\u7279\u6027\u548c\u6ce8\u610f\u529b\u6c47\u805a\u70b9\u5f62\u6210\u7684\u5f71\u54cd\u3002", "conclusion": "\u4fe1\u606f\u68c0\u7d22\u9700\u6c42\u3001\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7ed3\u6784\u6ce8\u610f\u529b\u52a8\u6001\u5171\u540c\u5bfc\u81f4\u4e86LLMs\u4e2d\u89c2\u5bdf\u5230\u7684\u4f4d\u7f6e\u504f\u5dee\uff0c\u8fd9\u4e9b\u53d1\u73b0\u4ece\u7b80\u5355\u8bb0\u5fc6\u8303\u5f0f\u63a8\u5e7f\u5230\u4e86\u66f4\u63a5\u8fd1LLM\u9884\u8bad\u7ec3\u7684\u5e8f\u5217\u5b8c\u6210\u4efb\u52a1\u3002"}}
{"id": "2510.10374", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10374", "abs": "https://arxiv.org/abs/2510.10374", "authors": ["Ziyi Wei", "Huaiyang Zhong", "Xiaocheng Li"], "title": "Exploration-free Algorithms for Multi-group Mean Estimation", "comment": null, "summary": "We address the problem of multi-group mean estimation, which seeks to\nallocate a finite sampling budget across multiple groups to obtain uniformly\naccurate estimates of their means. Unlike classical multi-armed bandits, whose\nobjective is to minimize regret by identifying and exploiting the best arm, the\noptimal allocation in this setting requires sampling every group on the order\nof $\\Theta(T)$ times. This fundamental distinction makes exploration-free\nalgorithms both natural and effective. Our work makes three contributions.\nFirst, we strengthen the existing results on subgaussian variance concentration\nusing the Hanson-Wright inequality and identify a class of strictly subgaussian\ndistributions that yield sharper guarantees. Second, we design exploration-free\nnon-adaptive and adaptive algorithms, and we establish tighter regret bounds\nthan the existing results. Third, we extend the framework to contextual bandit\nsettings, an underexplored direction, and propose algorithms that leverage side\ninformation with provable guarantees. Overall, these results position\nexploration-free allocation as a principled and efficient approach to\nmulti-group mean estimation, with potential applications in experimental\ndesign, personalization, and other domains requiring accurate multi-group\ninference.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u591a\u7ec4\u5747\u503c\u4f30\u8ba1\u95ee\u9898\uff0c\u63d0\u51fa\u63a2\u7d22\u65e0\u5173\u7684\u5206\u914d\u7b97\u6cd5\uff0c\u5728\u4e25\u683c\u6b21\u9ad8\u65af\u5206\u5e03\u4e0b\u83b7\u5f97\u66f4\u7d27\u7684\u9057\u61be\u754c\uff0c\u5e76\u6269\u5c55\u5230\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u8bbe\u7f6e\u3002", "motivation": "\u89e3\u51b3\u591a\u7ec4\u5747\u503c\u4f30\u8ba1\u95ee\u9898\uff0c\u4e0e\u7ecf\u5178\u591a\u81c2\u8d4c\u535a\u673a\u4e0d\u540c\uff0c\u8be5\u95ee\u9898\u9700\u8981\u5747\u5300\u51c6\u786e\u5730\u4f30\u8ba1\u6240\u6709\u7ec4\u7684\u5747\u503c\uff0c\u800c\u975e\u4ec5\u8bc6\u522b\u6700\u4f73\u81c2\u3002\u63a2\u7d22\u65e0\u5173\u7b97\u6cd5\u5728\u6b64\u8bbe\u7f6e\u4e0b\u65e2\u81ea\u7136\u53c8\u6709\u6548\u3002", "method": "\u4f7f\u7528Hanson-Wright\u4e0d\u7b49\u5f0f\u52a0\u5f3a\u6b21\u9ad8\u65af\u65b9\u5dee\u96c6\u4e2d\u6027\u7ed3\u679c\uff0c\u8bc6\u522b\u4e25\u683c\u6b21\u9ad8\u65af\u5206\u5e03\u7c7b\uff1b\u8bbe\u8ba1\u63a2\u7d22\u65e0\u5173\u7684\u975e\u81ea\u9002\u5e94\u548c\u81ea\u9002\u5e94\u7b97\u6cd5\uff1b\u6269\u5c55\u5230\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u8bbe\u7f6e\uff0c\u5229\u7528\u4fa7\u4fe1\u606f\u3002", "result": "\u5efa\u7acb\u4e86\u6bd4\u73b0\u6709\u7ed3\u679c\u66f4\u7d27\u7684\u9057\u61be\u754c\uff1b\u4e3a\u4e25\u683c\u6b21\u9ad8\u65af\u5206\u5e03\u63d0\u4f9b\u4e86\u66f4\u5c16\u9510\u7684\u4fdd\u8bc1\uff1b\u5728\u4e0a\u4e0b\u6587\u8bbe\u7f6e\u4e2d\u63d0\u51fa\u4e86\u5177\u6709\u53ef\u8bc1\u660e\u4fdd\u8bc1\u7684\u7b97\u6cd5\u3002", "conclusion": "\u63a2\u7d22\u65e0\u5173\u5206\u914d\u662f\u591a\u7ec4\u5747\u503c\u4f30\u8ba1\u7684\u539f\u5219\u6027\u548c\u9ad8\u6548\u65b9\u6cd5\uff0c\u5728\u5b9e\u9a8c\u8bbe\u8ba1\u3001\u4e2a\u6027\u5316\u7b49\u9700\u8981\u51c6\u786e\u591a\u7ec4\u63a8\u65ad\u7684\u9886\u57df\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.10375", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.10375", "abs": "https://arxiv.org/abs/2510.10375", "authors": ["Kenichi Satoh"], "title": "Applying non-negative matrix factorization with covariates to label matrix for classification", "comment": "2 figures, R package: nmfkc published in GitHub,\n  https://github.com/ksatohds/nmfkc", "summary": "Non-negative matrix factorization (NMF) is widely used for dimensionality\nreduction and interpretable analysis, but standard formulations are\nunsupervised and cannot directly exploit class labels. Existing supervised or\nsemi-supervised extensions usually incorporate labels only via penalties or\ngraph constraints, still requiring an external classifier. We propose\n\\textit{NMF-LAB} (Non-negative Matrix Factorization for Label Matrix), which\nredefines classification as the inverse problem of non-negative matrix\ntri-factorization (tri-NMF). Unlike joint NMF methods, which reconstruct both\nfeatures and labels, NMF-LAB directly factorizes the label matrix $Y$ as the\nobservation, while covariates $A$ are treated as given explanatory variables.\nThis yields a direct probabilistic mapping from covariates to labels,\ndistinguishing our method from label-matrix factorization approaches that\nmainly model label correlations or impute missing labels. Our inversion offers\ntwo key advantages: (i) class-membership probabilities are obtained directly\nfrom the factorization without a separate classifier, and (ii) covariates,\nincluding kernel-based similarities, can be seamlessly integrated to generalize\npredictions to unseen samples. In addition, unlabeled data can be encoded as\nuniform distributions, supporting semi-supervised learning. Experiments on\ndiverse datasets, from small-scale benchmarks to the large-scale MNIST dataset,\ndemonstrate that NMF-LAB achieves competitive predictive accuracy, robustness\nto noisy or incomplete labels, and scalability to high-dimensional problems,\nwhile preserving interpretability. By unifying regression and classification\nwithin the tri-NMF framework, NMF-LAB provides a novel, probabilistic, and\nscalable approach to modern classification tasks.", "AI": {"tldr": "NMF-LAB\u662f\u4e00\u79cd\u65b0\u7684\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u5c06\u5206\u7c7b\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u975e\u8d1f\u77e9\u9635\u4e09\u56e0\u5b50\u5206\u89e3\u7684\u9006\u95ee\u9898\uff0c\u76f4\u63a5\u4ece\u534f\u53d8\u91cf\u6620\u5c04\u5230\u6807\u7b7e\uff0c\u65e0\u9700\u5916\u90e8\u5206\u7c7b\u5668\u3002", "motivation": "\u4f20\u7edf\u7684\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u662f\u65e0\u76d1\u7763\u7684\uff0c\u65e0\u6cd5\u76f4\u63a5\u5229\u7528\u7c7b\u522b\u6807\u7b7e\u3002\u73b0\u6709\u7684\u76d1\u7763\u6216\u534a\u76d1\u7763\u6269\u5c55\u901a\u5e38\u53ea\u901a\u8fc7\u60e9\u7f5a\u9879\u6216\u56fe\u7ea6\u675f\u6765\u6574\u5408\u6807\u7b7e\uff0c\u4ecd\u7136\u9700\u8981\u5916\u90e8\u5206\u7c7b\u5668\u3002", "method": "NMF-LAB\u5c06\u6807\u7b7e\u77e9\u9635Y\u4f5c\u4e3a\u89c2\u6d4b\u503c\u8fdb\u884c\u56e0\u5b50\u5206\u89e3\uff0c\u800c\u534f\u53d8\u91cfA\u4f5c\u4e3a\u7ed9\u5b9a\u7684\u89e3\u91ca\u53d8\u91cf\u3002\u8be5\u65b9\u6cd5\u76f4\u63a5\u83b7\u5f97\u7c7b\u522b\u6210\u5458\u6982\u7387\uff0c\u65e0\u9700\u5355\u72ec\u7684\u5206\u7c7b\u5668\uff0c\u5e76\u652f\u6301\u534a\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u5728\u4ece\u57fa\u51c6\u6570\u636e\u96c6\u5230\u5927\u89c4\u6a21MNIST\u6570\u636e\u96c6\u7684\u5404\u79cd\u5b9e\u9a8c\u4e2d\uff0cNMF-LAB\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5bf9\u566a\u58f0\u6216\u4e0d\u5b8c\u6574\u6807\u7b7e\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u9ad8\u7ef4\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u901a\u8fc7\u5728tri-NMF\u6846\u67b6\u5185\u7edf\u4e00\u56de\u5f52\u548c\u5206\u7c7b\uff0cNMF-LAB\u4e3a\u73b0\u4ee3\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u3001\u6982\u7387\u5316\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.10402", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.10402", "abs": "https://arxiv.org/abs/2510.10402", "authors": ["Jiachi Zhao", "Zehong Wang", "Yamei Liao", "Chuxu Zhang", "Yanfang Ye"], "title": "Controllable Graph Generation with Diffusion Models via Inference-Time Tree Search Guidance", "comment": null, "summary": "Graph generation is a fundamental problem in graph learning with broad\napplications across Web-scale systems, knowledge graphs, and scientific domains\nsuch as drug and material discovery. Recent approaches leverage diffusion\nmodels for step-by-step generation, yet unconditional diffusion offers little\ncontrol over desired properties, often leading to unstable quality and\ndifficulty in incorporating new objectives. Inference-time guidance methods\nmitigate these issues by adjusting the sampling process without retraining, but\nthey remain inherently local, heuristic, and limited in controllability. To\novercome these limitations, we propose TreeDiff, a Monte Carlo Tree Search\n(MCTS) guided dual-space diffusion framework for controllable graph generation.\nTreeDiff is a plug-and-play inference-time method that expands the search space\nwhile keeping computation tractable. Specifically, TreeDiff introduces three\nkey designs to make it practical and scalable: (1) a macro-step expansion\nstrategy that groups multiple denoising updates into a single transition,\nreducing tree depth and enabling long-horizon exploration; (2) a dual-space\ndenoising mechanism that couples efficient latent-space denoising with\nlightweight discrete correction in graph space, ensuring both scalability and\nstructural fidelity; and (3) a dual-space verifier that predicts long-term\nrewards from partially denoised graphs, enabling early value estimation and\nremoving the need for full rollouts. Extensive experiments on 2D and 3D\nmolecular generation benchmarks, under both unconditional and conditional\nsettings, demonstrate that TreeDiff achieves state-of-the-art performance.\nNotably, TreeDiff exhibits favorable inference-time scaling: it continues to\nimprove with additional computation, while existing inference-time methods\nplateau early under limited resources.", "AI": {"tldr": "TreeDiff\u662f\u4e00\u4e2a\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u7684\u53cc\u7a7a\u95f4\u6269\u6563\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u63a7\u56fe\u751f\u6210\uff0c\u901a\u8fc7\u5b8f\u6b65\u6269\u5c55\u3001\u53cc\u7a7a\u95f4\u53bb\u566a\u548c\u53cc\u7a7a\u95f4\u9a8c\u8bc1\u5668\u5b9e\u73b0\u9ad8\u6548\u53ef\u63a7\u7684\u56fe\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u5728\u56fe\u751f\u6210\u4e2d\u7f3a\u4e4f\u5bf9\u671f\u671b\u5c5e\u6027\u7684\u63a7\u5236\uff0c\u5bfc\u81f4\u8d28\u91cf\u4e0d\u7a33\u5b9a\u4e14\u96be\u4ee5\u878d\u5165\u65b0\u76ee\u6807\uff0c\u63a8\u7406\u65f6\u5f15\u5bfc\u65b9\u6cd5\u867d\u7136\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u4f46\u4ecd\u662f\u5c40\u90e8\u542f\u53d1\u5f0f\u4e14\u53ef\u63a7\u6027\u6709\u9650\u3002", "method": "\u63d0\u51faTreeDiff\u6846\u67b6\uff1a1\uff09\u5b8f\u6b65\u6269\u5c55\u7b56\u7565\u5c06\u591a\u4e2a\u53bb\u566a\u66f4\u65b0\u5206\u7ec4\u4e3a\u5355\u6b21\u8f6c\u79fb\uff1b2\uff09\u53cc\u7a7a\u95f4\u53bb\u566a\u673a\u5236\u8026\u5408\u6f5c\u5728\u7a7a\u95f4\u53bb\u566a\u548c\u56fe\u7a7a\u95f4\u79bb\u6563\u6821\u6b63\uff1b3\uff09\u53cc\u7a7a\u95f4\u9a8c\u8bc1\u5668\u4ece\u90e8\u5206\u53bb\u566a\u56fe\u4e2d\u9884\u6d4b\u957f\u671f\u5956\u52b1\u3002", "result": "\u57282D\u548c3D\u5206\u5b50\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65e0\u8bba\u662f\u65e0\u6761\u4ef6\u8fd8\u662f\u6709\u6761\u4ef6\u8bbe\u7f6e\uff0cTreeDiff\u90fd\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4e14\u5728\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "TreeDiff\u901a\u8fc7MCTS\u5f15\u5bfc\u7684\u53cc\u7a7a\u95f4\u6269\u6563\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u751f\u6210\u4e2d\u7684\u53ef\u63a7\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u53ef\u5904\u7406\u6027\u7684\u540c\u65f6\u6269\u5c55\u4e86\u641c\u7d22\u7a7a\u95f4\u3002"}}
{"id": "2510.10425", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10425", "abs": "https://arxiv.org/abs/2510.10425", "authors": ["Sara Dragutinovi\u0107", "Andrew M. Saxe", "Aaditya K. Singh"], "title": "Softmax $\\geq$ Linear: Transformers may learn to classify in-context by kernel gradient descent", "comment": null, "summary": "The remarkable ability of transformers to learn new concepts solely by\nreading examples within the input prompt, termed in-context learning (ICL), is\na crucial aspect of intelligent behavior. Here, we focus on understanding the\nlearning algorithm transformers use to learn from context. Existing theoretical\nwork, often based on simplifying assumptions, has primarily focused on linear\nself-attention and continuous regression tasks, finding transformers can learn\nin-context by gradient descent. Given that transformers are typically trained\non discrete and complex tasks, we bridge the gap from this existing work to the\nsetting of classification, with non-linear (importantly, softmax) activation.\nWe find that transformers still learn to do gradient descent in-context, though\non functionals in the kernel feature space and with a context-adaptive learning\nrate in the case of softmax transformer. These theoretical findings suggest a\ngreater adaptability to context for softmax attention, which we empirically\nverify and study through ablations. Overall, we hope this enhances theoretical\nunderstanding of in-context learning algorithms in more realistic settings,\npushes forward our intuitions and enables further theory bridging to larger\nmodels.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86transformer\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u7b97\u6cd5\u673a\u5236\uff0c\u53d1\u73b0\u5728\u5206\u7c7b\u4efb\u52a1\u4e2dtransformer\u4ecd\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u5b66\u4e60\uff0c\u4f46\u5728\u6838\u7279\u5f81\u7a7a\u95f4\u4e2d\u8fdb\u884c\uff0c\u4e14softmax transformer\u5177\u6709\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u3002", "motivation": "\u7406\u89e3transformer\u4ec5\u901a\u8fc7\u8f93\u5165\u63d0\u793a\u4e2d\u7684\u793a\u4f8b\u5b66\u4e60\u65b0\u6982\u5ff5\uff08\u4e0a\u4e0b\u6587\u5b66\u4e60\uff09\u7684\u7b97\u6cd5\u673a\u5236\uff0c\u73b0\u6709\u7406\u8bba\u7814\u7a76\u4e3b\u8981\u57fa\u4e8e\u7b80\u5316\u5047\u8bbe\u548c\u7ebf\u6027\u81ea\u6ce8\u610f\u529b\uff0c\u800c\u5b9e\u9645transformer\u901a\u5e38\u5904\u7406\u79bb\u6563\u590d\u6742\u4efb\u52a1\uff0c\u9700\u8981\u7814\u7a76\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u975e\u7ebf\u6027\uff08\u7279\u522b\u662fsoftmax\uff09\u6fc0\u6d3b\u60c5\u51b5\u3002", "method": "\u5c06\u73b0\u6709\u7406\u8bba\u7814\u7a76\u6269\u5c55\u5230\u5206\u7c7b\u4efb\u52a1\u8bbe\u7f6e\uff0c\u5206\u6790\u975e\u7ebf\u6027\uff08softmax\uff09\u6fc0\u6d3b\u4e0b\u7684transformer\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0transformer\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u4ecd\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u8fdb\u884c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u4f46\u5728\u6838\u7279\u5f81\u7a7a\u95f4\u4e2d\u8fdb\u884c\uff0csoftmax transformer\u5177\u6709\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86softmax\u6ce8\u610f\u529b\u5bf9\u4e0a\u4e0b\u6587\u6709\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u589e\u5f3a\u4e86\u5728\u66f4\u73b0\u5b9e\u8bbe\u7f6e\u4e0b\u5bf9\u4e0a\u4e0b\u6587\u5b66\u4e60\u7b97\u6cd5\u7684\u7406\u8bba\u7406\u89e3\uff0c\u63a8\u52a8\u4e86\u76f4\u89c9\u8ba4\u77e5\uff0c\u5e76\u4e3a\u5411\u66f4\u5927\u6a21\u578b\u7684\u7406\u8bba\u62d3\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.10432", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.10432", "abs": "https://arxiv.org/abs/2510.10432", "authors": ["Zhichen Zeng", "Mengyue Hang", "Xiaolong Liu", "Xiaoyi Liu", "Xiao Lin", "Ruizhong Qiu", "Tianxin Wei", "Zhining Liu", "Siyang Yuan", "Chaofei Yang", "Yiqun Liu", "Hang Yin", "Jiyan Yang", "Hanghang Tong"], "title": "Hierarchical LoRA MoE for Efficient CTR Model Scaling", "comment": "13 pages, 9 figures", "summary": "Deep models have driven significant advances in click-through rate (CTR)\nprediction. While vertical scaling via layer stacking improves model\nexpressiveness, the layer-by-layer sequential computation poses challenges to\nefficient scaling. Conversely, horizontal scaling through Mixture of Experts\n(MoE) achieves efficient scaling by activating a small subset of experts in\nparallel, but flat MoE layers may struggle to capture the hierarchical\nstructure inherent in recommendation tasks. To push the Return-On-Investment\n(ROI) boundary, we explore the complementary strengths of both directions and\npropose HiLoMoE, a hierarchical LoRA MoE framework that enables holistic\nscaling in a parameter-efficient manner. Specifically, HiLoMoE employs\nlightweight rank-1 experts for parameter-efficient horizontal scaling, and\nstacks multiple MoE layers with hierarchical routing to enable combinatorially\ndiverse expert compositions. Unlike conventional stacking, HiLoMoE routes based\non prior layer scores rather than outputs, allowing all layers to execute in\nparallel. A principled three-stage training framework ensures stable\noptimization and expert diversity. Experiments on four public datasets show\nthat HiLoMoE achieving better performance-efficiency tradeoff, achieving an\naverage AUC improvement of 0.20\\% in AUC and 18.5\\% reduction in FLOPs compared\nto the non-MoE baseline.", "AI": {"tldr": "HiLoMoE\u662f\u4e00\u4e2a\u5206\u5c42LoRA MoE\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5782\u76f4\u548c\u6c34\u5e73\u6269\u5c55\u7684\u4f18\u52bf\uff0c\u5728\u53c2\u6570\u9ad8\u6548\u7684\u65b9\u5f0f\u4e0b\u5b9e\u73b0\u6574\u4f53\u6269\u5c55\uff0c\u5728CTR\u9884\u6d4b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd-\u6548\u7387\u6743\u8861\u3002", "motivation": "\u6df1\u5ea6\u6a21\u578b\u5728\u70b9\u51fb\u7387\u9884\u6d4b\u4e2d\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5782\u76f4\u6269\u5c55\u5b58\u5728\u987a\u5e8f\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u800c\u6c34\u5e73\u6269\u5c55\u7684\u6241\u5e73MoE\u5c42\u96be\u4ee5\u6355\u6349\u63a8\u8350\u4efb\u52a1\u4e2d\u7684\u5c42\u6b21\u7ed3\u6784\u3002\u4e3a\u4e86\u7a81\u7834\u6295\u8d44\u56de\u62a5\u7387\u8fb9\u754c\uff0c\u63a2\u7d22\u4e24\u79cd\u65b9\u5411\u7684\u4e92\u8865\u4f18\u52bf\u3002", "method": "\u63d0\u51faHiLoMoE\u6846\u67b6\uff1a\u4f7f\u7528\u8f7b\u91cf\u7ea7rank-1\u4e13\u5bb6\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u7684\u6c34\u5e73\u6269\u5c55\uff1b\u5806\u53e0\u591a\u4e2aMoE\u5c42\u8fdb\u884c\u5206\u5c42\u8def\u7531\u4ee5\u5b9e\u73b0\u7ec4\u5408\u591a\u6837\u7684\u4e13\u5bb6\u7ec4\u5408\uff1b\u57fa\u4e8e\u524d\u5c42\u5206\u6570\u800c\u975e\u8f93\u51fa\u8fdb\u884c\u8def\u7531\uff0c\u4f7f\u6240\u6709\u5c42\u80fd\u5e76\u884c\u6267\u884c\uff1b\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\u786e\u4fdd\u7a33\u5b9a\u4f18\u5316\u548c\u4e13\u5bb6\u591a\u6837\u6027\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHiLoMoE\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd-\u6548\u7387\u6743\u8861\uff0c\u4e0e\u975eMoE\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5e73\u5747AUC\u63d0\u53470.20%\uff0cFLOPs\u51cf\u5c1118.5%\u3002", "conclusion": "HiLoMoE\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u5782\u76f4\u548c\u6c34\u5e73\u6269\u5c55\u7684\u4f18\u52bf\uff0c\u5728\u53c2\u6570\u9ad8\u6548\u7684\u65b9\u5f0f\u4e0b\u5b9e\u73b0\u4e86\u6574\u4f53\u6269\u5c55\uff0c\u4e3aCTR\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6027\u80fd-\u6548\u7387\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10433", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10433", "abs": "https://arxiv.org/abs/2510.10433", "authors": ["Zixiang Xu", "Menghui Zhou", "Jun Qi", "Xuanhan Fan", "Yun Yang", "Po Yang"], "title": "Multi-Task Learning with Feature-Similarity Laplacian Graphs for Predicting Alzheimer's Disease Progression", "comment": null, "summary": "Alzheimer's Disease (AD) is the most prevalent neurodegenerative disorder in\naging populations, posing a significant and escalating burden on global\nhealthcare systems. While Multi-Tusk Learning (MTL) has emerged as a powerful\ncomputational paradigm for modeling longitudinal AD data, existing frameworks\ndo not account for the time-varying nature of feature correlations. To address\nthis limitation, we propose a novel MTL framework, named Feature Similarity\nLaplacian graph Multi-Task Learning (MTL-FSL). Our framework introduces a novel\nFeature Similarity Laplacian (FSL) penalty that explicitly models the\ntime-varying relationships between features. By simultaneously considering\ntemporal smoothness among tasks and the dynamic correlations among features,\nour model enhances both predictive accuracy and biological interpretability. To\nsolve the non-smooth optimization problem arising from our proposed penalty\nterms, we adopt the Alternating Direction Method of Multipliers (ADMM)\nalgorithm. Experiments conducted on the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) dataset demonstrate that our proposed MTL-FSL framework\nachieves state-of-the-art performance, outperforming various baseline methods.\nThe implementation source can be found at https://github.com/huatxxx/MTL-FSL.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMTL-FSL\u7684\u65b0\u578b\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7279\u5f81\u76f8\u4f3c\u6027\u62c9\u666e\u62c9\u65af\u60e9\u7f5a\u9879\u6765\u5efa\u6a21\u7279\u5f81\u95f4\u7684\u65f6\u95f4\u53d8\u5316\u5173\u7cfb\uff0c\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\u6ca1\u6709\u8003\u8651\u7279\u5f81\u76f8\u5173\u6027\u7684\u65f6\u95f4\u53d8\u5316\u7279\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u5efa\u6a21\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7eb5\u5411\u6570\u636e\u65f6\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86MTL-FSL\u6846\u67b6\uff0c\u5f15\u5165\u7279\u5f81\u76f8\u4f3c\u6027\u62c9\u666e\u62c9\u65af\u60e9\u7f5a\u9879\u6765\u663e\u5f0f\u5efa\u6a21\u7279\u5f81\u95f4\u7684\u65f6\u95f4\u53d8\u5316\u5173\u7cfb\uff0c\u540c\u65f6\u8003\u8651\u4efb\u52a1\u95f4\u7684\u65f6\u95f4\u5e73\u6ed1\u6027\u548c\u7279\u5f81\u95f4\u7684\u52a8\u6001\u76f8\u5173\u6027\uff0c\u4f7f\u7528ADMM\u7b97\u6cd5\u89e3\u51b3\u975e\u5149\u6ed1\u4f18\u5316\u95ee\u9898\u3002", "result": "\u5728ADNI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMTL-FSL\u6846\u67b6\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "MTL-FSL\u6846\u67b6\u901a\u8fc7\u5efa\u6a21\u7279\u5f81\u95f4\u7684\u65f6\u95f4\u53d8\u5316\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u751f\u7269\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.10446", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10446", "abs": "https://arxiv.org/abs/2510.10446", "authors": ["Masoud Makrehchi"], "title": "Reverse Supervision at Scale: Exponential Search Meets the Economics of Annotation", "comment": "10 pages", "summary": "We analyze a reversed-supervision strategy that searches over labelings of a\nlarge unlabeled set \\(B\\) to minimize error on a small labeled set \\(A\\). The\nsearch space is \\(2^n\\), and the resulting complexity remains exponential even\nunder large constant-factor speedups (e.g., quantum or massively parallel\nhardware). Consequently, arbitrarily fast -- but not exponentially faster --\ncomputation does not obviate the need for informative labels or priors. In\npractice, the machine learning pipeline still requires an initial human\ncontribution: specifying the objective, defining classes, and providing a seed\nset of representative annotations that inject inductive bias and align models\nwith task semantics. Synthetic labels from generative AI can partially\nsubstitute provided their quality is human-grade and anchored by a\nhuman-specified objective, seed supervision, and validation. In this view,\ngenerative models function as \\emph{label amplifiers}, leveraging small\nhuman-curated cores via active, semi-supervised, and self-training loops, while\nhumans retain oversight for calibration, drift detection, and failure auditing.\nThus, extreme computational speed reduces wall-clock time but not the\nfundamental supervision needs of learning; initial human (or human-grade) input\nremains necessary to ground the system in the intended task.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u53cd\u5411\u76d1\u7763\u7b56\u7565\u7684\u5c40\u9650\u6027\uff0c\u6307\u51fa\u5373\u4f7f\u8ba1\u7b97\u901f\u5ea6\u5927\u5e45\u63d0\u5347\uff0c\u673a\u5668\u5b66\u4e60\u4ecd\u7136\u9700\u8981\u4eba\u7c7b\u63d0\u4f9b\u7684\u521d\u59cb\u6807\u7b7e\u3001\u76ee\u6807\u548c\u8bed\u4e49\u5b9a\u4e49\u6765\u786e\u4fdd\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u7814\u7a76\u5728\u8ba1\u7b97\u80fd\u529b\u5927\u5e45\u63d0\u5347\uff08\u5982\u91cf\u5b50\u8ba1\u7b97\u6216\u5927\u89c4\u6a21\u5e76\u884c\u786c\u4ef6\uff09\u7684\u80cc\u666f\u4e0b\uff0c\u662f\u5426\u80fd\u591f\u901a\u8fc7\u53cd\u5411\u76d1\u7763\u7b56\u7565\u5b8c\u5168\u6d88\u9664\u5bf9\u4eba\u5de5\u6807\u6ce8\u7684\u9700\u6c42\u3002", "method": "\u5206\u6790\u53cd\u5411\u76d1\u7763\u7b56\u7565\u7684\u590d\u6742\u6027\uff0c\u8be5\u7b56\u7565\u5728\u5927\u89c4\u6a21\u672a\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u641c\u7d22\u6700\u5c0f\u5316\u5c0f\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u96c6\u8bef\u5dee\u7684\u6807\u6ce8\u65b9\u6848\uff0c\u641c\u7d22\u7a7a\u95f4\u4e3a2^n\u7684\u6307\u6570\u590d\u6742\u5ea6\u3002", "result": "\u5373\u4f7f\u8ba1\u7b97\u901f\u5ea6\u83b7\u5f97\u5e38\u6570\u500d\u63d0\u5347\uff0c\u590d\u6742\u5ea6\u4ecd\u7136\u662f\u6307\u6570\u7ea7\u7684\uff0c\u65e0\u6cd5\u6d88\u9664\u5bf9\u4fe1\u606f\u6027\u6807\u7b7e\u6216\u5148\u9a8c\u77e5\u8bc6\u7684\u9700\u6c42\u3002", "conclusion": "\u6781\u7aef\u8ba1\u7b97\u901f\u5ea6\u53ea\u80fd\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u4f46\u4e0d\u80fd\u66ff\u4ee3\u5b66\u4e60\u7684\u57fa\u672c\u76d1\u7763\u9700\u6c42\uff1b\u521d\u59cb\u7684\u4eba\u7c7b\uff08\u6216\u4eba\u7c7b\u7ea7\u522b\uff09\u8f93\u5165\u4ecd\u7136\u662f\u5fc5\u8981\u7684\uff0c\u751f\u6210\u6a21\u578b\u53ea\u80fd\u4f5c\u4e3a\u6807\u7b7e\u653e\u5927\u5668\u53d1\u6325\u4f5c\u7528\u3002"}}
{"id": "2510.10465", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10465", "abs": "https://arxiv.org/abs/2510.10465", "authors": ["Yi Ren", "Xinjie Yu"], "title": "LightSAE: Parameter-Efficient and Heterogeneity-Aware Embedding for IoT Multivariate Time Series Forecasting", "comment": "Submitted to IEEE IoT-J", "summary": "Modern Internet of Things (IoT) systems generate massive, heterogeneous\nmultivariate time series data. Accurate Multivariate Time Series Forecasting\n(MTSF) of such data is critical for numerous applications. However, existing\nmethods almost universally employ a shared embedding layer that processes all\nchannels identically, creating a representational bottleneck that obscures\nvaluable channel-specific information. To address this challenge, we introduce\na Shared-Auxiliary Embedding (SAE) framework that decomposes the embedding into\na shared base component capturing common patterns and channel-specific\nauxiliary components modeling unique deviations. Within this decomposition, we\n\\rev{empirically observe} that the auxiliary components tend to exhibit\nlow-rank and clustering characteristics, a structural pattern that is\nsignificantly less apparent when using purely independent embeddings.\nConsequently, we design LightSAE, a parameter-efficient embedding module that\noperationalizes these observed characteristics through low-rank factorization\nand a shared, gated component pool. Extensive experiments across 9 IoT-related\ndatasets and 4 backbone architectures demonstrate LightSAE's effectiveness,\nachieving MSE improvements of up to 22.8\\% with only 4.0\\% parameter increase.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5171\u4eab-\u8f85\u52a9\u5d4c\u5165(SAE)\u6846\u67b6\u6765\u89e3\u51b3\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u8868\u793a\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u89e3\u4e3a\u5171\u4eab\u57fa\u7840\u7ec4\u4ef6\u548c\u901a\u9053\u7279\u5b9a\u8f85\u52a9\u7ec4\u4ef6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u53c2\u6570\u9ad8\u6548\u7684LightSAE\u6a21\u5757\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u5171\u4eab\u5d4c\u5165\u5c42\u5904\u7406\u6240\u6709\u901a\u9053\uff0c\u5bfc\u81f4\u8868\u793a\u74f6\u9888\uff0c\u63a9\u76d6\u4e86\u6709\u4ef7\u503c\u7684\u901a\u9053\u7279\u5b9a\u4fe1\u606f\u3002", "method": "\u5f15\u5165\u5171\u4eab-\u8f85\u52a9\u5d4c\u5165(SAE)\u6846\u67b6\uff0c\u5c06\u5d4c\u5165\u5206\u89e3\u4e3a\u5171\u4eab\u57fa\u7840\u7ec4\u4ef6\u548c\u901a\u9053\u7279\u5b9a\u8f85\u52a9\u7ec4\u4ef6\uff0c\u5e76\u57fa\u4e8e\u89c2\u5bdf\u5230\u7684\u4f4e\u79e9\u548c\u805a\u7c7b\u7279\u6027\u8bbe\u8ba1\u4e86LightSAE\u6a21\u5757\uff0c\u91c7\u7528\u4f4e\u79e9\u5206\u89e3\u548c\u5171\u4eab\u95e8\u63a7\u7ec4\u4ef6\u6c60\u3002", "result": "\u57289\u4e2a\u7269\u8054\u7f51\u76f8\u5173\u6570\u636e\u96c6\u548c4\u79cd\u9aa8\u5e72\u67b6\u6784\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cLightSAE\u4ec5\u589e\u52a04.0%\u53c2\u6570\u5373\u53ef\u5b9e\u73b0\u9ad8\u8fbe22.8%\u7684MSE\u6539\u8fdb\u3002", "conclusion": "SAE\u6846\u67b6\u548cLightSAE\u6a21\u5757\u6709\u6548\u89e3\u51b3\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u8868\u793a\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\u4e14\u53c2\u6570\u6548\u7387\u9ad8\u3002"}}
{"id": "2510.10467", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10467", "abs": "https://arxiv.org/abs/2510.10467", "authors": ["Gunho Park", "Jeongin Bae", "Beomseok Kwon", "Byeongwook Kim", "Se Jung Kwon", "Dongsoo Lee"], "title": "AnyBCQ: Hardware Efficient Flexible Binary-Coded Quantization for Multi-Precision LLMs", "comment": null, "summary": "The deployment of large language models (LLMs) is increasingly constrained by\nmemory and latency bottlenecks, motivating the need for quantization techniques\nthat flexibly balance accuracy and efficiency. Recent work has introduced\nmulti-precision models, which enable inference at multiple precisions within a\nsingle model depending on runtime constraints. To support such flexibility,\nquantized weights are often stored as bit-planes, where hardware efficiency\nimproves when the compute operates directly at the bit-plane level and\nactivates only the precision required by each request. In this work, we present\nAnyBCQ, a hardware-friendly multi-precision extension of Binary-Coded\nQuantization (BCQ) that supports direct bit-plane operations. By representing\nweights as binary bit-planes with corresponding scale factors, AnyBCQ enables\nbit-plane-level computation and maps naturally to accelerator-friendly,\nbit-parallel arithmetic. Our progressive precision expansion mechanism\nincrementally refines scaling factors while reusing previously assigned binary\ncodes, yielding monotonic improvements in accuracy as additional bits are\nenabled. We further co-design a specialized kernel that exploits the BCQ\nstructure to support dynamic per-request precision selection with negligible\noverhead. Experiments on recent LLMs demonstrate that AnyBCQ significantly\nnarrows the accuracy drop in the low-bit regime (e.g. 2-bit), remains\ncompetitive at higher precision, and achieves throughput gains of up to 3.0x\nover half precision and 1.2x over state-of-the-art multi-precision methods. By\naligning algorithmic flexibility with hardware efficiency, AnyBCQ provides a\npractical foundation for multi-precision LLM deployment across diverse\nservice-level objectives.", "AI": {"tldr": "AnyBCQ\u662f\u4e00\u79cd\u786c\u4ef6\u53cb\u597d\u7684\u591a\u7cbe\u5ea6\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e8c\u8fdb\u5236\u4f4d\u5e73\u9762\u8868\u793a\u6743\u91cd\uff0c\u652f\u6301\u76f4\u63a5\u4f4d\u5e73\u9762\u64cd\u4f5c\uff0c\u80fd\u591f\u5728\u5355\u4e2a\u6a21\u578b\u4e2d\u5b9e\u73b0\u52a8\u6001\u7cbe\u5ea6\u9009\u62e9\uff0c\u663e\u8457\u63d0\u5347LLM\u90e8\u7f72\u7684\u6548\u7387\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u9762\u4e34\u5185\u5b58\u548c\u5ef6\u8fdf\u74f6\u9888\uff0c\u9700\u8981\u7075\u6d3b\u7684\u91cf\u5316\u6280\u672f\u6765\u5e73\u8861\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u786c\u4ef6\u53cb\u597d\u7684\u591a\u7cbe\u5ea6\u652f\u6301\uff0c\u65e0\u6cd5\u5728\u8fd0\u884c\u65f6\u6839\u636e\u7ea6\u675f\u52a8\u6001\u8c03\u6574\u7cbe\u5ea6\u3002", "method": "\u63d0\u51faAnyBCQ\u65b9\u6cd5\uff0c\u5c06\u6743\u91cd\u8868\u793a\u4e3a\u4e8c\u8fdb\u5236\u4f4d\u5e73\u9762\u548c\u5bf9\u5e94\u7684\u7f29\u653e\u56e0\u5b50\uff0c\u652f\u6301\u4f4d\u5e73\u9762\u7ea7\u8ba1\u7b97\u548c\u6e10\u8fdb\u7cbe\u5ea6\u6269\u5c55\u673a\u5236\uff0c\u540c\u65f6\u8bbe\u8ba1\u4e86\u4e13\u7528\u5185\u6838\u6765\u652f\u6301\u52a8\u6001\u7cbe\u5ea6\u9009\u62e9\u3002", "result": "\u5728\u4f4e\u6bd4\u7279\u4f4d\uff08\u59822\u4f4d\uff09\u4e0b\u663e\u8457\u51cf\u5c11\u7cbe\u5ea6\u635f\u5931\uff0c\u5728\u9ad8\u7cbe\u5ea6\u4e0b\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u76f8\u6bd4\u534a\u7cbe\u5ea6\u5b9e\u73b03.0\u500d\u541e\u5410\u91cf\u63d0\u5347\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u591a\u7cbe\u5ea6\u65b9\u6cd5\u63d0\u53471.2\u500d\u3002", "conclusion": "AnyBCQ\u901a\u8fc7\u7b97\u6cd5\u7075\u6d3b\u6027\u4e0e\u786c\u4ef6\u6548\u7387\u7684\u7ed3\u5408\uff0c\u4e3a\u591a\u7cbe\u5ea6LLM\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u80fd\u591f\u9002\u5e94\u591a\u6837\u5316\u7684\u670d\u52a1\u7ea7\u522b\u76ee\u6807\u3002"}}
{"id": "2510.10477", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10477", "abs": "https://arxiv.org/abs/2510.10477", "authors": ["Zhijian Zhou", "Liuhua Peng", "Xunye Tian", "Feng Liu"], "title": "Anchor-based Maximum Discrepancy for Relative Similarity Testing", "comment": null, "summary": "The relative similarity testing aims to determine which of the distributions,\nP or Q, is closer to an anchor distribution U. Existing kernel-based approaches\noften test the relative similarity with a fixed kernel in a manually specified\nalternative hypothesis, e.g., Q is closer to U than P. Although kernel\nselection is known to be important to kernel-based testing methods, the\nmanually specified hypothesis poses a significant challenge for kernel\nselection in relative similarity testing: Once the hypothesis is specified\nfirst, we can always find a kernel such that the hypothesis is rejected. This\nchallenge makes relative similarity testing ill-defined when we want to select\na good kernel after the hypothesis is specified. In this paper, we cope with\nthis challenge via learning a proper hypothesis and a kernel simultaneously,\ninstead of learning a kernel after manually specifying the hypothesis. We\npropose an anchor-based maximum discrepancy (AMD), which defines the relative\nsimilarity as the maximum discrepancy between the distances of (U, P) and (U,\nQ) in a space of deep kernels. Based on AMD, our testing incorporates two\nphases. In Phase I, we estimate the AMD over the deep kernel space and infer\nthe potential hypothesis. In Phase II, we assess the statistical significance\nof the potential hypothesis, where we propose a unified testing framework to\nderive thresholds for tests over different possible hypotheses from Phase I.\nLastly, we validate our method theoretically and demonstrate its effectiveness\nvia extensive experiments on benchmark datasets. Codes are publicly available\nat: https://github.com/zhijianzhouml/AMD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u951a\u70b9\u7684\u6700\u5927\u5dee\u5f02\u5ea6\uff08AMD\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u76f8\u5bf9\u76f8\u4f3c\u6027\u6d4b\u8bd5\u4e2d\u6838\u9009\u62e9\u4e0e\u5047\u8bbe\u6307\u5b9a\u76f8\u4e92\u4f9d\u8d56\u7684\u95ee\u9898\u3002\u901a\u8fc7\u540c\u65f6\u5b66\u4e60\u5408\u9002\u7684\u5047\u8bbe\u548c\u6838\u51fd\u6570\uff0c\u800c\u4e0d\u662f\u5728\u624b\u52a8\u6307\u5b9a\u5047\u8bbe\u540e\u9009\u62e9\u6838\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u8fdb\u884c\u76f8\u5bf9\u76f8\u4f3c\u6027\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6838\u7684\u76f8\u5bf9\u76f8\u4f3c\u6027\u6d4b\u8bd5\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u56fa\u5b9a\u6838\u5e76\u5728\u624b\u52a8\u6307\u5b9a\u7684\u5907\u62e9\u5047\u8bbe\u4e0b\u8fdb\u884c\u6d4b\u8bd5\u3002\u7136\u800c\uff0c\u4e00\u65e6\u5047\u8bbe\u88ab\u6307\u5b9a\uff0c\u603b\u80fd\u627e\u5230\u4e00\u4e2a\u6838\u4f7f\u5f97\u8be5\u5047\u8bbe\u88ab\u62d2\u7edd\uff0c\u8fd9\u5bfc\u81f4\u5728\u6307\u5b9a\u5047\u8bbe\u540e\u9009\u62e9\u5408\u9002\u6838\u53d8\u5f97\u56f0\u96be\uff0c\u4f7f\u5f97\u76f8\u5bf9\u76f8\u4f3c\u6027\u6d4b\u8bd5\u5728\u5b9a\u4e49\u4e0a\u5b58\u5728\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u951a\u70b9\u6700\u5927\u5dee\u5f02\u5ea6\uff08AMD\uff09\u65b9\u6cd5\uff0c\u5c06\u76f8\u5bf9\u76f8\u4f3c\u6027\u5b9a\u4e49\u4e3a\u5728\u6df1\u5ea6\u6838\u7a7a\u95f4\u4e2d(U,P)\u548c(U,Q)\u8ddd\u79bb\u4e4b\u95f4\u7684\u6700\u5927\u5dee\u5f02\u3002\u6d4b\u8bd5\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728\u6df1\u5ea6\u6838\u7a7a\u95f4\u4f30\u8ba1AMD\u5e76\u63a8\u65ad\u6f5c\u5728\u5047\u8bbe\uff1b\u7b2c\u4e8c\u9636\u6bb5\u8bc4\u4f30\u6f5c\u5728\u5047\u8bbe\u7684\u7edf\u8ba1\u663e\u8457\u6027\uff0c\u63d0\u51fa\u7edf\u4e00\u6d4b\u8bd5\u6846\u67b6\u4e3a\u4e0d\u540c\u53ef\u80fd\u5047\u8bbe\u63a8\u5bfc\u9608\u503c\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u9a8c\u8bc1\u548c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u4ee3\u7801\u5df2\u5728GitHub\u4e0a\u516c\u5f00\u3002", "conclusion": "\u901a\u8fc7\u540c\u65f6\u5b66\u4e60\u5047\u8bbe\u548c\u6838\u51fd\u6570\uff0cAMD\u65b9\u6cd5\u89e3\u51b3\u4e86\u76f8\u5bf9\u76f8\u4f3c\u6027\u6d4b\u8bd5\u4e2d\u6838\u9009\u62e9\u4e0e\u5047\u8bbe\u6307\u5b9a\u7684\u76f8\u4e92\u4f9d\u8d56\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u53ef\u9760\u548c\u6709\u6548\u7684\u6d4b\u8bd5\u6846\u67b6\u3002"}}
{"id": "2510.10480", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10480", "abs": "https://arxiv.org/abs/2510.10480", "authors": ["Zishen Zhang", "Xiangzhe Kong", "Wenbing Huang", "Yang Liu"], "title": "Latent Retrieval Augmented Generation of Cross-Domain Protein Binders", "comment": null, "summary": "Designing protein binders targeting specific sites, which requires to\ngenerate realistic and functional interaction patterns, is a fundamental\nchallenge in drug discovery. Current structure-based generative models are\nlimited in generating nterfaces with sufficient rationality and\ninterpretability. In this paper, we propose Retrieval-Augmented Diffusion for\nAligned interface (RADiAnce), a new framework that leverages known interfaces\nto guide the design of novel binders. By unifying retrieval and generation in a\nshared contrastive latent space, our model efficiently identifies relevant\ninterfaces for a given binding site and seamlessly integrates them through a\nconditional latent diffusion generator, enabling cross-domain interface\ntransfer. Extensive exeriments show that RADiAnce significantly outperforms\nbaseline models across multiple metrics, including binding affinity and\nrecovery of geometries and interactions. Additional experimental results\nvalidate cross-domain generalization, demonstrating that retrieving interfaces\nfrom diverse domains, such as peptides, antibodies, and protein fragments,\nenhances the generation performance of binders for other domains. Our work\nestablishes a new paradigm for protein binder design that successfully bridges\nretrieval-based knowledge and generative AI, opening new possibilities for drug\ndiscovery.", "AI": {"tldr": "RADiAnce\u662f\u4e00\u4e2a\u65b0\u7684\u86cb\u767d\u8d28\u7ed3\u5408\u5242\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u6269\u6563\u65b9\u6cd5\uff0c\u5229\u7528\u5df2\u77e5\u754c\u9762\u6307\u5bfc\u65b0\u578b\u7ed3\u5408\u5242\u7684\u8bbe\u8ba1\uff0c\u5728\u7ed3\u5408\u4eb2\u548c\u529b\u3001\u51e0\u4f55\u7ed3\u6784\u548c\u76f8\u4e92\u4f5c\u7528\u6062\u590d\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u7ed3\u6784\u7684\u751f\u6210\u6a21\u578b\u5728\u751f\u6210\u5177\u6709\u8db3\u591f\u5408\u7406\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u754c\u9762\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u751f\u6210\u73b0\u5b9e\u4e14\u529f\u80fd\u6027\u76f8\u4e92\u4f5c\u7528\u6a21\u5f0f\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u57fa\u672c\u6311\u6218\u3002", "method": "\u63d0\u51faRADiAnce\u6846\u67b6\uff0c\u5728\u5171\u4eab\u5bf9\u6bd4\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7edf\u4e00\u68c0\u7d22\u548c\u751f\u6210\uff0c\u901a\u8fc7\u6761\u4ef6\u6f5c\u5728\u6269\u6563\u751f\u6210\u5668\u8bc6\u522b\u76f8\u5173\u754c\u9762\u5e76\u5b9e\u73b0\u8de8\u57df\u754c\u9762\u8f6c\u79fb\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRADiAnce\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5305\u62ec\u7ed3\u5408\u4eb2\u548c\u529b\u4ee5\u53ca\u51e0\u4f55\u7ed3\u6784\u548c\u76f8\u4e92\u4f5c\u7528\u7684\u6062\u590d\u3002\u8de8\u57df\u6cdb\u5316\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4ece\u80bd\u3001\u6297\u4f53\u548c\u86cb\u767d\u8d28\u7247\u6bb5\u7b49\u4e0d\u540c\u57df\u68c0\u7d22\u754c\u9762\u53ef\u4ee5\u589e\u5f3a\u5176\u4ed6\u57df\u7ed3\u5408\u5242\u7684\u751f\u6210\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u86cb\u767d\u8d28\u7ed3\u5408\u5242\u8bbe\u8ba1\u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u8303\u5f0f\uff0c\u6210\u529f\u6865\u63a5\u4e86\u57fa\u4e8e\u68c0\u7d22\u7684\u77e5\u8bc6\u548c\u751f\u6210\u5f0fAI\uff0c\u4e3a\u836f\u7269\u53d1\u73b0\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.10483", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.10483", "abs": "https://arxiv.org/abs/2510.10483", "authors": ["Narayan S Iyer", "Bivas Bhaumik", "Ram S Iyer", "Satyasaran Changdar"], "title": "Gradient Enhanced Self-Training Physics-Informed Neural Network (gST-PINN) for Solving Nonlinear Partial Differential Equations", "comment": null, "summary": "Partial differential equations (PDEs) provide a mathematical foundation for\nsimulating and understanding intricate behaviors in both physical sciences and\nengineering. With the growing capabilities of deep learning, data$-$driven\napproaches like Physics$-$Informed Neural Networks (PINNs) have been developed,\noffering a mesh$-$free, analytic type framework for efficiently solving PDEs\nacross a wide range of applications. However, traditional PINNs often struggle\nwith challenges such as limited precision, slow training dynamics, lack of\nlabeled data availability, and inadequate handling of multi$-$physics\ninteractions. To overcome these challenging issues of PINNs, we proposed a\nGradient Enhanced Self$-$Training PINN (gST$-$PINN) method that specifically\nintroduces a gradient based pseudo point self$-$learning algorithm for solving\nPDEs. We tested the proposed method on three different types of PDE problems\nfrom various fields, each representing distinct scenarios. The effectiveness of\nthe proposed method is evident, as the PINN approach for solving the Burgers$'$\nequation attains a mean square error (MSE) on the order of $10^{-3}$, while the\ndiffusion$-$sorption equation achieves an MSE on the order of $10^{-4}$ after\n12,500 iterations, with no further improvement as the iterations increase. In\ncontrast, the MSE for both PDEs in the gST$-$PINN model continues to decrease,\ndemonstrating better generalization and reaching an MSE on the order of\n$10^{-5}$ after 18,500 iterations. Furthermore, the results show that the\nproposed purely semi$-$supervised gST$-$PINN consistently outperforms the\nstandard PINN method in all cases, even when solution of the PDEs are\nunavailable. It generalizes both PINN and Gradient$-$enhanced PINN (gPINN), and\ncan be effectively applied in scenarios prone to low accuracy and convergence\nissues, particularly in the absence of labeled data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u68af\u5ea6\u589e\u5f3a\u81ea\u8bad\u7ec3PINN\uff08gST-PINN\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u4f2a\u70b9\u81ea\u5b66\u4e60\u7b97\u6cd5\u89e3\u51b3\u4f20\u7edfPINNs\u5728\u7cbe\u5ea6\u3001\u8bad\u7ec3\u901f\u5ea6\u3001\u6570\u636e\u7a00\u7f3a\u548c\u591a\u7269\u7406\u573a\u5904\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edfPINNs\u9762\u4e34\u7cbe\u5ea6\u6709\u9650\u3001\u8bad\u7ec3\u7f13\u6162\u3001\u6807\u8bb0\u6570\u636e\u7f3a\u4e4f\u548c\u591a\u7269\u7406\u573a\u4ea4\u4e92\u5904\u7406\u4e0d\u8db3\u7b49\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u6c42\u89e3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u68af\u5ea6\u589e\u5f3a\u81ea\u8bad\u7ec3PINN\u65b9\u6cd5\uff0c\u5f15\u5165\u57fa\u4e8e\u68af\u5ea6\u7684\u4f2a\u70b9\u81ea\u5b66\u4e60\u7b97\u6cd5\uff0c\u5728\u65e0\u6807\u7b7e\u6570\u636e\u60c5\u51b5\u4e0b\u63d0\u5347PDE\u6c42\u89e3\u6027\u80fd\u3002", "result": "\u5728\u4e09\u79cd\u4e0d\u540c\u7c7b\u578bPDE\u95ee\u9898\u4e0a\u6d4b\u8bd5\uff0cgST-PINN\u76f8\u6bd4\u4f20\u7edfPINN\u663e\u8457\u63d0\u5347\u7cbe\u5ea6\uff1aBurgers\u65b9\u7a0bMSE\u4ece10^-3\u964d\u81f310^-5\uff0c\u6269\u6563-\u5438\u9644\u65b9\u7a0b\u4ece10^-4\u964d\u81f310^-5\uff0c\u4e14\u6301\u7eed\u6536\u655b\u3002", "conclusion": "gST-PINN\u5728\u65e0\u6807\u7b7e\u6570\u636e\u60c5\u51b5\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6PINN\u65b9\u6cd5\uff0c\u6cdb\u5316\u4e86PINN\u548cgPINN\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7cbe\u5ea6\u4f4e\u548c\u6536\u655b\u95ee\u9898\u7684\u573a\u666f\u3002"}}
{"id": "2510.10503", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10503", "abs": "https://arxiv.org/abs/2510.10503", "authors": ["Kanishkha Jaisankar", "Sunidhi Tandel"], "title": "Align2Act: Instruction-Tuned Models for Human-Aligned Autonomous Driving", "comment": null, "summary": "Motion planning in complex scenarios is a core challenge in autonomous\ndriving. Conventional methods apply predefined rules or learn from driving data\nto generate trajectories, while recent approaches leverage large language\nmodels (LLMs) for decision-making. However, it remains unclear whether LLMs\ntruly capture human driving logic. We propose Align2Act, a motion planning\nframework that transforms instruction-tuned LLMs into interpretable planners\naligned with human behavior. We derive structured driving instructions based on\nhuman reasoning patterns (e.g., anticipate hazards, yield at intersections) and\ntraffic rules (e.g., stop at red lights, maintain lane boundaries). Our\nAlign2ActChain module guides step-by-step reasoning to produce both an\ninterpretable rationale and a safe trajectory. By fine-tuning LLaMA-2-7B with\nLoRA on one million scenarios from the nuPlan dataset, our method achieves an\nopen-loop score of 85.17 and closed-loop scores of 70.31 (non-reactive) and\n66.96 (reactive) on Test14-random. Unlike prior work focused on synthetic or\nopen-loop settings, we demonstrate improved planning quality and human-likeness\non the real-world nuPlan closed-loop benchmark. Ablation studies confirm that\nstructured reasoning significantly improves performance over baseline LLM\nplanners.", "AI": {"tldr": "Align2Act\u662f\u4e00\u4e2a\u5c06\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u89c4\u5212\u5668\u7684\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u9a7e\u9a76\u6307\u4ee4\u548c\u9010\u6b65\u63a8\u7406\u6765\u751f\u6210\u5b89\u5168\u8f68\u8ff9\uff0c\u5728\u771f\u5b9e\u4e16\u754cnuPlan\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u786e\u4fddLLM\u771f\u6b63\u7406\u89e3\u4eba\u7c7b\u9a7e\u9a76\u903b\u8f91\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u4e0e\u4eba\u7c7b\u884c\u4e3a\u5bf9\u9f50\u7684\u53ef\u89e3\u91ca\u89c4\u5212\u5668\u3002", "method": "\u57fa\u4e8e\u4eba\u7c7b\u63a8\u7406\u6a21\u5f0f\u548c\u4ea4\u901a\u89c4\u5219\u6784\u5efa\u7ed3\u6784\u5316\u9a7e\u9a76\u6307\u4ee4\uff0c\u901a\u8fc7Align2ActChain\u6a21\u5757\u8fdb\u884c\u9010\u6b65\u63a8\u7406\uff0c\u4f7f\u7528LoRA\u5728nuPlan\u6570\u636e\u96c6\u4e0a\u5fae\u8c03LLaMA-2-7B\u3002", "result": "\u5728Test14-random\u4e0a\u83b7\u5f97\u5f00\u73af\u5206\u657085.17\uff0c\u95ed\u73af\u5206\u657070.31\uff08\u975e\u53cd\u5e94\u5f0f\uff09\u548c66.96\uff08\u53cd\u5e94\u5f0f\uff09\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u6784\u5316\u63a8\u7406\u663e\u8457\u63d0\u5347\u4e86LLM\u89c4\u5212\u5668\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u89c4\u5212\u8d28\u91cf\u548c\u4eba\u7c7b\u76f8\u4f3c\u6027\u3002"}}
{"id": "2510.10510", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10510", "abs": "https://arxiv.org/abs/2510.10510", "authors": ["Subhodip Panda", "Dhruv Tarsadiya", "Shashwat Sourav", "Prathosh A. P", "Sai Praneeth Karimireddy"], "title": "f-INE: A Hypothesis Testing Framework for Estimating Influence under Training Randomness", "comment": null, "summary": "Influence estimation methods promise to explain and debug machine learning by\nestimating the impact of individual samples on the final model. Yet, existing\nmethods collapse under training randomness: the same example may appear\ncritical in one run and irrelevant in the next. Such instability undermines\ntheir use in data curation or cleanup since it is unclear if we indeed\ndeleted/kept the correct datapoints. To overcome this, we introduce\n*f-influence* -- a new influence estimation framework grounded in hypothesis\ntesting that explicitly accounts for training randomness, and establish\ndesirable properties that make it suitable for reliable influence estimation.\nWe also design a highly efficient algorithm **f**-**IN**fluence **E**stimation\n(**f-INE**) that computes f-influence **in a single training run**. Finally, we\nscale up f-INE to estimate influence of instruction tuning data on Llama-3.1-8B\nand show it can reliably detect poisoned samples that steer model opinions,\ndemonstrating its utility for data cleanup and attributing model behavior.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86f-influence\u6846\u67b6\uff0c\u901a\u8fc7\u5047\u8bbe\u68c0\u9a8c\u8003\u8651\u8bad\u7ec3\u968f\u673a\u6027\uff0c\u63d0\u4f9b\u7a33\u5b9a\u7684\u5f71\u54cd\u529b\u4f30\u8ba1\uff0c\u5e76\u5f00\u53d1\u4e86f-INE\u7b97\u6cd5\u5728\u5355\u6b21\u8bad\u7ec3\u4e2d\u9ad8\u6548\u8ba1\u7b97\u5f71\u54cd\u529b\u3002", "motivation": "\u73b0\u6709\u5f71\u54cd\u529b\u4f30\u8ba1\u65b9\u6cd5\u5728\u8bad\u7ec3\u968f\u673a\u6027\u4e0b\u4e0d\u7a33\u5b9a\uff0c\u540c\u4e00\u6837\u672c\u5728\u4e0d\u540c\u8bad\u7ec3\u4e2d\u53ef\u80fd\u88ab\u8bc4\u4f30\u4e3a\u5173\u952e\u6216\u65e0\u5173\uff0c\u8fd9\u524a\u5f31\u4e86\u5728\u6570\u636e\u6e05\u7406\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5047\u8bbe\u68c0\u9a8c\u7684f-influence\u6846\u67b6\uff0c\u8bbe\u8ba1f-INE\u7b97\u6cd5\u5728\u5355\u6b21\u8bad\u7ec3\u4e2d\u9ad8\u6548\u8ba1\u7b97\u6837\u672c\u5f71\u54cd\u529b\uff0c\u53ef\u6269\u5c55\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "f-influence\u6846\u67b6\u5177\u6709\u7406\u60f3\u7279\u6027\uff0cf-INE\u7b97\u6cd5\u80fd\u53ef\u9760\u68c0\u6d4bLlama-3.1-8B\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u4e2d\u7684\u4e2d\u6bd2\u6837\u672c\uff0c\u6709\u6548\u5f15\u5bfc\u6a21\u578b\u89c2\u70b9\u3002", "conclusion": "f-influence\u63d0\u4f9b\u53ef\u9760\u7684\u5f71\u54cd\u529b\u4f30\u8ba1\uff0c\u9002\u7528\u4e8e\u6570\u636e\u6e05\u7406\u548c\u6a21\u578b\u884c\u4e3a\u5f52\u56e0\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8bad\u7ec3\u968f\u673a\u6027\u4e0b\u7684\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002"}}
{"id": "2510.10530", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10530", "abs": "https://arxiv.org/abs/2510.10530", "authors": ["Hanbing Liu", "Huaze Tang", "Yanru Wu", "Yang Li", "Xiao-Ping Zhang"], "title": "Reinforced Domain Selection for Continuous Domain Adaptation", "comment": null, "summary": "Continuous Domain Adaptation (CDA) effectively bridges significant domain\nshifts by progressively adapting from the source domain through intermediate\ndomains to the target domain. However, selecting intermediate domains without\nexplicit metadata remains a substantial challenge that has not been extensively\nexplored in existing studies. To tackle this issue, we propose a novel\nframework that combines reinforcement learning with feature disentanglement to\nconduct domain path selection in an unsupervised CDA setting. Our approach\nintroduces an innovative unsupervised reward mechanism that leverages the\ndistances between latent domain embeddings to facilitate the identification of\noptimal transfer paths. Furthermore, by disentangling features, our method\nfacilitates the calculation of unsupervised rewards using domain-specific\nfeatures and promotes domain adaptation by aligning domain-invariant features.\nThis integrated strategy is designed to simultaneously optimize transfer paths\nand target task performance, enhancing the effectiveness of domain adaptation\nprocesses. Extensive empirical evaluations on datasets such as Rotated MNIST\nand ADNI demonstrate substantial improvements in prediction accuracy and domain\nselection efficiency, establishing our method's superiority over traditional\nCDA approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u7279\u5f81\u89e3\u8026\u7684\u65e0\u76d1\u7763\u8fde\u7eed\u57df\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6ca1\u6709\u663e\u5f0f\u5143\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u9009\u62e9\u6700\u4f18\u57df\u8f6c\u79fb\u8def\u5f84\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u57df\u9009\u62e9\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u8fde\u7eed\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u5728\u7f3a\u4e4f\u663e\u5f0f\u5143\u6570\u636e\u65f6\u96be\u4ee5\u6709\u6548\u9009\u62e9\u4e2d\u95f4\u57df\uff0c\u8fd9\u9650\u5236\u4e86\u57df\u81ea\u9002\u5e94\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u57df\u8def\u5f84\u9009\u62e9\uff0c\u7ed3\u5408\u7279\u5f81\u89e3\u8026\u6280\u672f\u5206\u79bb\u57df\u7279\u5b9a\u548c\u57df\u4e0d\u53d8\u7279\u5f81\uff0c\u901a\u8fc7\u57fa\u4e8e\u6f5c\u5728\u57df\u5d4c\u5165\u8ddd\u79bb\u7684\u65e0\u76d1\u7763\u5956\u52b1\u673a\u5236\u4f18\u5316\u8f6c\u79fb\u8def\u5f84\u3002", "result": "\u5728Rotated MNIST\u548cADNI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u57df\u9009\u62e9\u6548\u7387\u65b9\u9762\u76f8\u6bd4\u4f20\u7edf\u8fde\u7eed\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u96c6\u6210\u7b56\u7565\u80fd\u591f\u540c\u65f6\u4f18\u5316\u8f6c\u79fb\u8def\u5f84\u548c\u76ee\u6807\u4efb\u52a1\u6027\u80fd\uff0c\u6709\u6548\u63d0\u5347\u4e86\u57df\u81ea\u9002\u5e94\u8fc7\u7a0b\u7684\u6548\u679c\uff0c\u4e3a\u65e0\u76d1\u7763\u8fde\u7eed\u57df\u81ea\u9002\u5e94\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10541", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10541", "abs": "https://arxiv.org/abs/2510.10541", "authors": ["Zihan Chen", "Yiming Zhang", "Hengguang Zhou", "Zenghui Ding", "Yining Sun", "Cho-Jui Hsieh"], "title": "Rethinking RL Evaluation: Can Benchmarks Truly Reveal Failures of RL Methods?", "comment": null, "summary": "Current benchmarks are inadequate for evaluating progress in reinforcement\nlearning (RL) for large language models (LLMs).Despite recent benchmark gains\nreported for RL, we find that training on these benchmarks' training sets\nachieves nearly the same performance as training directly on the test sets,\nsuggesting that the benchmarks cannot reliably separate further progress.To\nstudy this phenomenon, we introduce a diagnostic suite and the Oracle\nPerformance Gap (OPG) metric that quantifies the performance difference between\ntraining on the train split versus the test split of a benchmark. We further\nanalyze this phenomenon with stress tests and find that, despite strong\nbenchmark scores, existing RL methods struggle to generalize across\ndistribution shifts, varying levels of difficulty, and counterfactual\nscenarios: shortcomings that current benchmarks fail to reveal.We conclude that\ncurrent benchmarks are insufficient for evaluating generalization and propose\nthree core principles for designing more faithful benchmarks: sufficient\ndifficulty, balanced evaluation, and distributional robustness.", "AI": {"tldr": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u5c55\uff0c\u56e0\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u6027\u80fd\u5dee\u5f02\u5f88\u5c0f\u3002\u4f5c\u8005\u63d0\u51fa\u4e86Oracle\u6027\u80fd\u5dee\u8ddd\u6307\u6807\u548c\u8bca\u65ad\u5957\u4ef6\uff0c\u53d1\u73b0\u73b0\u6709RL\u65b9\u6cd5\u5728\u5206\u5e03\u504f\u79fb\u3001\u96be\u5ea6\u53d8\u5316\u548c\u53cd\u4e8b\u5b9e\u573a\u666f\u4e0b\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u5efa\u8bae\u8bbe\u8ba1\u66f4\u53ef\u9760\u7684\u57fa\u51c6\u5e94\u9075\u5faa\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u771f\u5b9e\u8fdb\u5c55\uff0c\u56e0\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u6027\u80fd\u5dee\u5f02\u8fc7\u5c0f\uff0c\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "method": "\u5f15\u5165\u8bca\u65ad\u5957\u4ef6\u548cOracle\u6027\u80fd\u5dee\u8ddd(OPG)\u6307\u6807\uff0c\u91cf\u5316\u8bad\u7ec3\u96c6\u4e0e\u6d4b\u8bd5\u96c6\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u901a\u8fc7\u538b\u529b\u6d4b\u8bd5\u5206\u6790\u73b0\u6709RL\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u5c3d\u7ba1\u57fa\u51c6\u5206\u6570\u5f88\u9ad8\uff0c\u4f46\u73b0\u6709RL\u65b9\u6cd5\u5728\u5206\u5e03\u504f\u79fb\u3001\u96be\u5ea6\u53d8\u5316\u548c\u53cd\u4e8b\u5b9e\u573a\u666f\u4e0b\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u5f53\u524d\u57fa\u51c6\u65e0\u6cd5\u63ed\u793a\u8fd9\u4e9b\u7f3a\u9677\u3002", "conclusion": "\u5f53\u524d\u57fa\u51c6\u4e0d\u8db3\u4ee5\u8bc4\u4f30\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u51fa\u8bbe\u8ba1\u66f4\u53ef\u9760\u57fa\u51c6\u7684\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\uff1a\u8db3\u591f\u96be\u5ea6\u3001\u5e73\u8861\u8bc4\u4f30\u548c\u5206\u5e03\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.10544", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10544", "abs": "https://arxiv.org/abs/2510.10544", "authors": ["Abdelkrim Zitouni", "Mehdi Hennequin", "Juba Agoun", "Ryan Horache", "Nadia Kabachi", "Omar Rivasplata"], "title": "PAC-Bayesian Reinforcement Learning Trains Generalizable Policies", "comment": null, "summary": "We derive a novel PAC-Bayesian generalization bound for reinforcement\nlearning that explicitly accounts for Markov dependencies in the data, through\nthe chain's mixing time. This contributes to overcoming challenges in obtaining\ngeneralization guarantees for reinforcement learning, where the sequential\nnature of data breaks the independence assumptions underlying classical bounds.\nOur bound provides non-vacuous certificates for modern off-policy algorithms\nlike Soft Actor-Critic. We demonstrate the bound's practical utility through\nPB-SAC, a novel algorithm that optimizes the bound during training to guide\nexploration. Experiments across continuous control tasks show that our approach\nprovides meaningful confidence certificates while maintaining competitive\nperformance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60PAC-Bayesian\u6cdb\u5316\u8fb9\u754c\uff0c\u8003\u8651\u9a6c\u5c14\u53ef\u592b\u4f9d\u8d56\u6027\u548c\u94fe\u7684\u6df7\u5408\u65f6\u95f4\uff0c\u4e3a\u73b0\u4ee3\u79bb\u7b56\u7565\u7b97\u6cd5\u63d0\u4f9b\u975e\u7a7a\u6cdb\u7684\u6cdb\u5316\u4fdd\u8bc1\uff0c\u5e76\u5f00\u53d1\u4e86PB-SAC\u7b97\u6cd5\u6765\u4f18\u5316\u8fb9\u754c\u6307\u5bfc\u63a2\u7d22\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7531\u4e8e\u6570\u636e\u5e8f\u5217\u6027\u7834\u574f\u72ec\u7acb\u6027\u5047\u8bbe\u800c\u96be\u4ee5\u83b7\u5f97\u6cdb\u5316\u4fdd\u8bc1\u7684\u6311\u6218\uff0c\u4e3a\u73b0\u4ee3\u79bb\u7b56\u7565\u7b97\u6cd5\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u7f6e\u4fe1\u5ea6\u8bc1\u4e66\u3002", "method": "\u63a8\u5bfc\u4e86\u8003\u8651\u9a6c\u5c14\u53ef\u592b\u4f9d\u8d56\u6027\u548c\u6df7\u5408\u65f6\u95f4\u7684PAC-Bayesian\u6cdb\u5316\u8fb9\u754c\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86PB-SAC\u7b97\u6cd5\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f18\u5316\u8fb9\u754c\u6765\u6307\u5bfc\u63a2\u7d22\u3002", "result": "\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u7f6e\u4fe1\u5ea6\u8bc1\u4e66\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u8003\u8651\u6570\u636e\u4f9d\u8d56\u6027\u7684\u6cdb\u5316\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u7406\u8bba\u8fb9\u754c\u5728\u5b9e\u9645\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.10572", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10572", "abs": "https://arxiv.org/abs/2510.10572", "authors": ["Byeongchan Lee"], "title": "Understanding Self-supervised Contrastive Learning through Supervised Objectives", "comment": "Accepted at TMLR 2025", "summary": "Self-supervised representation learning has achieved impressive empirical\nsuccess, yet its theoretical understanding remains limited. In this work, we\nprovide a theoretical perspective by formulating self-supervised representation\nlearning as an approximation to supervised representation learning objectives.\nBased on this formulation, we derive a loss function closely related to popular\ncontrastive losses such as InfoNCE, offering insight into their underlying\nprinciples. Our derivation naturally introduces the concepts of prototype\nrepresentation bias and a balanced contrastive loss, which help explain and\nimprove the behavior of self-supervised learning algorithms. We further show\nhow components of our theoretical framework correspond to established practices\nin contrastive learning. Finally, we empirically validate the effect of\nbalancing positive and negative pair interactions. All theoretical proofs are\nprovided in the appendix, and our code is included in the supplementary\nmaterial.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u5f62\u5f0f\u5316\u4e3a\u76d1\u7763\u8868\u793a\u5b66\u4e60\u76ee\u6807\u7684\u8fd1\u4f3c\uff0c\u63a8\u5bfc\u51fa\u4e0eInfoNCE\u7b49\u5bf9\u6bd4\u635f\u5931\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570\uff0c\u5f15\u5165\u539f\u578b\u8868\u793a\u504f\u5dee\u548c\u5e73\u8861\u5bf9\u6bd4\u635f\u5931\u6982\u5ff5\uff0c\u5e76\u5b9e\u8bc1\u9a8c\u8bc1\u6b63\u8d1f\u5bf9\u4ea4\u4e92\u5e73\u8861\u7684\u6548\u679c\u3002", "motivation": "\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u5728\u5b9e\u8bc1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u672c\u6587\u65e8\u5728\u4ece\u7406\u8bba\u89d2\u5ea6\u7406\u89e3\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\uff0c\u5c06\u5176\u4e0e\u76d1\u7763\u5b66\u4e60\u76ee\u6807\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u5c06\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u5f62\u5f0f\u5316\u4e3a\u76d1\u7763\u8868\u793a\u5b66\u4e60\u76ee\u6807\u7684\u8fd1\u4f3c\uff0c\u57fa\u4e8e\u6b64\u63a8\u5bfc\u51fa\u4e0e\u5bf9\u6bd4\u635f\u5931\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570\uff0c\u5f15\u5165\u539f\u578b\u8868\u793a\u504f\u5dee\u548c\u5e73\u8861\u5bf9\u6bd4\u635f\u5931\u6982\u5ff5\uff0c\u5e76\u5c06\u7406\u8bba\u6846\u67b6\u7ec4\u4ef6\u4e0e\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u8df5\u5bf9\u5e94\u3002", "result": "\u63a8\u5bfc\u51fa\u4e0e\u6d41\u884c\u5bf9\u6bd4\u635f\u5931\uff08\u5982InfoNCE\uff09\u5bc6\u5207\u76f8\u5173\u7684\u635f\u5931\u51fd\u6570\uff0c\u89e3\u91ca\u4e86\u5176\u57fa\u672c\u539f\u7406\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u8868\u793a\u504f\u5dee\u548c\u5e73\u8861\u5bf9\u6bd4\u635f\u5931\u6982\u5ff5\u6539\u5584\u81ea\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\u7684\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u5c06\u81ea\u76d1\u7763\u8868\u793a\u5b66\u4e60\u5f62\u5f0f\u5316\u4e3a\u76d1\u7763\u76ee\u6807\u7684\u8fd1\u4f3c\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u89c6\u89d2\uff0c\u89e3\u91ca\u4e86\u5bf9\u6bd4\u635f\u5931\u7684\u57fa\u672c\u539f\u7406\uff0c\u5e76\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u5e73\u8861\u6b63\u8d1f\u5bf9\u4ea4\u4e92\u7684\u6548\u679c\uff0c\u4e3a\u81ea\u76d1\u7763\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6491\u3002"}}
{"id": "2510.10586", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.10586", "abs": "https://arxiv.org/abs/2510.10586", "authors": ["Giulio Ruffini"], "title": "Compositional Symmetry as Compression: Lie Pseudogroup Structure in Algorithmic Agents", "comment": "Submitted to NeurReps 2025 (https://www.neurreps.org)", "summary": "In the algorithmic (Kolmogorov) view, agents are programs that track and\ncompress sensory streams using generative programs. We propose a framework\nwhere the relevant structural prior is simplicity (Solomonoff) understood as\n\\emph{compositional symmetry}: natural streams are well described by (local)\nactions of finite-parameter Lie pseudogroups on geometrically and topologically\ncomplex low-dimensional configuration manifolds (latent spaces). Modeling the\nagent as a generic neural dynamical system coupled to such streams, we show\nthat accurate world-tracking imposes (i) \\emph{structural constraints} --\nequivariance of the agent's constitutive equations and readouts -- and (ii)\n\\emph{dynamical constraints}: under static inputs, symmetry induces conserved\nquantities (Noether-style labels) in the agent dynamics and confines\ntrajectories to reduced invariant manifolds; under slow drift, these manifolds\nmove but remain low-dimensional. This yields a hierarchy of reduced manifolds\naligned with the compositional factorization of the pseudogroup, providing a\ngeometric account of the ``blessing of compositionality'' in deep models. We\nconnect these ideas to the Spencer formalism for Lie pseudogroups and formulate\na symmetry-based, self-contained version of predictive coding in which higher\nlayers receive only \\emph{coarse-grained residual transformations}\n(prediction-error coordinates) along symmetry directions unresolved at lower\nlayers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7ec4\u5408\u5bf9\u79f0\u6027\u7684\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u89c6\u4e3a\u8ddf\u8e2a\u548c\u538b\u7f29\u611f\u5b98\u6d41\u7684\u751f\u6210\u7a0b\u5e8f\uff0c\u901a\u8fc7\u674e\u4f2a\u7fa4\u7684\u5c40\u90e8\u4f5c\u7528\u6765\u63cf\u8ff0\u81ea\u7136\u6d41\u7684\u7ed3\u6784\u5148\u9a8c\u3002", "motivation": "\u4ece\u7b97\u6cd5\uff08Kolmogorov\uff09\u89c6\u89d2\u7406\u89e3\u667a\u80fd\u4f53\u5982\u4f55\u901a\u8fc7\u751f\u6210\u7a0b\u5e8f\u8ddf\u8e2a\u548c\u538b\u7f29\u611f\u5b98\u6d41\uff0c\u63a2\u7d22\u7ec4\u5408\u5bf9\u79f0\u6027\u4f5c\u4e3a\u7ed3\u6784\u5148\u9a8c\u5728\u63cf\u8ff0\u81ea\u7136\u6d41\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u5c06\u667a\u80fd\u4f53\u5efa\u6a21\u4e3a\u4e0e\u611f\u5b98\u6d41\u8026\u5408\u7684\u901a\u7528\u795e\u7ecf\u52a8\u529b\u7cfb\u7edf\uff0c\u5206\u6790\u51c6\u786e\u4e16\u754c\u8ddf\u8e2a\u65bd\u52a0\u7684\u7ed3\u6784\u7ea6\u675f\uff08\u672c\u6784\u65b9\u7a0b\u548c\u8bfb\u51fa\u7684\u7b49\u53d8\u6027\uff09\u548c\u52a8\u529b\u5b66\u7ea6\u675f\uff08\u5bf9\u79f0\u6027\u8bf1\u5bfc\u5b88\u6052\u91cf\u548c\u4f4e\u7ef4\u4e0d\u53d8\u6d41\u5f62\uff09\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u79f0\u6027\u5bfc\u81f4\u667a\u80fd\u4f53\u52a8\u529b\u5b66\u4e2d\u7684\u5b88\u6052\u91cf\uff08Noether\u98ce\u683c\u6807\u7b7e\uff09\uff0c\u5e76\u5c06\u8f68\u8ff9\u9650\u5236\u5728\u4f4e\u7ef4\u4e0d\u53d8\u6d41\u5f62\u4e0a\uff0c\u8fd9\u4e9b\u6d41\u5f62\u4e0e\u674e\u4f2a\u7fa4\u7684\u7ec4\u5408\u5206\u89e3\u5bf9\u9f50\uff0c\u4e3a\u6df1\u5ea6\u6a21\u578b\u7684\u7ec4\u5408\u6027\u63d0\u4f9b\u4e86\u51e0\u4f55\u89e3\u91ca\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5bf9\u79f0\u6027\u7684\u81ea\u5305\u542b\u9884\u6d4b\u7f16\u7801\u7248\u672c\uff0c\u5176\u4e2d\u9ad8\u5c42\u4ec5\u63a5\u6536\u6cbf\u5bf9\u79f0\u65b9\u5411\u7684\u7c97\u7c92\u5ea6\u6b8b\u5dee\u53d8\u6362\uff08\u9884\u6d4b\u8bef\u5dee\u5750\u6807\uff09\uff0c\u4e3a\u7406\u89e3\u667a\u80fd\u4f53\u5982\u4f55\u6709\u6548\u8ddf\u8e2a\u548c\u538b\u7f29\u611f\u5b98\u6d41\u63d0\u4f9b\u4e86\u51e0\u4f55\u6846\u67b6\u3002"}}
{"id": "2510.10604", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10604", "abs": "https://arxiv.org/abs/2510.10604", "authors": ["Yuheng Chen", "Dingkun Liu", "Xinyao Yang", "Xinping Xu", "Baicheng Chen", "Dongrui Wu"], "title": "FusionGen: Feature Fusion-Based Few-Shot EEG Data Generation", "comment": null, "summary": "Brain-computer interfaces (BCIs) provide potential for applications ranging\nfrom medical rehabilitation to cognitive state assessment by establishing\ndirect communication pathways between the brain and external devices via\nelectroencephalography (EEG). However, EEG-based BCIs are severely constrained\nby data scarcity and significant inter-subject variability, which hinder the\ngeneralization and applicability of EEG decoding models in practical settings.\nTo address these challenges, we propose FusionGen, a novel EEG data generation\nframework based on disentangled representation learning and feature fusion. By\nintegrating features across trials through a feature matching fusion module and\ncombining them with a lightweight feature extraction and reconstruction\npipeline, FusionGen ensures both data diversity and trainability under limited\ndata constraints. Extensive experiments on multiple publicly available EEG\ndatasets demonstrate that FusionGen significantly outperforms existing\naugmentation techniques, yielding notable improvements in classification\naccuracy.", "AI": {"tldr": "FusionGen\u662f\u4e00\u4e2a\u57fa\u4e8e\u89e3\u8026\u8868\u793a\u5b66\u4e60\u548c\u7279\u5f81\u878d\u5408\u7684\u65b0\u578bEEG\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u8111\u673a\u63a5\u53e3\u4e2dEEG\u6570\u636e\u7a00\u7f3a\u548c\u53d7\u8bd5\u8005\u95f4\u53d8\u5f02\u6027\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8de8\u8bd5\u9a8c\u7279\u5f81\u6574\u5408\u548c\u8f7b\u91cf\u7ea7\u7279\u5f81\u63d0\u53d6\u91cd\u5efa\u6d41\u7a0b\uff0c\u5728\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u786e\u4fdd\u6570\u636e\u591a\u6837\u6027\u548c\u53ef\u8bad\u7ec3\u6027\u3002", "motivation": "\u8111\u673a\u63a5\u53e3\u4e2d\u7684EEG\u6570\u636e\u7a00\u7f3a\u548c\u663e\u8457\u7684\u53d7\u8bd5\u8005\u95f4\u53d8\u5f02\u6027\u4e25\u91cd\u9650\u5236\u4e86EEG\u89e3\u7801\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9002\u7528\u6027\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51faFusionGen\u6846\u67b6\uff0c\u57fa\u4e8e\u89e3\u8026\u8868\u793a\u5b66\u4e60\u548c\u7279\u5f81\u878d\u5408\uff0c\u901a\u8fc7\u7279\u5f81\u5339\u914d\u878d\u5408\u6a21\u5757\u6574\u5408\u8de8\u8bd5\u9a8c\u7279\u5f81\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u7279\u5f81\u63d0\u53d6\u548c\u91cd\u5efa\u6d41\u7a0b\u751f\u6210EEG\u6570\u636e\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00EEG\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cFusionGen\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6570\u636e\u589e\u5f3a\u6280\u672f\uff0c\u5728\u5206\u7c7b\u51c6\u786e\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "FusionGen\u901a\u8fc7\u6709\u6548\u7684\u7279\u5f81\u878d\u5408\u548c\u8f7b\u91cf\u7ea7\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86EEG\u6570\u636e\u7a00\u7f3a\u548c\u53d8\u5f02\u6027\u95ee\u9898\uff0c\u4e3a\u8111\u673a\u63a5\u53e3\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6570\u636e\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10605", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10605", "abs": "https://arxiv.org/abs/2510.10605", "authors": ["MohammadHossein Bateni", "Hossein Esfandiari", "Samira HosseinGhorban", "Alireza Mirrokni", "Radin Shahdaei"], "title": "Budget Allocation for Unknown Value Functions in a Lipschitz Space", "comment": null, "summary": "Building learning models frequently requires evaluating numerous intermediate\nmodels. Examples include models considered during feature selection, model\nstructure search, and parameter tunings. The evaluation of an intermediate\nmodel influences subsequent model exploration decisions. Although prior\nknowledge can provide initial quality estimates, true performance is only\nrevealed after evaluation. In this work, we address the challenge of optimally\nallocating a bounded budget to explore the space of intermediate models. We\nformalize this as a general budget allocation problem over unknown-value\nfunctions within a Lipschitz space.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u6709\u9650\u9884\u7b97\u4e0b\u5982\u4f55\u6700\u4f18\u5206\u914d\u8d44\u6e90\u6765\u8bc4\u4f30\u4e2d\u95f4\u6a21\u578b\u7684\u95ee\u9898\uff0c\u5c06\u8fd9\u4e00\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u5728Lipschitz\u7a7a\u95f4\u4e2d\u5bf9\u672a\u77e5\u4ef7\u503c\u51fd\u6570\u7684\u9884\u7b97\u5206\u914d\u95ee\u9898\u3002", "motivation": "\u6784\u5efa\u5b66\u4e60\u6a21\u578b\u901a\u5e38\u9700\u8981\u8bc4\u4f30\u5927\u91cf\u4e2d\u95f4\u6a21\u578b\uff0c\u8fd9\u4e9b\u8bc4\u4f30\u7ed3\u679c\u4f1a\u5f71\u54cd\u540e\u7eed\u7684\u6a21\u578b\u63a2\u7d22\u51b3\u7b56\u3002\u867d\u7136\u5148\u9a8c\u77e5\u8bc6\u53ef\u4ee5\u63d0\u4f9b\u521d\u59cb\u8d28\u91cf\u4f30\u8ba1\uff0c\u4f46\u771f\u5b9e\u6027\u80fd\u53ea\u6709\u5728\u8bc4\u4f30\u540e\u624d\u80fd\u63ed\u793a\u3002", "method": "\u5c06\u4e2d\u95f4\u6a21\u578b\u63a2\u7d22\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u5728Lipschitz\u7a7a\u95f4\u4e2d\u5bf9\u672a\u77e5\u4ef7\u503c\u51fd\u6570\u7684\u4e00\u822c\u9884\u7b97\u5206\u914d\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u9884\u7b97\u5206\u914d\u6846\u67b6\u6765\u89e3\u51b3\u4e2d\u95f4\u6a21\u578b\u8bc4\u4f30\u7684\u4f18\u5316\u95ee\u9898\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u5728\u6709\u9650\u9884\u7b97\u4e0b\u6709\u6548\u63a2\u7d22\u4e2d\u95f4\u6a21\u578b\u7a7a\u95f4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684\u89e3\u51b3\u65b9\u6848\u6846\u67b6\u3002"}}
{"id": "2510.10617", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.10617", "abs": "https://arxiv.org/abs/2510.10617", "authors": ["Bahadur Yadav", "Sanjay Kumar Mohanty"], "title": "Encoder Decoder Generative Adversarial Network Model for Stock Market Prediction", "comment": null, "summary": "Forecasting stock prices remains challenging due to the volatile and\nnon-linear nature of financial markets. Despite the promise of deep learning,\nissues such as mode collapse, unstable training, and difficulty in capturing\ntemporal and feature level correlations have limited the applications of GANs\nin this domain. We propose a GRU-based Encoder-Decoder GAN (EDGAN) model that\nstrikes a balance between expressive power and simplicity. The model introduces\nkey innovations such as a temporal decoder with residual connections for\nprecise reconstruction, conditioning on static and dynamic covariates for\ncontextual learning, and a windowing mechanism to capture temporal dynamics.\nHere, the generator uses a dense encoder-decoder framework with residual GRU\nblocks. Extensive experiments on diverse stock datasets demonstrate that EDGAN\nachieves superior forecasting accuracy and training stability, even in volatile\nmarkets. It consistently outperforms traditional GAN variants in forecasting\naccuracy and convergence stability under market conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGRU\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668GAN\u6a21\u578b\uff08EDGAN\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u89e3\u7801\u5668\u3001\u6b8b\u5dee\u8fde\u63a5\u3001\u6761\u4ef6\u673a\u5236\u548c\u7a97\u53e3\u673a\u5236\uff0c\u5728\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u9762\u4e34\u5e02\u573a\u6ce2\u52a8\u6027\u548c\u975e\u7ebf\u6027\u6311\u6218\uff0c\u73b0\u6709GAN\u6a21\u578b\u5b58\u5728\u6a21\u5f0f\u5d29\u6e83\u3001\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u4ee5\u53ca\u96be\u4ee5\u6355\u6349\u65f6\u95f4\u548c\u7279\u5f81\u76f8\u5173\u6027\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eGRU\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5305\u542b\u6b8b\u5dee\u8fde\u63a5\u7684\u65f6\u95f4\u89e3\u7801\u5668\u3001\u9759\u6001\u548c\u52a8\u6001\u534f\u53d8\u91cf\u7684\u6761\u4ef6\u673a\u5236\uff0c\u4ee5\u53ca\u6355\u6349\u65f6\u95f4\u52a8\u6001\u7684\u7a97\u53e3\u673a\u5236\u3002\u751f\u6210\u5668\u91c7\u7528\u5bc6\u96c6\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6846\u67b6\u548c\u6b8b\u5deeGRU\u5757\u3002", "result": "\u5728\u591a\u6837\u5316\u80a1\u7968\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEDGAN\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5373\u4f7f\u5728\u6ce2\u52a8\u5e02\u573a\u4e2d\u4e5f\u80fd\u4fdd\u6301\u7a33\u5b9a\uff0c\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6536\u655b\u7a33\u5b9a\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u4f20\u7edfGAN\u53d8\u4f53\u3002", "conclusion": "EDGAN\u6a21\u578b\u5728\u8868\u8fbe\u80fd\u529b\u548c\u7b80\u5355\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u7a33\u5b9a\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u91d1\u878d\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9886\u57df\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.10621", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10621", "abs": "https://arxiv.org/abs/2510.10621", "authors": ["Hanbing Liu", "Yanru Wu", "Yang Li", "Ercan E. Kuruoglu", "Xuan Zhang"], "title": "SDG-L: A Semiparametric Deep Gaussian Process based Framework for Battery Capacity Prediction", "comment": null, "summary": "Lithium-ion batteries are becoming increasingly omnipresent in energy supply.\nHowever, the durability of energy storage using lithium-ion batteries is\nthreatened by their dropping capacity with the growing number of\ncharging/discharging cycles. An accurate capacity prediction is the key to\nensure system efficiency and reliability, where the exploitation of battery\nstate information in each cycle has been largely undervalued. In this paper, we\npropose a semiparametric deep Gaussian process regression framework named SDG-L\nto give predictions based on the modeling of time series battery state data. By\nintroducing an LSTM feature extractor, the SDG-L is specially designed to\nbetter utilize the auxiliary profiling information during charging/discharging\nprocess. In experimental studies based on NASA dataset, our proposed method\nobtains an average test MSE error of 1.2%. We also show that SDG-L achieves\nbetter performance compared to existing works and validate the framework using\nablation studies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSDG-L\u7684\u534a\u53c2\u6570\u6df1\u5ea6\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u4e8e\u65f6\u95f4\u5e8f\u5217\u7535\u6c60\u72b6\u6001\u6570\u636e\u5efa\u6a21\u6765\u9884\u6d4b\u9502\u79bb\u5b50\u7535\u6c60\u5bb9\u91cf\u8870\u51cf\u3002", "motivation": "\u9502\u79bb\u5b50\u7535\u6c60\u5728\u80fd\u6e90\u4f9b\u5e94\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u5bb9\u91cf\u968f\u5145\u653e\u7535\u5faa\u73af\u6b21\u6570\u589e\u52a0\u800c\u4e0b\u964d\u7684\u95ee\u9898\u5a01\u80c1\u7740\u50a8\u80fd\u7cfb\u7edf\u7684\u8010\u4e45\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u6bcf\u4e2a\u5faa\u73af\u4e2d\u7535\u6c60\u72b6\u6001\u4fe1\u606f\u7684\u5229\u7528\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u51c6\u786e\u7684\u5bb9\u91cf\u9884\u6d4b\u65b9\u6cd5\u6765\u786e\u4fdd\u7cfb\u7edf\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faSDG-L\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165LSTM\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u66f4\u597d\u5730\u5229\u7528\u5145\u653e\u7535\u8fc7\u7a0b\u4e2d\u7684\u8f85\u52a9\u5256\u9762\u4fe1\u606f\uff0c\u57fa\u4e8e\u65f6\u95f4\u5e8f\u5217\u7535\u6c60\u72b6\u6001\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u9884\u6d4b\u3002", "result": "\u5728\u57fa\u4e8eNASA\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u7814\u7a76\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u83b7\u5f97\u4e861.2%\u7684\u5e73\u5747\u6d4b\u8bd5MSE\u8bef\u5dee\uff0c\u76f8\u6bd4\u73b0\u6709\u5de5\u4f5c\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "SDG-L\u6846\u67b6\u80fd\u591f\u6709\u6548\u9884\u6d4b\u9502\u79bb\u5b50\u7535\u6c60\u5bb9\u91cf\u8870\u51cf\uff0c\u4e3a\u50a8\u80fd\u7cfb\u7edf\u7684\u53ef\u9760\u8fd0\u884c\u63d0\u4f9b\u4e86\u91cd\u8981\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2510.10634", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10634", "abs": "https://arxiv.org/abs/2510.10634", "authors": ["Shaoning Li", "Le Zhuo", "Yusong Wang", "Mingyu Li", "Xinheng He", "Fandi Wu", "Hongsheng Li", "Pheng-Ann Heng"], "title": "ProteinAE: Protein Diffusion Autoencoders for Structure Encoding", "comment": null, "summary": "Developing effective representations of protein structures is essential for\nadvancing protein science, particularly for protein generative modeling.\nCurrent approaches often grapple with the complexities of the SE(3) manifold,\nrely on discrete tokenization, or the need for multiple training objectives,\nall of which can hinder the model optimization and generalization. We introduce\nProteinAE, a novel and streamlined protein diffusion autoencoder designed to\novercome these challenges by directly mapping protein backbone coordinates from\nE(3) into a continuous, compact latent space. ProteinAE employs a\nnon-equivariant Diffusion Transformer with a bottleneck design for efficient\ncompression and is trained end-to-end with a single flow matching objective,\nsubstantially simplifying the optimization pipeline. We demonstrate that\nProteinAE achieves state-of-the-art reconstruction quality, outperforming\nexisting autoencoders. The resulting latent space serves as a powerful\nfoundation for a latent diffusion model that bypasses the need for explicit\nequivariance. This enables efficient, high-quality structure generation that is\ncompetitive with leading structure-based approaches and significantly\noutperforms prior latent-based methods. Code is available at\nhttps://github.com/OnlyLoveKFC/ProteinAE_v1.", "AI": {"tldr": "ProteinAE\u662f\u4e00\u79cd\u65b0\u9896\u7684\u86cb\u767d\u8d28\u6269\u6563\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5c06\u86cb\u767d\u8d28\u4e3b\u5e72\u5750\u6807\u4eceE(3)\u76f4\u63a5\u6620\u5c04\u5230\u8fde\u7eed\u7d27\u51d1\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u5728SE(3)\u6d41\u5f62\u590d\u6742\u6027\u3001\u79bb\u6563\u6807\u8bb0\u5316\u548c\u591a\u8bad\u7ec3\u76ee\u6807\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u5f00\u53d1\u6709\u6548\u7684\u86cb\u767d\u8d28\u7ed3\u6784\u8868\u793a\u5bf9\u4e8e\u63a8\u8fdb\u86cb\u767d\u8d28\u79d1\u5b66\u7279\u522b\u662f\u86cb\u767d\u8d28\u751f\u6210\u5efa\u6a21\u81f3\u5173\u91cd\u8981\u3002\u5f53\u524d\u65b9\u6cd5\u5728\u5904\u7406SE(3)\u6d41\u5f62\u590d\u6742\u6027\u3001\u4f9d\u8d56\u79bb\u6563\u6807\u8bb0\u5316\u6216\u9700\u8981\u591a\u4e2a\u8bad\u7ec3\u76ee\u6807\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u8fd9\u4e9b\u90fd\u963b\u788d\u4e86\u6a21\u578b\u4f18\u5316\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "ProteinAE\u91c7\u7528\u5177\u6709\u74f6\u9888\u8bbe\u8ba1\u7684\u975e\u7b49\u53d8\u6269\u6563\u53d8\u6362\u5668\u8fdb\u884c\u9ad8\u6548\u538b\u7f29\uff0c\u5e76\u901a\u8fc7\u5355\u4e00\u6d41\u5339\u914d\u76ee\u6807\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u663e\u8457\u7b80\u5316\u4e86\u4f18\u5316\u6d41\u7a0b\u3002", "result": "ProteinAE\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u91cd\u5efa\u8d28\u91cf\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u81ea\u7f16\u7801\u5668\u3002\u751f\u6210\u7684\u6f5c\u5728\u7a7a\u95f4\u4e3a\u6f5c\u5728\u6269\u6563\u6a21\u578b\u63d0\u4f9b\u4e86\u5f3a\u5927\u57fa\u7840\uff0c\u65e0\u9700\u663e\u5f0f\u7b49\u53d8\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u9ad8\u8d28\u91cf\u7684\u7ed3\u6784\u751f\u6210\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u7ed3\u6784\u751f\u6210\u65b9\u9762\u4e0e\u9886\u5148\u7684\u7ed3\u6784\u57fa\u65b9\u6cd5\u7ade\u4e89\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u6f5c\u5728\u57fa\u65b9\u6cd5\uff0c\u4e3a\u86cb\u767d\u8d28\u7ed3\u6784\u8868\u793a\u548c\u751f\u6210\u63d0\u4f9b\u4e86\u7b80\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10645", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10645", "abs": "https://arxiv.org/abs/2510.10645", "authors": ["Michal Sadowski", "Maria Wyrzykowska", "Lukasz Sztukiewicz", "Tadija Radusinovi\u0107", "Jan Rzymkowski", "Pawe\u0142 W\u0142odarczyk-Pruszy\u0144ski", "Miko\u0142aj Sacha", "Piotr Kozakowski", "Ruard van Workum", "Stanislaw Kamil Jastrzebski"], "title": "Trustworthy Retrosynthesis: Eliminating Hallucinations with a Diverse Ensemble of Reaction Scorers", "comment": null, "summary": "Retrosynthesis is one of the domains transformed by the rise of generative\nmodels, and it is one where the problem of nonsensical or erroneous outputs\n(hallucinations) is particularly insidious: reliable assessment of synthetic\nplans is time-consuming, with automatic methods lacking. In this work, we\npresent RetroTrim, a retrosynthesis system that successfully avoids nonsensical\nplans on a set of challenging drug-like targets. Compared to common baselines\nin the field, our system is not only the sole method that succeeds in filtering\nout hallucinated reactions, but it also results in the highest number of\nhigh-quality paths overall. The key insight behind RetroTrim is the combination\nof diverse reaction scoring strategies, based on machine learning models and\nexisting chemical databases. We show that our scoring strategies capture\ndifferent classes of hallucinations by analyzing them on a dataset of labeled\nretrosynthetic intermediates. To measure the performance of retrosynthesis\nsystems, we propose a novel evaluation protocol for reactions and synthetic\npaths based on a structured review by expert chemists. Using this protocol, we\ncompare systems on a set of 32 novel targets, curated to reflect recent trends\nin drug structures. While the insights behind our methodology are broadly\napplicable to retrosynthesis, our focus is on targets in the drug-like domain.\nBy releasing our benchmark targets and the details of our evaluation protocol,\nwe hope to inspire further research into reliable retrosynthesis.", "AI": {"tldr": "RetroTrim\u662f\u4e00\u4e2a\u9006\u5408\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u53cd\u5e94\u8bc4\u5206\u7b56\u7565\u6210\u529f\u907f\u514d\u751f\u6210\u65e0\u610f\u4e49\u7684\u5408\u6210\u8ba1\u5212\uff0c\u5728\u836f\u7269\u7c7b\u76ee\u6807\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u9006\u5408\u6210\u9886\u57df\u4e2d\u751f\u6210\u6a21\u578b\u4f1a\u4ea7\u751f\u65e0\u610f\u4e49\u6216\u9519\u8bef\u7684\u8f93\u51fa\uff08\u5e7b\u89c9\uff09\uff0c\u800c\u53ef\u9760\u7684\u5408\u6210\u8ba1\u5212\u8bc4\u4f30\u8017\u65f6\u4e14\u7f3a\u4e4f\u81ea\u52a8\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u73b0\u6709\u5316\u5b66\u6570\u636e\u5e93\u7684\u591a\u6837\u5316\u53cd\u5e94\u8bc4\u5206\u7b56\u7565\uff0c\u901a\u8fc7\u4e13\u5bb6\u5316\u5b66\u5bb6\u7684\u7ed3\u6784\u5316\u8bc4\u5ba1\u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\u3002", "result": "RetroTrim\u662f\u552f\u4e00\u80fd\u6210\u529f\u8fc7\u6ee4\u5e7b\u89c9\u53cd\u5e94\u7684\u65b9\u6cd5\uff0c\u572832\u4e2a\u65b0\u9896\u836f\u7269\u76ee\u6807\u4e0a\u4ea7\u751f\u6700\u591a\u9ad8\u8d28\u91cf\u5408\u6210\u8def\u5f84\u3002", "conclusion": "RetroTrim\u901a\u8fc7\u591a\u6837\u5316\u8bc4\u5206\u7b56\u7565\u6709\u6548\u89e3\u51b3\u9006\u5408\u6210\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5176\u65b9\u6cd5\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u9006\u5408\u6210\u9886\u57df\uff0c\u7279\u522b\u662f\u836f\u7269\u7c7b\u76ee\u6807\u3002"}}
{"id": "2510.10694", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10694", "abs": "https://arxiv.org/abs/2510.10694", "authors": ["Ying-Kuan Tsai", "Vispi Karkaria", "Yi-Ping Chen", "Wei Chen"], "title": "Digital Twin-enabled Multi-generation Control Co-Design with Deep Reinforcement Learning", "comment": "to be published in Journal of Mechanical Design", "summary": "Control Co-Design (CCD) integrates physical and control system design to\nimprove the performance of dynamic and autonomous systems. Despite advances in\nuncertainty-aware CCD methods, real-world uncertainties remain highly\nunpredictable. Multi-generation design addresses this challenge by considering\nthe full lifecycle of a product: data collected from each generation informs\nthe design of subsequent generations, enabling progressive improvements in\nrobustness and efficiency. Digital Twin (DT) technology further strengthens\nthis paradigm by creating virtual representations that evolve over the\nlifecycle through real-time sensing, model updating, and adaptive\nre-optimization. This paper presents a DT-enabled CCD framework that integrates\nDeep Reinforcement Learning (DRL) to jointly optimize physical design and\ncontroller. DRL accelerates real-time decision-making by allowing controllers\nto continuously learn from data and adapt to uncertain environments. Extending\nthis approach, the framework employs a multi-generation paradigm, where each\ncycle of deployment, operation, and redesign uses collected data to refine DT\nmodels, improve uncertainty quantification through quantile regression, and\ninform next-generation designs of both physical components and controllers. The\nframework is demonstrated on an active suspension system, where DT-enabled\nlearning from road conditions and driving behaviors yields smoother and more\nstable control trajectories. Results show that the method significantly\nenhances dynamic performance, robustness, and efficiency. Contributions of this\nwork include: (1) extending CCD into a lifecycle-oriented multi-generation\nframework, (2) leveraging DTs for continuous model updating and informed\ndesign, and (3) employing DRL to accelerate adaptive real-time decision-making.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u8d4b\u80fd\u7684\u63a7\u5236\u534f\u540c\u8bbe\u8ba1\uff08CCD\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u6765\u8054\u5408\u4f18\u5316\u7269\u7406\u8bbe\u8ba1\u548c\u63a7\u5236\u5668\uff0c\u91c7\u7528\u591a\u4ee3\u8bbe\u8ba1\u8303\u5f0f\u901a\u8fc7\u6570\u636e\u6536\u96c6\u548c\u6a21\u578b\u66f4\u65b0\u5b9e\u73b0\u6e10\u8fdb\u5f0f\u6539\u8fdb\u3002", "motivation": "\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u4e0d\u786e\u5b9a\u6027\u9ad8\u5ea6\u4e0d\u53ef\u9884\u6d4b\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u4ee3\u8bbe\u8ba1\u548c\u6570\u5b57\u5b6a\u751f\u6280\u672f\u6765\u5e94\u5bf9\u52a8\u6001\u81ea\u4e3b\u7cfb\u7edf\u7684\u5168\u751f\u547d\u5468\u671f\u6311\u6218\uff0c\u5b9e\u73b0\u9c81\u68d2\u6027\u548c\u6548\u7387\u7684\u6301\u7eed\u63d0\u5347\u3002", "method": "\u96c6\u6210\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u8fdb\u884c\u7269\u7406\u8bbe\u8ba1\u548c\u63a7\u5236\u5668\u7684\u8054\u5408\u4f18\u5316\uff0c\u91c7\u7528\u591a\u4ee3\u8bbe\u8ba1\u8303\u5f0f\uff0c\u6bcf\u4e2a\u90e8\u7f72\u3001\u64cd\u4f5c\u548c\u91cd\u65b0\u8bbe\u8ba1\u5468\u671f\u90fd\u4f7f\u7528\u6536\u96c6\u7684\u6570\u636e\u6765\u7cbe\u70bc\u6570\u5b57\u5b6a\u751f\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u4f4d\u6570\u56de\u5f52\u6539\u8fdb\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u5e76\u4e3a\u4e0b\u4e00\u4ee3\u7269\u7406\u7ec4\u4ef6\u548c\u63a7\u5236\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4fe1\u606f\u3002", "result": "\u5728\u4e3b\u52a8\u60ac\u67b6\u7cfb\u7edf\u4e0a\u7684\u6f14\u793a\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4ece\u9053\u8def\u6761\u4ef6\u548c\u9a7e\u9a76\u884c\u4e3a\u4e2d\u5b66\u4e60\uff0c\u4ea7\u751f\u4e86\u66f4\u5e73\u6ed1\u548c\u66f4\u7a33\u5b9a\u7684\u63a7\u5236\u8f68\u8ff9\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u52a8\u6001\u6027\u80fd\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u7684\u8d21\u732e\u5305\u62ec\uff1a\uff081\uff09\u5c06CCD\u6269\u5c55\u5230\u9762\u5411\u751f\u547d\u5468\u671f\u7684\u591a\u4ee3\u6846\u67b6\uff0c\uff082\uff09\u5229\u7528DT\u8fdb\u884c\u8fde\u7eed\u6a21\u578b\u66f4\u65b0\u548c\u77e5\u60c5\u8bbe\u8ba1\uff0c\uff083\uff09\u91c7\u7528DRL\u52a0\u901f\u81ea\u9002\u5e94\u5b9e\u65f6\u51b3\u7b56\u5236\u5b9a\u3002"}}
{"id": "2510.10702", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10702", "abs": "https://arxiv.org/abs/2510.10702", "authors": ["Usman Gani Joy", "Shahadat kabir", "Tasnim Niger"], "title": "Attention-Enhanced LSTM Modeling for Improved Temperature and Rainfall Forecasting in Bangladesh", "comment": null, "summary": "Accurate climate forecasting is vital for Bangladesh, a region highly\nsusceptible to climate change impacts on temperature and rainfall. Existing\nmodels often struggle to capture long-range dependencies and complex temporal\npatterns in climate data. This study introduces an advanced Long Short-Term\nMemory (LSTM) model integrated with an attention mechanism to enhance the\nprediction of temperature and rainfall dynamics. Utilizing comprehensive\ndatasets from 1901-2023, sourced from NASA's POWER Project for temperature and\nthe Humanitarian Data Exchange for rainfall, the model effectively captures\nseasonal and long-term trends. It outperforms baseline models, including\nXGBoost, Simple LSTM, and GRU, achieving a test MSE of 0.2411 (normalized\nunits), MAE of 0.3860 degrees C, R^2 of 0.9834, and NRMSE of 0.0370 for\ntemperature, and MSE of 1283.67 mm^2, MAE of 22.91 mm, R^2 of 0.9639, and NRMSE\nof 0.0354 for rainfall on monthly forecasts. The model demonstrates improved\nrobustness with only a 20 percent increase in MSE under simulated climate\ntrends (compared to an approximately 2.2-fold increase in baseline models\nwithout trend features) and a 50 percent degradation under regional variations\n(compared to an approximately 4.8-fold increase in baseline models without\nenhancements). These results highlight the model's ability to improve\nforecasting precision and offer potential insights into the physical processes\ngoverning climate variability in Bangladesh, supporting applications in\nclimate-sensitive sectors.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u7684\u9ad8\u7ea7LSTM\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u9ad8\u5b5f\u52a0\u62c9\u56fd\u6e29\u5ea6\u548c\u964d\u96e8\u91cf\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002\u8be5\u6a21\u578b\u57281901-2023\u5e74\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u6e29\u5ea6\u548c\u964d\u96e8\u91cf\u7684\u6708\u5ea6\u9884\u6d4b\u4e2d\u5747\u8d85\u8d8a\u4e86XGBoost\u3001Simple LSTM\u548cGRU\u7b49\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u5b5f\u52a0\u62c9\u56fd\u662f\u6781\u6613\u53d7\u6c14\u5019\u53d8\u5316\u5f71\u54cd\u7684\u5730\u533a\uff0c\u51c6\u786e\u7684\u5929\u6c14\u9884\u62a5\u5bf9\u5f53\u5730\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6a21\u578b\u5f80\u5f80\u96be\u4ee5\u6355\u6349\u6c14\u5019\u6570\u636e\u4e2d\u7684\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u548c\u590d\u6742\u65f6\u95f4\u6a21\u5f0f\u3002", "method": "\u91c7\u7528\u96c6\u6210\u6ce8\u610f\u529b\u673a\u5236\u7684\u9ad8\u7ea7LSTM\u6a21\u578b\uff0c\u5229\u7528NASA POWER\u9879\u76ee\u7684\u6e29\u5ea6\u6570\u636e\u548cHDX\u7684\u964d\u96e8\u6570\u636e\uff081901-2023\u5e74\uff09\uff0c\u6709\u6548\u6355\u6349\u5b63\u8282\u6027\u548c\u957f\u671f\u8d8b\u52bf\u3002", "result": "\u5728\u6e29\u5ea6\u9884\u6d4b\u4e2d\u8fbe\u5230\u6d4b\u8bd5MSE 0.2411\u3001MAE 0.3860\u00b0C\u3001R\u00b2 0.9834\u3001NRMSE 0.0370\uff1b\u5728\u964d\u96e8\u91cf\u9884\u6d4b\u4e2d\u8fbe\u5230MSE 1283.67 mm\u00b2\u3001MAE 22.91 mm\u3001R\u00b2 0.9639\u3001NRMSE 0.0354\u3002\u5728\u6a21\u62df\u6c14\u5019\u8d8b\u52bf\u4e0bMSE\u4ec5\u589e\u52a020%\uff0c\u5728\u533a\u57df\u53d8\u5316\u4e0b\u6027\u80fd\u4e0b\u964d50%\uff0c\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4e3a\u7406\u89e3\u5b5f\u52a0\u62c9\u56fd\u6c14\u5019\u53d8\u7387\u7684\u7269\u7406\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u6f5c\u5728\u89c1\u89e3\uff0c\u652f\u6301\u6c14\u5019\u654f\u611f\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2510.10730", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10730", "abs": "https://arxiv.org/abs/2510.10730", "authors": ["Jiazheng Sun", "Weixin Wang", "Pan Xu"], "title": "Provable Anytime Ensemble Sampling Algorithms in Nonlinear Contextual Bandits", "comment": "40 pages, 1 figure", "summary": "We provide a unified algorithmic framework for ensemble sampling in nonlinear\ncontextual bandits and develop corresponding regret bounds for two most common\nnonlinear contextual bandit settings: Generalized Linear Ensemble Sampling\n(\\texttt{GLM-ES}) for generalized linear bandits and Neural Ensemble Sampling\n(\\texttt{Neural-ES}) for neural contextual bandits. Both methods maintain\nmultiple estimators for the reward model parameters via maximum likelihood\nestimation on randomly perturbed data. We prove high-probability frequentist\nregret bounds of $\\mathcal{O}(d^{3/2} \\sqrt{T} + d^{9/2})$ for \\texttt{GLM-ES}\nand $\\mathcal{O}(\\widetilde{d} \\sqrt{T})$ for \\texttt{Neural-ES}, where $d$ is\nthe dimension of feature vectors, $\\widetilde{d}$ is the effective dimension of\na neural tangent kernel matrix, and $T$ is the number of rounds. These regret\nbounds match the state-of-the-art results of randomized exploration algorithms\nin nonlinear contextual bandit settings. In the theoretical analysis, we\nintroduce techniques that address challenges specific to nonlinear models.\nPractically, we remove fixed-time horizon assumptions by developing anytime\nversions of our algorithms, suitable when $T$ is unknown. Finally, we\nempirically evaluate \\texttt{GLM-ES}, \\texttt{Neural-ES}, and their anytime\nvariants, demonstrating strong performance. Overall, our results establish\nensemble sampling as a provable and practical randomized exploration approach\nfor nonlinear contextual bandits.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u96c6\u6210\u91c7\u6837\u7b97\u6cd5\u6846\u67b6\uff0c\u7528\u4e8e\u975e\u7ebf\u6027\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u5305\u62ecGLM-ES\uff08\u5e7f\u4e49\u7ebf\u6027\u96c6\u6210\u91c7\u6837\uff09\u548cNeural-ES\uff08\u795e\u7ecf\u96c6\u6210\u91c7\u6837\uff09\u4e24\u79cd\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5e94\u7684\u9057\u61be\u754c\u5206\u6790\u3002", "motivation": "\u89e3\u51b3\u975e\u7ebf\u6027\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u4e2d\u7684\u968f\u673a\u63a2\u7d22\u95ee\u9898\uff0c\u4e3a\u5e7f\u4e49\u7ebf\u6027\u8d4c\u535a\u673a\u548c\u795e\u7ecf\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u63d0\u4f9b\u7edf\u4e00\u7684\u7b97\u6cd5\u6846\u67b6\u548c\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5728\u968f\u673a\u6270\u52a8\u6570\u636e\u4e0a\u7ef4\u62a4\u591a\u4e2a\u5956\u52b1\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u5668\uff0c\u5f00\u53d1\u4e86GLM-ES\u548cNeural-ES\u4e24\u79cd\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u65e0\u56fa\u5b9a\u65f6\u95f4\u5047\u8bbe\u7684\u968f\u65f6\u7248\u672c\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e86GLM-ES\u7684\u9057\u61be\u754c\u4e3aO(d^{3/2}\u221aT + d^{9/2})\uff0cNeural-ES\u7684\u9057\u61be\u754c\u4e3aO(\u02dcd\u221aT)\uff0c\u5176\u4e2dd\u662f\u7279\u5f81\u5411\u91cf\u7ef4\u5ea6\uff0c\u02dcd\u662f\u795e\u7ecf\u6b63\u5207\u6838\u77e9\u9635\u7684\u6709\u6548\u7ef4\u5ea6\uff0cT\u662f\u8f6e\u6570\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e0e\u975e\u7ebf\u6027\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u4e2d\u968f\u673a\u63a2\u7d22\u7b97\u6cd5\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u76f8\u5339\u914d\u3002", "conclusion": "\u96c6\u6210\u91c7\u6837\u88ab\u786e\u7acb\u4e3a\u975e\u7ebf\u6027\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u4e2d\u53ef\u8bc1\u660e\u4e14\u5b9e\u7528\u7684\u968f\u673a\u63a2\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.10739", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.10739", "abs": "https://arxiv.org/abs/2510.10739", "authors": ["Shivani Shukla", "Himanshu Joshi"], "title": "A Stochastic Differential Equation Framework for Multi-Objective LLM Interactions: Dynamical Systems Analysis with Code Generation Applications", "comment": "Peer-reviewed and accepted to the 39th Conference on Neural\n  Information Processing Systems (NeurIPS 2025) DynaFront 2025 Workshop\n  (https://sites.google.com/view/dynafrontneurips25)", "summary": "We introduce a general stochastic differential equation framework for\nmodelling multiobjective optimization dynamics in iterative Large Language\nModel (LLM) interactions. Our framework captures the inherent stochasticity of\nLLM responses through explicit diffusion terms and reveals systematic\ninterference patterns between competing objectives via an interference matrix\nformulation. We validate our theoretical framework using iterative code\ngeneration as a proof-of-concept application, analyzing 400 sessions across\nsecurity, efficiency, and functionality objectives. Our results demonstrate\nstrategy-dependent convergence behaviors with rates ranging from 0.33 to 1.29,\nand predictive accuracy achieving R2 = 0.74 for balanced approaches. This work\nproposes the feasibility of dynamical systems analysis for multi-objective LLM\ninteractions, with code generation serving as an initial validation domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u6846\u67b6\u6765\u5efa\u6a21\u5927\u8bed\u8a00\u6a21\u578b\u591a\u76ee\u6807\u4f18\u5316\u52a8\u6001\uff0c\u901a\u8fc7\u6269\u6563\u9879\u6355\u6349LLM\u54cd\u5e94\u7684\u968f\u673a\u6027\uff0c\u4f7f\u7528\u5e72\u6270\u77e9\u9635\u63ed\u793a\u76ee\u6807\u95f4\u7684\u7cfb\u7edf\u6027\u5e72\u6270\u6a21\u5f0f\uff0c\u5e76\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fed\u4ee3\u4ea4\u4e92\u4e2d\u5b58\u5728\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5730\u5efa\u6a21\u5176\u52a8\u6001\u884c\u4e3a\u548c\u76ee\u6807\u95f4\u7684\u5e72\u6270\u6548\u5e94\uff0c\u4ee5\u7406\u89e3LLM\u5728\u591a\u76ee\u6807\u573a\u666f\u4e0b\u7684\u6536\u655b\u7279\u6027\u3002", "method": "\u91c7\u7528\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u6846\u67b6\uff0c\u5305\u542b\u663e\u5f0f\u6269\u6563\u9879\u6765\u6355\u6349LLM\u54cd\u5e94\u7684\u968f\u673a\u6027\uff0c\u901a\u8fc7\u5e72\u6270\u77e9\u9635\u63cf\u8ff0\u7ade\u4e89\u76ee\u6807\u95f4\u7684\u7cfb\u7edf\u6027\u5e72\u6270\uff0c\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8fdb\u884c400\u6b21\u4f1a\u8bdd\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u7b56\u7565\u4f9d\u8d56\u7684\u6536\u655b\u884c\u4e3a\uff0c\u6536\u655b\u7387\u57280.33\u52301.29\u4e4b\u95f4\uff0c\u5e73\u8861\u65b9\u6cd5\u7684\u9884\u6d4b\u51c6\u786e\u7387\u8fbe\u5230R\u00b2=0.74\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8bc1\u660e\u4e86\u52a8\u6001\u7cfb\u7edf\u5206\u6790\u5728\u591a\u76ee\u6807LLM\u4ea4\u4e92\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4ee3\u7801\u751f\u6210\u4e3a\u521d\u6b65\u9a8c\u8bc1\u9886\u57df\uff0c\u4e3a\u7406\u89e3LLM\u591a\u76ee\u6807\u4f18\u5316\u52a8\u6001\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.10767", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.10767", "abs": "https://arxiv.org/abs/2510.10767", "authors": ["Jiayuan Sheng", "Hanyang Zhao", "Haoxian Chen", "David D. Yao", "Wenpin Tang"], "title": "Understanding Sampler Stochasticity in Training Diffusion Models for RLHF", "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) is increasingly used to\nfine-tune diffusion models, but a key challenge arises from the mismatch\nbetween stochastic samplers used during training and deterministic samplers\nused during inference. In practice, models are fine-tuned using stochastic SDE\nsamplers to encourage exploration, while inference typically relies on\ndeterministic ODE samplers for efficiency and stability. This discrepancy\ninduces a reward gap, raising concerns about whether high-quality outputs can\nbe expected during inference. In this paper, we theoretically characterize this\nreward gap and provide non-vacuous bounds for general diffusion models, along\nwith sharper convergence rates for Variance Exploding (VE) and Variance\nPreserving (VP) Gaussian models. Methodologically, we adopt the generalized\ndenoising diffusion implicit models (gDDIM) framework to support arbitrarily\nhigh levels of stochasticity, preserving data marginals throughout.\nEmpirically, our findings through large-scale experiments on text-to-image\nmodels using denoising diffusion policy optimization (DDPO) and mixed group\nrelative policy optimization (MixGRPO) validate that reward gaps consistently\nnarrow over training, and ODE sampling quality improves when models are updated\nusing higher-stochasticity SDE training.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86RLHF\u5728\u6269\u6563\u6a21\u578b\u4e2d\u8bad\u7ec3\u4e0e\u63a8\u7406\u9636\u6bb5\u91c7\u6837\u5668\u4e0d\u5339\u914d\u5bfc\u81f4\u7684\u5956\u52b1\u5dee\u8ddd\u95ee\u9898\uff0c\u4ece\u7406\u8bba\u4e0a\u7ed9\u51fa\u4e86\u5956\u52b1\u5dee\u8ddd\u7684\u8fb9\u754c\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u9ad8\u968f\u673a\u6027SDE\u8bad\u7ec3\u80fd\u6539\u5584ODE\u91c7\u6837\u8d28\u91cf\u3002", "motivation": "RLHF\u5728\u6269\u6563\u6a21\u578b\u5fae\u8c03\u4e2d\u9762\u4e34\u8bad\u7ec3\u65f6\u4f7f\u7528\u968f\u673aSDE\u91c7\u6837\u5668\u4e0e\u63a8\u7406\u65f6\u4f7f\u7528\u786e\u5b9a\u6027ODE\u91c7\u6837\u5668\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u8fd9\u79cd\u5dee\u5f02\u5bfc\u81f4\u5956\u52b1\u5dee\u8ddd\uff0c\u5f15\u53d1\u5bf9\u63a8\u7406\u9636\u6bb5\u8f93\u51fa\u8d28\u91cf\u7684\u62c5\u5fe7\u3002", "method": "\u91c7\u7528\u5e7f\u4e49\u53bb\u566a\u6269\u6563\u9690\u5f0f\u6a21\u578b(gDDIM)\u6846\u67b6\u652f\u6301\u4efb\u610f\u9ad8\u6c34\u5e73\u7684\u968f\u673a\u6027\uff0c\u4fdd\u6301\u6570\u636e\u8fb9\u9645\u5206\u5e03\uff1b\u901a\u8fc7\u7406\u8bba\u5206\u6790\u7ed9\u51fa\u5956\u52b1\u5dee\u8ddd\u7684\u975e\u7a7a\u8fb9\u754c\uff0c\u5e76\u5bf9VE\u548cVP\u9ad8\u65af\u6a21\u578b\u63d0\u4f9b\u66f4\u5c16\u9510\u7684\u6536\u655b\u7387\u3002", "result": "\u5927\u89c4\u6a21\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u5b9e\u9a8c\u4f7f\u7528DDPO\u548cMixGRPO\u9a8c\u8bc1\u4e86\u5956\u52b1\u5dee\u8ddd\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6301\u7eed\u7f29\u5c0f\uff0c\u5f53\u4f7f\u7528\u66f4\u9ad8\u968f\u673a\u6027\u7684SDE\u8bad\u7ec3\u66f4\u65b0\u6a21\u578b\u65f6\uff0cODE\u91c7\u6837\u8d28\u91cf\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u8bad\u7ec3\u4e0e\u63a8\u7406\u91c7\u6837\u5668\u4e0d\u5339\u914d\u5bfc\u81f4\u7684\u5956\u52b1\u5dee\u8ddd\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5f97\u5230\u89e3\u51b3\uff0c\u9ad8\u968f\u673a\u6027SDE\u8bad\u7ec3\u6709\u52a9\u4e8e\u63d0\u5347\u63a8\u7406\u9636\u6bb5ODE\u91c7\u6837\u7684\u8f93\u51fa\u8d28\u91cf\u3002"}}
{"id": "2510.10777", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.10777", "abs": "https://arxiv.org/abs/2510.10777", "authors": ["Andrey Veprikov", "Arman Bolatov", "Samuel Horv\u00e1th", "Aleksandr Beznosikov", "Martin Tak\u00e1\u010d", "Slavomir Hanzely"], "title": "Preconditioned Norms: A Unified Framework for Steepest Descent, Quasi-Newton and Adaptive Methods", "comment": "22 pages, 2 figures, 8 tables", "summary": "Optimization lies at the core of modern deep learning, yet existing methods\noften face a fundamental trade-off between adapting to problem geometry and\nleveraging curvature utilization. Steepest descent algorithms adapt to\ndifferent geometries through norm choices but remain strictly first-order,\nwhereas quasi-Newton and adaptive optimizers incorporate curvature information\nbut are restricted to Frobenius geometry, limiting their applicability across\ndiverse architectures. In this work, we propose a unified framework\ngeneralizing steepest descent, quasi-Newton methods, and adaptive methods\nthrough the novel notion of preconditioned matrix norms. This abstraction\nreveals that widely used optimizers such as SGD and Adam, as well as more\nadvanced approaches like Muon and KL-Shampoo, and recent hybrids including SOAP\nand SPlus, all emerge as special cases of the same principle. Within this\nframework, we provide the first systematic treatment of affine and scale\ninvariance in the matrix-parameterized setting, establishing necessary and\nsufficient conditions under generalized norms. Building on this foundation, we\nintroduce two new methods, $\\texttt{MuAdam}$ and $\\texttt{MuAdam-SANIA}$, which\ncombine the spectral geometry of Muon with Adam-style preconditioning. Our\nexperiments demonstrate that these optimizers are competitive with, and in some\ncases outperform, existing state-of-the-art methods. Our code is available at\nhttps://github.com/brain-lab-research/LIB/tree/quasi_descent", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6761\u4ef6\u77e9\u9635\u8303\u6570\u5c06\u6700\u901f\u4e0b\u964d\u6cd5\u3001\u62df\u725b\u987f\u6cd5\u548c\u81ea\u9002\u5e94\u65b9\u6cd5\u7edf\u4e00\u8d77\u6765\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u79cd\u65b0\u4f18\u5316\u5668MuAdam\u548cMuAdam-SANIA\u3002", "motivation": "\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u5728\u9002\u5e94\u95ee\u9898\u51e0\u4f55\u548c\u5229\u7528\u66f2\u7387\u4fe1\u606f\u4e4b\u95f4\u5b58\u5728\u57fa\u672c\u6743\u8861\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u517c\u987e\u4e24\u8005\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u9884\u6761\u4ef6\u77e9\u9635\u8303\u6570\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u591a\u79cd\u4f18\u5316\u5668\u7edf\u4e00\u4e3a\u540c\u4e00\u539f\u7406\u7684\u7279\u4f8b\uff0c\u5e76\u5f15\u5165\u7ed3\u5408Muon\u8c31\u51e0\u4f55\u548cAdam\u98ce\u683c\u9884\u6761\u4ef6\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u65b0\u4f18\u5316\u5668\u4e0e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4f18\u5316\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7edf\u4e00\u89c6\u89d2\uff0c\u65b0\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.10790", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10790", "abs": "https://arxiv.org/abs/2510.10790", "authors": ["Zhongju Yuan", "Geraint Wiggins", "Dick Botteldooren"], "title": "BioOSS: A Bio-Inspired Oscillatory State System with Spatio-Temporal Dynamics", "comment": null, "summary": "Today's deep learning architectures are primarily based on perceptron models,\nwhich do not capture the oscillatory dynamics characteristic of biological\nneurons. Although oscillatory systems have recently gained attention for their\ncloser resemblance to neural behavior, they still fall short of modeling the\nintricate spatio-temporal interactions observed in natural neural circuits. In\nthis paper, we propose a bio-inspired oscillatory state system (BioOSS)\ndesigned to emulate the wave-like propagation dynamics critical to neural\nprocessing, particularly in the prefrontal cortex (PFC), where complex activity\npatterns emerge. BioOSS comprises two interacting populations of neurons: p\nneurons, which represent simplified membrane-potential-like units inspired by\npyramidal cells in cortical columns, and o neurons, which govern propagation\nvelocities and modulate the lateral spread of activity. Through local\ninteractions, these neurons produce wave-like propagation patterns. The model\nincorporates trainable parameters for damping and propagation speed, enabling\nflexible adaptation to task-specific spatio-temporal structures. We evaluate\nBioOSS on both synthetic and real-world tasks, demonstrating superior\nperformance and enhanced interpretability compared to alternative\narchitectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u751f\u7269\u542f\u53d1\u7684\u632f\u8361\u72b6\u6001\u7cfb\u7edf\uff08BioOSS\uff09\uff0c\u6a21\u62df\u795e\u7ecf\u5904\u7406\u4e2d\u7684\u6ce2\u72b6\u4f20\u64ad\u52a8\u529b\u5b66\uff0c\u7279\u522b\u662f\u5728\u524d\u989d\u53f6\u76ae\u5c42\u4e2d\u89c2\u5bdf\u5230\u7684\u590d\u6742\u6d3b\u52a8\u6a21\u5f0f\u3002\u8be5\u7cfb\u7edf\u5305\u542b\u4e24\u79cd\u76f8\u4e92\u4f5c\u7528\u7684\u795e\u7ecf\u5143\u7fa4\u4f53\uff0c\u901a\u8fc7\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u4ea7\u751f\u6ce2\u72b6\u4f20\u64ad\u6a21\u5f0f\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4e3b\u8981\u57fa\u4e8e\u611f\u77e5\u5668\u6a21\u578b\uff0c\u65e0\u6cd5\u6355\u6349\u751f\u7269\u795e\u7ecf\u5143\u7684\u632f\u8361\u52a8\u529b\u5b66\u7279\u6027\u3002\u867d\u7136\u632f\u8361\u7cfb\u7edf\u56e0\u5176\u66f4\u63a5\u8fd1\u795e\u7ecf\u884c\u4e3a\u800c\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u4ecd\u65e0\u6cd5\u6a21\u62df\u81ea\u7136\u795e\u7ecf\u56de\u8def\u4e2d\u89c2\u5bdf\u5230\u7684\u590d\u6742\u65f6\u7a7a\u76f8\u4e92\u4f5c\u7528\u3002", "method": "BioOSS\u5305\u542b\u4e24\u79cd\u76f8\u4e92\u4f5c\u7528\u7684\u795e\u7ecf\u5143\u7fa4\u4f53\uff1ap\u795e\u7ecf\u5143\uff08\u4ee3\u8868\u7b80\u5316\u7684\u819c\u7535\u4f4d\u5355\u5143\uff0c\u53d7\u76ae\u8d28\u67f1\u4e2d\u9525\u4f53\u7ec6\u80de\u542f\u53d1\uff09\u548co\u795e\u7ecf\u5143\uff08\u63a7\u5236\u4f20\u64ad\u901f\u5ea6\u5e76\u8c03\u8282\u6d3b\u52a8\u7684\u6a2a\u5411\u6269\u6563\uff09\u3002\u901a\u8fc7\u5c40\u90e8\u76f8\u4e92\u4f5c\u7528\u4ea7\u751f\u6ce2\u72b6\u4f20\u64ad\u6a21\u5f0f\uff0c\u6a21\u578b\u5305\u542b\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\u7528\u4e8e\u963b\u5c3c\u548c\u4f20\u64ad\u901f\u5ea6\uff0c\u80fd\u591f\u7075\u6d3b\u9002\u5e94\u4efb\u52a1\u7279\u5b9a\u7684\u65f6\u7a7a\u7ed3\u6784\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cBioOSS\u76f8\u6bd4\u5176\u4ed6\u67b6\u6784\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u589e\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "BioOSS\u6210\u529f\u6a21\u62df\u4e86\u795e\u7ecf\u5904\u7406\u4e2d\u7684\u6ce2\u72b6\u4f20\u64ad\u52a8\u529b\u5b66\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u63a5\u8fd1\u751f\u7269\u795e\u7ecf\u884c\u4e3a\u4e14\u5177\u6709\u66f4\u597d\u53ef\u89e3\u91ca\u6027\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u3002"}}
{"id": "2510.10799", "categories": ["cs.LG", "physics.ao-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.10799", "abs": "https://arxiv.org/abs/2510.10799", "authors": ["Wanshu Nie", "Sujay V. Kumar", "Junyu Chen", "Long Zhao", "Olya Skulovich", "Jinwoong Yoo", "Justin Pflug", "Shahryar Khalique Ahmad", "Goutam Konapala"], "title": "Rethinking deep learning: linear regression remains a key benchmark in predicting terrestrial water storage", "comment": null, "summary": "Recent advances in machine learning such as Long Short-Term Memory (LSTM)\nmodels and Transformers have been widely adopted in hydrological applications,\ndemonstrating impressive performance amongst deep learning models and\noutperforming physical models in various tasks. However, their superiority in\npredicting land surface states such as terrestrial water storage (TWS) that are\ndominated by many factors such as natural variability and human driven\nmodifications remains unclear. Here, using the open-access, globally\nrepresentative HydroGlobe dataset - comprising a baseline version derived\nsolely from a land surface model simulation and an advanced version\nincorporating multi-source remote sensing data assimilation - we show that\nlinear regression is a robust benchmark, outperforming the more complex LSTM\nand Temporal Fusion Transformer for TWS prediction. Our findings highlight the\nimportance of including traditional statistical models as benchmarks when\ndeveloping and evaluating deep learning models. Additionally, we emphasize the\ncritical need to establish globally representative benchmark datasets that\ncapture the combined impact of natural variability and human interventions.", "AI": {"tldr": "\u7ebf\u6027\u56de\u5f52\u5728\u9646\u5730\u6c34\u50a8\u91cf\u9884\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u590d\u6742\u7684LSTM\u548cTemporal Fusion Transformer\u6a21\u578b\uff0c\u5f3a\u8c03\u4e86\u5728\u8bc4\u4f30\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65f6\u5305\u542b\u4f20\u7edf\u7edf\u8ba1\u57fa\u51c6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8bc4\u4f30\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5982LSTM\u548cTransformer\uff09\u5728\u9884\u6d4b\u53d7\u591a\u79cd\u56e0\u7d20\uff08\u81ea\u7136\u53d8\u5f02\u6027\u548c\u4eba\u7c7b\u6d3b\u52a8\uff09\u5f71\u54cd\u7684\u9646\u5730\u6c34\u50a8\u91cf\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5e76\u786e\u5b9a\u5176\u76f8\u5bf9\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "method": "\u4f7f\u7528HydroGlobe\u6570\u636e\u96c6\uff08\u5305\u62ec\u4ec5\u6765\u81ea\u5730\u8868\u6a21\u578b\u6a21\u62df\u7684\u57fa\u51c6\u7248\u672c\u548c\u7ed3\u5408\u591a\u6e90\u9065\u611f\u6570\u636e\u540c\u5316\u7684\u9ad8\u7ea7\u7248\u672c\uff09\uff0c\u6bd4\u8f83\u7ebf\u6027\u56de\u5f52\u3001LSTM\u548cTemporal Fusion Transformer\u5728TWS\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\u3002", "result": "\u7ebf\u6027\u56de\u5f52\u5728TWS\u9884\u6d4b\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u4f18\u4e8e\u66f4\u590d\u6742\u7684LSTM\u548cTemporal Fusion Transformer\u6a21\u578b\u3002", "conclusion": "\u5728\u5f00\u53d1\u548c\u8bc4\u4f30\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65f6\uff0c\u5fc5\u987b\u5305\u542b\u4f20\u7edf\u7edf\u8ba1\u6a21\u578b\u4f5c\u4e3a\u57fa\u51c6\uff0c\u5e76\u5efa\u7acb\u80fd\u6355\u6349\u81ea\u7136\u53d8\u5f02\u6027\u548c\u4eba\u7c7b\u5e72\u9884\u7efc\u5408\u5f71\u54cd\u7684\u5168\u7403\u4ee3\u8868\u6027\u57fa\u51c6\u6570\u636e\u96c6\u3002"}}
{"id": "2510.10803", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10803", "abs": "https://arxiv.org/abs/2510.10803", "authors": ["Javier Garc\u00eda-Sig\u00fcenza", "Mirco Nanni", "Fara\u00f3n Llorens-Largo", "Jos\u00e9 F. Vicent"], "title": "PruneGCRN: Minimizing and explaining spatio-temporal problems through node pruning", "comment": null, "summary": "This work addresses the challenge of using a deep learning model to prune\ngraphs and the ability of this method to integrate explainability into\nspatio-temporal problems through a new approach. Instead of applying\nexplainability to the model's behavior, we seek to gain a better understanding\nof the problem itself. To this end, we propose a novel model that integrates an\noptimized pruning mechanism capable of removing nodes from the graph during the\ntraining process, rather than doing so as a separate procedure. This\nintegration allows the architecture to learn how to minimize prediction error\nwhile selecting the most relevant nodes. Thus, during training, the model\nsearches for the most relevant subset of nodes, obtaining the most important\nelements of the problem, facilitating its analysis. To evaluate the proposed\napproach, we used several widely used traffic datasets, comparing the accuracy\nobtained by pruning with the model and with other methods. The experiments\ndemonstrate that our method is capable of retaining a greater amount of\ninformation as the graph reduces in size compared to the other methods used.\nThese results highlight the potential of pruning as a tool for developing\nmodels capable of simplifying spatio-temporal problems, thereby obtaining their\nmost important elements.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u96c6\u6210\u4f18\u5316\u526a\u679d\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u80fd\u591f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a8\u6001\u79fb\u9664\u56fe\u8282\u70b9\uff0c\u4ece\u800c\u9009\u62e9\u6700\u76f8\u5173\u8282\u70b9\u5e76\u6700\u5c0f\u5316\u9884\u6d4b\u8bef\u5dee\uff0c\u7528\u4e8e\u65f6\u7a7a\u95ee\u9898\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u56fe\u526a\u679d\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u65b0\u65b9\u6cd5\u5c06\u53ef\u89e3\u91ca\u6027\u878d\u5165\u65f6\u7a7a\u95ee\u9898\uff0c\u65e8\u5728\u66f4\u597d\u5730\u7406\u89e3\u95ee\u9898\u672c\u8eab\u800c\u975e\u6a21\u578b\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u6a21\u578b\uff0c\u96c6\u6210\u4f18\u5316\u7684\u526a\u679d\u673a\u5236\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u800c\u975e\u5355\u72ec\u8fc7\u7a0b\u4e2d\u79fb\u9664\u56fe\u8282\u70b9\uff0c\u4f7f\u67b6\u6784\u80fd\u591f\u5b66\u4e60\u5982\u4f55\u6700\u5c0f\u5316\u9884\u6d4b\u8bef\u5dee\u540c\u65f6\u9009\u62e9\u6700\u76f8\u5173\u8282\u70b9\u3002", "result": "\u5728\u591a\u4e2a\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u5176\u4ed6\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u56fe\u5c3a\u5bf8\u51cf\u5c0f\u65f6\u4fdd\u7559\u66f4\u591a\u4fe1\u606f\uff0c\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u526a\u679d\u4f5c\u4e3a\u5f00\u53d1\u80fd\u591f\u7b80\u5316\u65f6\u7a7a\u95ee\u9898\u6a21\u578b\u7684\u6709\u529b\u5de5\u5177\uff0c\u5177\u6709\u83b7\u53d6\u95ee\u9898\u6700\u91cd\u8981\u5143\u7d20\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.10807", "categories": ["cs.LG", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2510.10807", "abs": "https://arxiv.org/abs/2510.10807", "authors": ["Ali Atiah Alzahrani"], "title": "Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation", "comment": "Code available at: https://github.com/AliAtiah/MARCD", "summary": "We study whether regime-conditioned generative scenarios, coupled with a\nconvex CVaR allocator, improve portfolio decisions under regime shifts. We\nintroduce Multi-Agent Regime-Conditioned Diffusion (MARCD), which (i) infers\nlatent regimes via a Gaussian HMM, (ii) trains a diffusion model with a\ntail-weighted objective and a regime-specialized mixture-of-experts (MoE)\ndenoiser to enrich crisis co-movements, and (iii) feeds the generated scenarios\ninto a turnover-aware CVaR epigraph quadratic program with explicit governance.\nIn strict walk-forward tests on liquid multi-asset ETFs (2005-2025), MARCD\noutperforms standard allocators and improves calibration relative to popular\ngenerators. Over 2020-2025 out-of-sample (monthly; 10 bps), MARCD attains\nSharpe 1.23 (BL 1.02) and MaxDD 9.3 percent (BL 14.1 percent), a 34 percent\nreduction, at comparable turnover; stationary block-bootstrap intervals\nindicate the Sharpe uplift is significant at 5 percent. We provide theory\nlinking tail-weighted diffusion to spectral-risk control of the\ndecision-relevant CVaR gap, oracle/consistency results for the regime-MoE\ndenoiser, and Lipschitz/regret guarantees for the allocator. Together, MARCD\noffers a reproducible bridge from tail-faithful scenario modeling to governed\nportfolio decisions with materially improved drawdown control.", "AI": {"tldr": "MARCD\u662f\u4e00\u79cd\u7ed3\u5408\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u8bc6\u522b\u5e02\u573a\u72b6\u6001\u3001\u6269\u6563\u6a21\u578b\u751f\u6210\u60c5\u666f\u548cCVaR\u4f18\u5316\u5668\u7684\u6295\u8d44\u7ec4\u5408\u7ba1\u7406\u65b9\u6cd5\uff0c\u5728\u4e25\u683c\u7684\u524d\u5411\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u590f\u666e\u6bd4\u7387\u5e76\u964d\u4f4e\u4e86\u6700\u5927\u56de\u64a4\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5e02\u573a\u72b6\u6001\u8f6c\u6362\u4e0b\u6295\u8d44\u7ec4\u5408\u51b3\u7b56\u7684\u6311\u6218\uff0c\u901a\u8fc7\u72b6\u6001\u6761\u4ef6\u751f\u6210\u60c5\u666f\u548cCVaR\u5206\u914d\u5668\u6765\u6539\u5584\u5c3e\u90e8\u98ce\u9669\u7ba1\u7406\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u63a8\u65ad\u6f5c\u5728\u5e02\u573a\u72b6\u6001\uff0c\u8bad\u7ec3\u5177\u6709\u5c3e\u90e8\u52a0\u6743\u76ee\u6807\u548c\u72b6\u6001\u4e13\u4e1a\u5316\u6df7\u5408\u4e13\u5bb6\u53bb\u566a\u5668\u7684\u6269\u6563\u6a21\u578b\uff0c\u5e76\u5c06\u751f\u6210\u7684\u60c5\u666f\u8f93\u5165\u5230\u8003\u8651\u6362\u624b\u7387\u7684CVaR\u4e8c\u6b21\u89c4\u5212\u4e2d\u3002", "result": "\u57282005-2025\u5e74\u6d41\u52a8\u6027\u591a\u8d44\u4ea7ETF\u7684\u4e25\u683c\u524d\u5411\u6d4b\u8bd5\u4e2d\uff0cMARCD\u5b9e\u73b0\u4e86\u590f\u666e\u6bd4\u73871.23\uff08\u57fa\u51c61.02\uff09\uff0c\u6700\u5927\u56de\u64a49.3%\uff08\u57fa\u51c614.1%\uff09\uff0c\u6362\u624b\u7387\u76f8\u5f53\u3002", "conclusion": "MARCD\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece\u5c3e\u90e8\u5fe0\u5b9e\u60c5\u666f\u5efa\u6a21\u5230\u53d7\u6cbb\u7406\u6295\u8d44\u7ec4\u5408\u51b3\u7b56\u7684\u53ef\u590d\u73b0\u6865\u6881\uff0c\u663e\u8457\u6539\u5584\u4e86\u56de\u64a4\u63a7\u5236\u3002"}}
{"id": "2510.10810", "categories": ["cs.LG", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.10810", "abs": "https://arxiv.org/abs/2510.10810", "authors": ["Omar Islam Laskar", "Fatemeh Ramezani Khozestani", "Ishika Nankani", "Sohrab Namazi Nia", "Senjuti Basu Roy", "Kaustubh Beedkar"], "title": "Aegis: A Correlation-Based Data Masking Advisor for Data Sharing Ecosystems", "comment": "Accepted at SIGMOD 2026", "summary": "Data-sharing ecosystems enable entities -- such as providers, consumers, and\nintermediaries -- to access, exchange, and utilize data for various downstream\ntasks and applications. Due to privacy concerns, data providers typically\nanonymize datasets before sharing them; however, the existence of multiple\nmasking configurations results in masked datasets with varying utility.\nConsequently, a key challenge lies in efficiently determining the optimal\nmasking configuration that maximizes a dataset's utility. This paper presents\nAEGIS, a middleware framework for identifying the optimal masking configuration\nfor machine learning datasets that consist of features and a class label. We\nintroduce a utility optimizer that minimizes predictive utility deviation -- a\nmetric based on the changes in feature-label correlations before and after\nmasking. Our framework leverages limited data summaries (such as 1D histograms)\nor none to estimate the feature-label joint distribution, making it suitable\nfor scenarios where raw data is inaccessible due to privacy restrictions. To\nachieve this, we propose a joint distribution estimator based on iterative\nproportional fitting, which allows supporting various feature-label correlation\nquantification methods such as g3, mutual information, or chi-square. Our\nexperimental evaluation on real-world datasets shows that AEGIS identifies\noptimal masking configurations over an order of magnitude faster, while the\nresulting masked datasets achieve predictive performance on downstream ML tasks\nthat is on par with baseline approaches.", "AI": {"tldr": "AEGIS\u662f\u4e00\u4e2a\u4e2d\u95f4\u4ef6\u6846\u67b6\uff0c\u7528\u4e8e\u4e3a\u5305\u542b\u7279\u5f81\u548c\u7c7b\u522b\u6807\u7b7e\u7684\u673a\u5668\u5b66\u4e60\u6570\u636e\u96c6\u8bc6\u522b\u6700\u4f18\u7684\u63a9\u7801\u914d\u7f6e\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u6d4b\u6548\u7528\u504f\u5dee\u6765\u4f18\u5316\u6570\u636e\u6548\u7528\uff0c\u540c\u65f6\u652f\u6301\u5728\u539f\u59cb\u6570\u636e\u4e0d\u53ef\u8bbf\u95ee\u7684\u60c5\u51b5\u4e0b\u5de5\u4f5c\u3002", "motivation": "\u7531\u4e8e\u9690\u79c1\u95ee\u9898\uff0c\u6570\u636e\u63d0\u4f9b\u8005\u901a\u5e38\u5728\u5171\u4eab\u6570\u636e\u524d\u8fdb\u884c\u533f\u540d\u5316\u5904\u7406\uff0c\u4f46\u4e0d\u540c\u7684\u63a9\u7801\u914d\u7f6e\u4f1a\u5bfc\u81f4\u6570\u636e\u6548\u7528\u4e0d\u540c\u3002\u5173\u952e\u6311\u6218\u5728\u4e8e\u9ad8\u6548\u786e\u5b9a\u6700\u5927\u5316\u6570\u636e\u96c6\u6548\u7528\u7684\u6700\u4f18\u63a9\u7801\u914d\u7f6e\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8fed\u4ee3\u6bd4\u4f8b\u62df\u5408\u7684\u8054\u5408\u5206\u5e03\u4f30\u8ba1\u5668\uff0c\u5229\u7528\u6709\u9650\u6570\u636e\u6458\u8981\u6216\u65e0\u6570\u636e\u6765\u4f30\u8ba1\u7279\u5f81-\u6807\u7b7e\u8054\u5408\u5206\u5e03\uff0c\u652f\u6301\u591a\u79cd\u7279\u5f81-\u6807\u7b7e\u76f8\u5173\u6027\u91cf\u5316\u65b9\u6cd5\uff08\u5982g3\u3001\u4e92\u4fe1\u606f\u3001\u5361\u65b9\u68c0\u9a8c\uff09\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0cAEGIS\u8bc6\u522b\u6700\u4f18\u63a9\u7801\u914d\u7f6e\u7684\u901f\u5ea6\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5feb\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u540c\u65f6\u751f\u6210\u7684\u63a9\u7801\u6570\u636e\u96c6\u5728\u4e0b\u6e38\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\u7684\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "AEGIS\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u8bc6\u522b\u6700\u4f18\u63a9\u7801\u914d\u7f6e\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u6570\u636e\u6548\u7528\uff0c\u9002\u7528\u4e8e\u539f\u59cb\u6570\u636e\u4e0d\u53ef\u8bbf\u95ee\u7684\u9690\u79c1\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2510.10849", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10849", "abs": "https://arxiv.org/abs/2510.10849", "authors": ["Donald Loveland", "Yao-An Yang", "Danai Koutra"], "title": "Glance for Context: Learning When to Leverage LLMs for Node-Aware GNN-LLM Fusion", "comment": null, "summary": "Learning on text-attributed graphs has motivated the use of Large Language\nModels (LLMs) for graph learning. However, most fusion strategies are applied\nuniformly across all nodes and attain only small overall performance gains. We\nargue this result stems from aggregate metrics that obscure when LLMs provide\nbenefit, inhibiting actionable signals for new strategies. In this work, we\nreframe LLM-GNN fusion around nodes where GNNs typically falter. We first show\nthat performance can significantly differ between GNNs and LLMs, with each\nexcelling on distinct structural patterns, such as local homophily. To leverage\nthis finding, we propose GLANCE (GNN with LLM Assistance for Neighbor- and\nContext-aware Embeddings), a framework that invokes an LLM to refine a GNN's\nprediction. GLANCE employs a lightweight router that, given inexpensive\nper-node signals, decides whether to query the LLM. Since the LLM calls are\nnon-differentiable, the router is trained with an advantage-based objective\nthat compares the utility of querying the LLM against relying solely on the\nGNN. Across multiple benchmarks, GLANCE achieves the best performance balance\nacross node subgroups, achieving significant gains on heterophilous nodes (up\nto $+13\\%$) while simultaneously achieving top overall performance. Our\nfindings highlight the value of adaptive, node-aware GNN-LLM architectures,\nwhere selectively invoking the LLM enables scalable deployment on large graphs\nwithout incurring high computational costs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGLANCE\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u9009\u62e9\u6027\u8c03\u7528LLM\u6765\u6539\u8fdbGNN\u5728\u7279\u5b9a\u8282\u70b9\u4e0a\u7684\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5728GNN\u8868\u73b0\u8f83\u5dee\u7684\u5f02\u914d\u6027\u8282\u70b9\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709LLM-GNN\u878d\u5408\u7b56\u7565\u5bf9\u6240\u6709\u8282\u70b9\u7edf\u4e00\u5e94\u7528\uff0c\u6574\u4f53\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u56e0\u4e3a\u805a\u5408\u6307\u6807\u63a9\u76d6\u4e86LLM\u4f55\u65f6\u771f\u6b63\u63d0\u4f9b\u5e2e\u52a9\uff0c\u963b\u788d\u4e86\u65b0\u7b56\u7565\u7684\u5f00\u53d1\u3002", "method": "\u63d0\u51faGLANCE\u6846\u67b6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8def\u7531\u5668\u57fa\u4e8e\u6bcf\u4e2a\u8282\u70b9\u7684\u5ec9\u4ef7\u4fe1\u53f7\u51b3\u5b9a\u662f\u5426\u67e5\u8be2LLM\u3002\u8def\u7531\u5668\u901a\u8fc7\u4f18\u52bf\u76ee\u6807\u8bad\u7ec3\uff0c\u6bd4\u8f83\u67e5\u8be2LLM\u4e0e\u4ec5\u4f9d\u8d56GNN\u7684\u6548\u7528\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cGLANCE\u5728\u8282\u70b9\u5b50\u7ec4\u95f4\u5b9e\u73b0\u4e86\u6700\u4f73\u6027\u80fd\u5e73\u8861\uff0c\u5728\u5f02\u914d\u6027\u8282\u70b9\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff08\u6700\u9ad8+13%\uff09\uff0c\u540c\u65f6\u8fbe\u5230\u9876\u7ea7\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u81ea\u9002\u5e94\u3001\u8282\u70b9\u611f\u77e5\u7684GNN-LLM\u67b6\u6784\u7684\u4ef7\u503c\uff0c\u9009\u62e9\u6027\u8c03\u7528LLM\u53ef\u4ee5\u5728\u4e0d\u4ea7\u751f\u9ad8\u8ba1\u7b97\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u5728\u5927\u56fe\u4e0a\u5b9e\u73b0\u53ef\u6269\u5c55\u90e8\u7f72\u3002"}}
{"id": "2510.10854", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10854", "abs": "https://arxiv.org/abs/2510.10854", "authors": ["Aadithya Srikanth", "Mudit Gaur", "Vaneet Aggarwal"], "title": "Discrete State Diffusion Models: A Sample Complexity Perspective", "comment": null, "summary": "Diffusion models have demonstrated remarkable performance in generating\nhigh-dimensional samples across domains such as vision, language, and the\nsciences. Although continuous-state diffusion models have been extensively\nstudied both empirically and theoretically, discrete-state diffusion models,\nessential for applications involving text, sequences, and combinatorial\nstructures, remain significantly less understood from a theoretical standpoint.\nIn particular, all existing analyses of discrete-state models assume score\nestimation error bounds without studying sample complexity results. In this\nwork, we present a principled theoretical framework for discrete-state\ndiffusion, providing the first sample complexity bound of\n$\\widetilde{\\mathcal{O}}(\\epsilon^{-2})$. Our structured decomposition of the\nscore estimation error into statistical, approximation, optimization, and\nclipping components offers critical insights into how discrete-state models can\nbe trained efficiently. This analysis addresses a fundamental gap in the\nliterature and establishes the theoretical tractability and practical relevance\nof discrete-state diffusion models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u79bb\u6563\u72b6\u6001\u6269\u6563\u6a21\u578b\u7684\u7b2c\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u5bf9\u79bb\u6563\u72b6\u6001\u6269\u6563\u6a21\u578b\u7406\u8bba\u7406\u89e3\u4e0d\u8db3\u7684\u7a7a\u767d\u3002", "motivation": "\u8fde\u7eed\u72b6\u6001\u6269\u6563\u6a21\u578b\u5df2\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u5f97\u5230\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u79bb\u6563\u72b6\u6001\u6269\u6563\u6a21\u578b\uff08\u5728\u6587\u672c\u3001\u5e8f\u5217\u548c\u7ec4\u5408\u7ed3\u6784\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\uff09\u5728\u7406\u8bba\u5c42\u9762\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\u3002\u73b0\u6709\u5206\u6790\u90fd\u5047\u8bbe\u5206\u6570\u4f30\u8ba1\u8bef\u5dee\u754c\u9650\uff0c\u800c\u6ca1\u6709\u7814\u7a76\u6837\u672c\u590d\u6742\u5ea6\u7ed3\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u79bb\u6563\u72b6\u6001\u6269\u6563\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u5206\u6570\u4f30\u8ba1\u8bef\u5dee\u5206\u89e3\u4e3a\u7edf\u8ba1\u3001\u8fd1\u4f3c\u3001\u4f18\u5316\u548c\u88c1\u526a\u7b49\u7ed3\u6784\u5316\u7ec4\u4ef6\u3002", "result": "\u83b7\u5f97\u4e86\u6837\u672c\u590d\u6742\u5ea6\u754c\u9650\u4e3a$\\widetilde{\\mathcal{O}}(\\epsilon^{-2})$\uff0c\u8fd9\u662f\u79bb\u6563\u72b6\u6001\u6269\u6563\u6a21\u578b\u7684\u7b2c\u4e00\u4e2a\u6837\u672c\u590d\u6742\u5ea6\u7ed3\u679c\u3002", "conclusion": "\u8be5\u5206\u6790\u586b\u8865\u4e86\u6587\u732e\u4e2d\u7684\u57fa\u672c\u7a7a\u767d\uff0c\u786e\u7acb\u4e86\u79bb\u6563\u72b6\u6001\u6269\u6563\u6a21\u578b\u7684\u7406\u8bba\u53ef\u5904\u7406\u6027\u548c\u5b9e\u9645\u76f8\u5173\u6027\uff0c\u4e3a\u9ad8\u6548\u8bad\u7ec3\u79bb\u6563\u72b6\u6001\u6a21\u578b\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2510.10862", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2510.10862", "abs": "https://arxiv.org/abs/2510.10862", "authors": ["Samuel Yuan", "Divyanshu Saxena", "Jiayi Chen", "Nihal Sharma", "Aditya Akella"], "title": "A Joint Learning Approach to Hardware Caching and Prefetching", "comment": "Accepted at ML for Systems Workshop at the 39th Conference on Neural\n  Information Processing Systems (NeurIPS 2025)", "summary": "Several learned policies have been proposed to replace heuristics for\nscheduling, caching, and other system components in modern systems. By\nleveraging diverse features, learning from historical trends, and predicting\nfuture behaviors, such models promise to keep pace with ever-increasing\nworkload dynamism and continuous hardware evolution. However, policies trained\nin isolation may still achieve suboptimal performance when placed together. In\nthis paper, we inspect one such instance in the domain of hardware caching --\nfor the policies of cache replacement and prefetching. We argue that these two\npolicies are bidirectionally interdependent and make the case for training the\ntwo jointly. We propose a joint learning approach based on developing shared\nrepresentations for the features used by the two policies. We present two\napproaches to develop these shared representations, one based on a joint\nencoder and another based on contrastive learning of the embeddings, and\ndemonstrate promising preliminary results for both of these. Finally, we lay\ndown an agenda for future research in this direction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u5b66\u4e60\u65b9\u6cd5\u6765\u4f18\u5316\u786c\u4ef6\u7f13\u5b58\u4e2d\u7684\u66ff\u6362\u7b56\u7565\u548c\u9884\u53d6\u7b56\u7565\uff0c\u901a\u8fc7\u5f00\u53d1\u5171\u4eab\u7279\u5f81\u8868\u793a\u6765\u89e3\u51b3\u8fd9\u4e24\u4e2a\u7b56\u7565\u4e4b\u95f4\u7684\u53cc\u5411\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u7684\u5b66\u4e60\u7b56\u7565\u867d\u7136\u5728\u5355\u72ec\u8bad\u7ec3\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5f53\u591a\u4e2a\u7b56\u7565\u5171\u540c\u90e8\u7f72\u65f6\u53ef\u80fd\u8fbe\u5230\u6b21\u4f18\u6027\u80fd\u3002\u7279\u522b\u662f\u5728\u786c\u4ef6\u7f13\u5b58\u9886\u57df\uff0c\u7f13\u5b58\u66ff\u6362\u548c\u9884\u53d6\u7b56\u7565\u4e4b\u95f4\u5b58\u5728\u53cc\u5411\u4f9d\u8d56\u5173\u7cfb\uff0c\u9700\u8981\u8054\u5408\u8bad\u7ec3\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u6574\u4f53\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5171\u4eab\u7279\u5f81\u8868\u793a\u7684\u8054\u5408\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u62ec\u4e24\u79cd\u5177\u4f53\u5b9e\u73b0\uff1a\u57fa\u4e8e\u8054\u5408\u7f16\u7801\u5668\u7684\u65b9\u6cd5\u548c\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u5d4c\u5165\u65b9\u6cd5\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u90fd\u5c55\u793a\u4e86\u6709\u524d\u666f\u7684\u521d\u6b65\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u8054\u5408\u5b66\u4e60\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u4e3a\u672a\u6765\u5728\u8fd9\u4e00\u65b9\u5411\u7684\u7814\u7a76\u5236\u5b9a\u4e86\u8bae\u7a0b\uff0c\u5f3a\u8c03\u4e86\u8054\u5408\u5b66\u4e60\u5728\u4f18\u5316\u7cfb\u7edf\u7ec4\u4ef6\u6027\u80fd\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.10902", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10902", "abs": "https://arxiv.org/abs/2510.10902", "authors": ["Mahmoud Abdelghafar", "Maryam Aliakbarpour", "Chris Jermaine"], "title": "Quantifying Information Disclosure During Gradient Descent Using Gradient Uniqueness", "comment": null, "summary": "Disclosing private information via publication of a machine learning model is\noften a concern. Intuitively, publishing a learned model should be less risky\nthan publishing a dataset. But how much risk is there? In this paper, we\npresent a principled disclosure metric called \\emph{gradient uniqueness} that\nis derived from an upper bound on the amount of information disclosure from\npublishing a learned model. Gradient uniqueness provides an intuitive way to\nperform privacy auditing. The mathematical derivation of gradient uniqueness is\ngeneral, and does not make any assumption on the model architecture, dataset\ntype, or the strategy of an attacker. We examine a simple defense based on\nmonitoring gradient uniqueness, and find that it achieves privacy comparable to\nclassical methods such as DP-SGD, while being substantially better in terms of\n(utility) testing accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u68af\u5ea6\u552f\u4e00\u6027\u7684\u9690\u79c1\u62ab\u9732\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u53d1\u5e03\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65f6\u7684\u9690\u79c1\u98ce\u9669\uff0c\u5e76\u53d1\u73b0\u57fa\u4e8e\u8be5\u65b9\u6cd5\u7684\u7b80\u5355\u9632\u5fa1\u7b56\u7565\u5728\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u4e0a\u4e0eDP-SGD\u76f8\u5f53\uff0c\u4f46\u5728\u6d4b\u8bd5\u51c6\u786e\u7387\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u53d1\u5e03\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65f6\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u91cf\u5316\u8fd9\u79cd\u98ce\u9669\uff0c\u56e0\u4e3a\u76f4\u89c9\u4e0a\u53d1\u5e03\u6a21\u578b\u5e94\u8be5\u6bd4\u53d1\u5e03\u6570\u636e\u96c6\u98ce\u9669\u66f4\u5c0f\uff0c\u4f46\u5177\u4f53\u98ce\u9669\u7a0b\u5ea6\u672a\u77e5\u3002", "method": "\u63d0\u51fa\u68af\u5ea6\u552f\u4e00\u6027\u8fd9\u4e00\u9690\u79c1\u62ab\u9732\u5ea6\u91cf\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u53d1\u5e03\u5b66\u4e60\u6a21\u578b\u65f6\u4fe1\u606f\u6cc4\u9732\u91cf\u7684\u4e0a\u754c\u63a8\u5bfc\u800c\u6765\uff0c\u4e0d\u4f9d\u8d56\u6a21\u578b\u67b6\u6784\u3001\u6570\u636e\u96c6\u7c7b\u578b\u6216\u653b\u51fb\u8005\u7b56\u7565\u7684\u5047\u8bbe\u3002", "result": "\u57fa\u4e8e\u68af\u5ea6\u552f\u4e00\u6027\u76d1\u63a7\u7684\u7b80\u5355\u9632\u5fa1\u7b56\u7565\u5728\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u4e0e\u7ecf\u5178\u65b9\u6cd5DP-SGD\u76f8\u5f53\uff0c\u4f46\u5728\u6d4b\u8bd5\u51c6\u786e\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8eDP-SGD\u3002", "conclusion": "\u68af\u5ea6\u552f\u4e00\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u76f4\u89c2\u7684\u9690\u79c1\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u5176\u6570\u5b66\u63a8\u5bfc\u5177\u6709\u666e\u9002\u6027\uff0c\u57fa\u4e8e\u8be5\u65b9\u6cd5\u7684\u9632\u5fa1\u7b56\u7565\u5728\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6548\u7528\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2510.10915", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10915", "abs": "https://arxiv.org/abs/2510.10915", "authors": ["Hanchang Cheng", "Weimin Mu", "Fan Liu", "Weilin Zhu", "Can Ma"], "title": "LPCVAE: A Conditional VAE with Long-Term Dependency and Probabilistic Time-Frequency Fusion for Time Series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection(TSAD) is a critical task in signal processing\nfield, ensuring the reliability of complex systems. Reconstruction-based\nmethods dominate in TSAD. Among these methods, VAE-based methods have achieved\npromising results. Existing VAE-based methods suffer from the limitation of\nsingle-window feature and insufficient leveraging of long-term time and\nfrequency information. We propose a Conditional Variational AutoEncoder with\nLong-term dependency and Probabilistic time-frequency fusion, named LPCVAE.\nLPCVAE introduces LSTM to capture long-term dependencies beyond windows. It\nfurther incorporates a Product-of-Experts (PoE) mechanism for adaptive and\ndistribution-level probabilistic fusion. This design effectively mitigates\ntime-frequency information loss. Extensive experiments on four public datasets\ndemonstrate it outperforms state-of-the-art methods. The results confirm that\nintegrating long-term time and frequency representations with adaptive fusion\nyields a robust and efficient solution for TSAD.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLPCVAE\u7684\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5f15\u5165LSTM\u6355\u83b7\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u4f7f\u7528\u4e13\u5bb6\u4e58\u79ef\u673a\u5236\u8fdb\u884c\u81ea\u9002\u5e94\u6982\u7387\u878d\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709VAE\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5355\u7a97\u53e3\u7279\u5f81\u548c\u957f\u65f6\u9891\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eVAE\u7684\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u5355\u7a97\u53e3\u7279\u5f81\u9650\u5236\u548c\u957f\u65f6\u9891\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u4ee5\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "method": "LPCVAE\u7ed3\u5408LSTM\u6355\u83b7\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u91c7\u7528\u4e13\u5bb6\u4e58\u79ef\u673a\u5236\u8fdb\u884c\u81ea\u9002\u5e94\u5206\u5e03\u7ea7\u6982\u7387\u878d\u5408\uff0c\u6709\u6548\u7f13\u89e3\u65f6\u9891\u4fe1\u606f\u635f\u5931\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u957f\u671f\u65f6\u95f4\u548c\u9891\u7387\u8868\u793a\u4e0e\u81ea\u9002\u5e94\u878d\u5408\u76f8\u7ed3\u5408\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10925", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.10925", "abs": "https://arxiv.org/abs/2510.10925", "authors": ["Hengyuan Zhang", "Shiping Yang", "Xiao Liang", "Chenming Shang", "Yuxuan Jiang", "Chaofan Tao", "Jing Xiong", "Hayden Kwok-Hay So", "Ruobing Xie", "Angel X. Chang", "Ngai Wong"], "title": "Find Your Optimal Teacher: Personalized Data Synthesis via Router-Guided Multi-Teacher Distillation", "comment": "19 pages, 10 figures", "summary": "Training student models on synthetic data generated by strong teacher models\nis a promising way to distilling the capabilities of teachers. However, recent\nstudies show that stronger models are not always optimal teachers, revealing a\nmismatch between teacher outputs and student learnability. To address this\nissue, we propose PerSyn (Personalized data Synthesis), a novel synthesis\nstrategy that operates under a new ``Route then Generate'' paradigm to create\ndata tailored to each student model, enabling it to learn more effectively.\nSpecifically, PerSyn first assigns each prompt to its optimal teacher via a\nquery-level router that jointly considers student learnability and teacher\nresponse quality. Each teacher then synthesizes data only for its assigned\nprompts, making the process more efficient than the conventional ``Generate\nthen Select'' paradigm, where all teachers must generate parallel responses for\nthe entire prompt set before constructing the final dataset. Extensive\nexperiments across different model families and scales demonstrate that PerSyn\nconsistently achieves superior or comparable performance to all baselines in\ninstruct tuning and math reasoning settings. Further analysis verifies the\neffectiveness of PerSyn and offers extra insights to propel future research.", "AI": {"tldr": "PerSyn\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u5408\u6210\u7b56\u7565\uff0c\u91c7\u7528\"\u8def\u7531\u540e\u751f\u6210\"\u8303\u5f0f\uff0c\u4e3a\u6bcf\u4e2a\u5b66\u751f\u6a21\u578b\u5b9a\u5236\u4e2a\u6027\u5316\u6570\u636e\uff0c\u901a\u8fc7\u67e5\u8be2\u7ea7\u8def\u7531\u5668\u5c06\u63d0\u793a\u5206\u914d\u7ed9\u6700\u4f18\u6559\u5e08\u6a21\u578b\uff0c\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\uff0c\u66f4\u5f3a\u7684\u6a21\u578b\u5e76\u4e0d\u603b\u662f\u6700\u4f18\u7684\u6559\u5e08\uff0c\u5b58\u5728\u6559\u5e08\u8f93\u51fa\u4e0e\u5b66\u751f\u53ef\u5b66\u4e60\u6027\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002", "method": "PerSyn\u91c7\u7528\"\u8def\u7531\u540e\u751f\u6210\"\u8303\u5f0f\uff1a\u9996\u5148\u901a\u8fc7\u67e5\u8be2\u7ea7\u8def\u7531\u5668\u8003\u8651\u5b66\u751f\u53ef\u5b66\u4e60\u6027\u548c\u6559\u5e08\u54cd\u5e94\u8d28\u91cf\uff0c\u4e3a\u6bcf\u4e2a\u63d0\u793a\u5206\u914d\u6700\u4f18\u6559\u5e08\uff1b\u7136\u540e\u6bcf\u4e2a\u6559\u5e08\u4ec5\u4e3a\u5176\u5206\u914d\u7684\u63d0\u793a\u751f\u6210\u6570\u636e\uff0c\u6bd4\u4f20\u7edf\u7684\"\u751f\u6210\u540e\u9009\u62e9\"\u8303\u5f0f\u66f4\u9ad8\u6548\u3002", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u7cfb\u5217\u548c\u89c4\u6a21\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPerSyn\u5728\u6307\u4ee4\u8c03\u4f18\u548c\u6570\u5b66\u63a8\u7406\u8bbe\u7f6e\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6216\u4e0e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "PerSyn\u901a\u8fc7\u4e2a\u6027\u5316\u6570\u636e\u5408\u6210\u6709\u6548\u89e3\u51b3\u4e86\u6559\u5e08\u8f93\u51fa\u4e0e\u5b66\u751f\u53ef\u5b66\u4e60\u6027\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u8fdb\u4e00\u6b65\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.10938", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10938", "abs": "https://arxiv.org/abs/2510.10938", "authors": ["Yuda Bi", "Ying Zhu", "Vince D Calhoun"], "title": "Redundancy as a Structural Information Principle for Learning and Generalization", "comment": null, "summary": "We present a theoretical framework that extends classical information theory\nto finite and structured systems by redefining redundancy as a fundamental\nproperty of information organization rather than inefficiency. In this\nframework, redundancy is expressed as a general family of informational\ndivergences that unifies multiple classical measures, such as mutual\ninformation, chi-squared dependence, and spectral redundancy, under a single\ngeometric principle. This reveals that these traditional quantities are not\nisolated heuristics but projections of a shared redundancy geometry. The theory\nfurther predicts that redundancy is bounded both above and below, giving rise\nto an optimal equilibrium that balances over-compression (loss of structure)\nand over-coupling (collapse). While classical communication theory favors\nminimal redundancy for transmission efficiency, finite and structured systems,\nsuch as those underlying real-world learning, achieve maximal stability and\ngeneralization near this equilibrium. Experiments with masked autoencoders are\nused to illustrate and verify this principle: the model exhibits a stable\nredundancy level where generalization peaks. Together, these results establish\nredundancy as a measurable and tunable quantity that bridges the asymptotic\nworld of communication and the finite world of learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u7ecf\u5178\u4fe1\u606f\u8bba\u6269\u5c55\u5230\u6709\u9650\u548c\u7ed3\u6784\u5316\u7cfb\u7edf\uff0c\u5c06\u5197\u4f59\u91cd\u65b0\u5b9a\u4e49\u4e3a\u4fe1\u606f\u7ec4\u7ec7\u7684\u57fa\u672c\u5c5e\u6027\u800c\u975e\u4f4e\u6548\u7387\u3002\u8be5\u6846\u67b6\u5c06\u5197\u4f59\u8868\u8fbe\u4e3a\u4e00\u4e2a\u7edf\u4e00\u591a\u79cd\u7ecf\u5178\u5ea6\u91cf\u7684\u4fe1\u606f\u6563\u5ea6\u65cf\uff0c\u63ed\u793a\u4e86\u5197\u4f59\u5728\u6709\u9650\u7cfb\u7edf\u4e2d\u5b58\u5728\u4e0a\u4e0b\u754c\uff0c\u5f62\u6210\u5e73\u8861\u538b\u7f29\u548c\u8026\u5408\u7684\u6700\u4f18\u5747\u8861\u70b9\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u7406\u8bba\u8ffd\u6c42\u6700\u5c0f\u5197\u4f59\u4ee5\u5b9e\u73b0\u4f20\u8f93\u6548\u7387\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u5b66\u4e60\u7cfb\u7edf\u7b49\u6709\u9650\u7ed3\u6784\u5316\u7cfb\u7edf\u9700\u8981\u5197\u4f59\u6765\u7ef4\u6301\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u4f5c\u8005\u65e8\u5728\u5efa\u7acb\u8fde\u63a5\u901a\u4fe1\u7406\u8bba\u548c\u5b66\u4e60\u4e16\u754c\u7684\u7edf\u4e00\u5197\u4f59\u7406\u8bba\u3002", "method": "\u901a\u8fc7\u91cd\u65b0\u5b9a\u4e49\u5197\u4f59\u4e3a\u4fe1\u606f\u7ec4\u7ec7\u7684\u57fa\u672c\u5c5e\u6027\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u591a\u79cd\u7ecf\u5178\u5ea6\u91cf\uff08\u4e92\u4fe1\u606f\u3001\u5361\u65b9\u4f9d\u8d56\u3001\u8c31\u5197\u4f59\u7b49\uff09\u7684\u4fe1\u606f\u6563\u5ea6\u65cf\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u4f20\u7edf\u91cf\u662f\u5171\u4eab\u5197\u4f59\u51e0\u4f55\u7684\u6295\u5f71\u3002", "result": "\u7406\u8bba\u9884\u6d4b\u5197\u4f59\u5b58\u5728\u4e0a\u4e0b\u754c\uff0c\u5f62\u6210\u6700\u4f18\u5747\u8861\u70b9\u3002\u5728\u63a9\u7801\u81ea\u7f16\u7801\u5668\u7684\u5b9e\u9a8c\u4e2d\uff0c\u6a21\u578b\u5728\u7279\u5b9a\u5197\u4f59\u6c34\u5e73\u4e0b\u8868\u73b0\u51fa\u6700\u4f73\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u8be5\u7406\u8bba\u539f\u7406\u3002", "conclusion": "\u5197\u4f59\u662f\u53ef\u6d4b\u91cf\u548c\u53ef\u8c03\u8282\u7684\u91cf\uff0c\u80fd\u591f\u6865\u63a5\u901a\u4fe1\u7684\u6e10\u8fd1\u4e16\u754c\u548c\u5b66\u4e60\u7684\u6709\u9650\u4e16\u754c\uff0c\u4e3a\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u5b66\u4e60\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2510.10952", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.10952", "abs": "https://arxiv.org/abs/2510.10952", "authors": ["Xi Mao", "Zhendong Wang", "Jingyu Li", "Lingchao Mao", "Utibe Essien", "Hairong Wang", "Xuelei Sherry Ni"], "title": "Interpretable Machine Learning for Cognitive Aging: Handling Missing Data and Uncovering Social Determinant", "comment": null, "summary": "Early detection of Alzheimer's disease (AD) is crucial because its\nneurodegenerative effects are irreversible, and neuropathologic and\nsocial-behavioral risk factors accumulate years before diagnosis. Identifying\nhigher-risk individuals earlier enables prevention, timely care, and equitable\nresource allocation. We predict cognitive performance from social determinants\nof health (SDOH) using the NIH NIA-supported PREPARE Challenge Phase 2 dataset\nderived from the nationally representative Mex-Cog cohort of the 2003 and 2012\nMexican Health and Aging Study (MHAS).\n  Data: The target is a validated composite cognitive score across seven\ndomains-orientation, memory, attention, language, constructional praxis, and\nexecutive function-derived from the 2016 and 2021 MHAS waves. Predictors span\ndemographic, socioeconomic, health, lifestyle, psychosocial, and healthcare\naccess factors.\n  Methodology: Missingness was addressed with a singular value decomposition\n(SVD)-based imputation pipeline treating continuous and categorical variables\nseparately. This approach leverages latent feature correlations to recover\nmissing values while balancing reliability and scalability. After evaluating\nmultiple methods, XGBoost was chosen for its superior predictive performance.\n  Results and Discussion: The framework outperformed existing methods and the\ndata challenge leaderboard, demonstrating high accuracy, robustness, and\ninterpretability. SHAP-based post hoc analysis identified top contributing SDOH\nfactors and age-specific feature patterns. Notably, flooring material emerged\nas a strong predictor, reflecting socioeconomic and environmental disparities.\nOther influential factors, age, SES, lifestyle, social interaction, sleep,\nstress, and BMI, underscore the multifactorial nature of cognitive aging and\nthe value of interpretable, data-driven SDOH modeling.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528\u58a8\u897f\u54e5\u5065\u5eb7\u4e0e\u8001\u9f84\u5316\u7814\u7a76\u6570\u636e\uff0c\u901a\u8fc7\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u9884\u6d4b\u8ba4\u77e5\u8868\u73b0\uff0c\u91c7\u7528SVD\u63d2\u8865\u548cXGBoost\u6a21\u578b\uff0c\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u68c0\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u795e\u7ecf\u9000\u884c\u6027\u6548\u5e94\u4e0d\u53ef\u9006\u8f6c\uff0c\u795e\u7ecf\u75c5\u7406\u5b66\u548c\u793e\u4f1a\u884c\u4e3a\u98ce\u9669\u56e0\u7d20\u5728\u8bca\u65ad\u524d\u591a\u5e74\u79ef\u7d2f\uff0c\u65e9\u671f\u8bc6\u522b\u9ad8\u98ce\u9669\u4e2a\u4f53\u5bf9\u4e8e\u9884\u9632\u3001\u53ca\u65f6\u62a4\u7406\u548c\u516c\u5e73\u8d44\u6e90\u5206\u914d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u5947\u5f02\u503c\u5206\u89e3\u7684\u63d2\u8865\u7ba1\u9053\u5206\u522b\u5904\u7406\u8fde\u7eed\u548c\u5206\u7c7b\u53d8\u91cf\uff0c\u5229\u7528\u6f5c\u5728\u7279\u5f81\u76f8\u5173\u6027\u6062\u590d\u7f3a\u5931\u503c\uff0c\u6700\u7ec8\u9009\u62e9XGBoost\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u8be5\u6846\u67b6\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u548c\u6570\u636e\u6311\u6218\u6392\u884c\u699c\uff0c\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002SHAP\u5206\u6790\u8bc6\u522b\u51fa\u5730\u677f\u6750\u6599\u3001\u5e74\u9f84\u3001\u793e\u4f1a\u7ecf\u6d4e\u5730\u4f4d\u3001\u751f\u6d3b\u65b9\u5f0f\u3001\u793e\u4f1a\u4e92\u52a8\u3001\u7761\u7720\u3001\u538b\u529b\u548cBMI\u7b49\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u8ba4\u77e5\u8001\u5316\u7684\u591a\u56e0\u7d20\u6027\u8d28\uff0c\u4ee5\u53ca\u53ef\u89e3\u91ca\u3001\u6570\u636e\u9a71\u52a8\u7684\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u5efa\u6a21\u7684\u4ef7\u503c\uff0c\u5730\u677f\u6750\u6599\u4f5c\u4e3a\u5f3a\u9884\u6d4b\u56e0\u5b50\u53cd\u6620\u4e86\u793e\u4f1a\u7ecf\u6d4e\u548c\u73af\u5883\u5dee\u5f02\u3002"}}
{"id": "2510.10959", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10959", "abs": "https://arxiv.org/abs/2510.10959", "authors": ["Xiaoyun Zhang", "Xiaojian Yuan", "Di Huang", "Wang You", "Chen Hu", "Jingqing Ruan", "Kejiang Chen", "Xing Hu"], "title": "Rediscovering Entropy Regularization: Adaptive Coefficient Unlocks Its Potential for LLM Reinforcement Learning", "comment": "16 pages, 4 figures", "summary": "Reasoning ability has become a defining capability of Large Language Models\n(LLMs), with Reinforcement Learning with Verifiable Rewards (RLVR) emerging as\na key paradigm to enhance it. However, RLVR training often suffers from policy\nentropy collapse, where the policy becomes overly deterministic, hindering\nexploration and limiting reasoning performance. While entropy regularization is\na common remedy, its effectiveness is highly sensitive to the fixed\ncoefficient, making it unstable across tasks and models. In this work, we\nrevisit entropy regularization in RLVR and argue that its potential has been\nlargely underestimated. Our analysis shows that (i) tasks of varying difficulty\ndemand distinct exploration intensities, and (ii) balanced exploration may\nrequire the policy entropy to be maintained within a moderate range below its\ninitial level. Therefore, we propose Adaptive Entropy Regularization (AER)--a\nframework that dynamically balances exploration and exploitation via three\ncomponents: difficulty-aware coefficient allocation, initial-anchored target\nentropy, and dynamic global coefficient adjustment. Experiments on multiple\nmathematical reasoning benchmarks show that AER consistently outperforms\nbaselines, improving both reasoning accuracy and exploration capability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u9002\u5e94\u71b5\u6b63\u5219\u5316\uff08AER\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u71b5\u6b63\u5219\u5316\u7cfb\u6570\u6765\u89e3\u51b3RLVR\u8bad\u7ec3\u4e2d\u7684\u7b56\u7565\u71b5\u5d29\u6e83\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "RLVR\u8bad\u7ec3\u4e2d\u5e38\u51fa\u73b0\u7b56\u7565\u71b5\u5d29\u6e83\u95ee\u9898\uff0c\u5bfc\u81f4\u7b56\u7565\u8fc7\u4e8e\u786e\u5b9a\u6027\uff0c\u963b\u788d\u63a2\u7d22\u5e76\u9650\u5236\u63a8\u7406\u6027\u80fd\u3002\u4f20\u7edf\u7684\u56fa\u5b9a\u7cfb\u6570\u71b5\u6b63\u5219\u5316\u65b9\u6cd5\u6548\u679c\u4e0d\u7a33\u5b9a\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u8c03\u8282\u673a\u5236\u3002", "method": "\u63d0\u51faAER\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u96be\u5ea6\u611f\u77e5\u7cfb\u6570\u5206\u914d\u3001\u521d\u59cb\u951a\u5b9a\u76ee\u6807\u71b5\u548c\u52a8\u6001\u5168\u5c40\u7cfb\u6570\u8c03\u6574\uff0c\u52a8\u6001\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAER\u65b9\u6cd5\u5728\u63a8\u7406\u51c6\u786e\u6027\u548c\u63a2\u7d22\u80fd\u529b\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u81ea\u9002\u5e94\u71b5\u6b63\u5219\u5316\u80fd\u6709\u6548\u89e3\u51b3RLVR\u8bad\u7ec3\u4e2d\u7684\u7b56\u7565\u71b5\u5d29\u6e83\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2510.10962", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10962", "abs": "https://arxiv.org/abs/2510.10962", "authors": ["Wei Huang", "Yue Liao", "Yukang Chen", "Jianhui Liu", "Haoru Tan", "Si Liu", "Shiming Zhang", "Shuicheng Yan", "Xiaojuan Qi"], "title": "MC#: Mixture Compressor for Mixture-of-Experts Large Models", "comment": "15 pages, 13 figures", "summary": "Mixture-of-Experts (MoE) effectively scales large language models (LLMs) and\nvision-language models (VLMs) by increasing capacity through sparse activation.\nHowever, preloading all experts into memory and activating multiple experts per\ninput introduces significant computational and memory overhead, making the\nexpert module a major contributor to model size and inference cost. To address\nthis, we propose MC# (Mixture-Compressor-sharp), a framework that combines\nstatic quantization and dynamic expert pruning by leveraging the significance\nof experts and tokens for aggressive compression of MoE-LLMs/VLMs. To reduce\nstorage and loading costs, we introduce Pre-Loading Mixed-Precision\nQuantization (PMQ), which optimizes bit allocation via linear programming,\nbalancing expert importance and quantization error for a Pareto-optimal\ntrade-off between size and performance. To reduce runtime computation, Online\nTop-any Pruning (OTP) uses Gumbel-Softmax sampling to dynamically select a\nsubset of experts per token, enabling fine-grained control over activation. By\ncombining PMQ's static bit-width optimization with OTP's dynamic routing, MC#\nachieves extreme compression with minimal accuracy loss. On DeepSeek-VL2, MC#\nachieves a 6.2 times weight reduction at 2.57 average bits with only a 1.7%\naccuracy drop across five multimodal benchmarks. Additionally, OTP reduces\nexpert activation over 20% with less than 1% performance degradation,\ndemonstrating strong potential for efficient MoE-based model deployment.", "AI": {"tldr": "MC#\u662f\u4e00\u4e2a\u7ed3\u5408\u9759\u6001\u91cf\u5316\u548c\u52a8\u6001\u4e13\u5bb6\u526a\u679d\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u538b\u7f29Mixture-of-Experts\u6a21\u578b\uff0c\u901a\u8fc7\u4f18\u5316\u4f4d\u5206\u914d\u548c\u52a8\u6001\u8def\u7531\u5b9e\u73b0\u9ad8\u6548\u538b\u7f29\u3002", "motivation": "\u89e3\u51b3MoE\u6a21\u578b\u4e2d\u4e13\u5bb6\u9884\u52a0\u8f7d\u548c\u6fc0\u6d3b\u5e26\u6765\u7684\u663e\u8457\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u95ee\u9898\uff0c\u4e13\u5bb6\u6a21\u5757\u662f\u6a21\u578b\u5927\u5c0f\u548c\u63a8\u7406\u6210\u672c\u7684\u4e3b\u8981\u8d21\u732e\u8005\u3002", "method": "\u63d0\u51faPre-Loading Mixed-Precision Quantization (PMQ)\u8fdb\u884c\u9759\u6001\u4f4d\u5bbd\u4f18\u5316\uff0c\u4f7f\u7528\u7ebf\u6027\u7f16\u7a0b\u5e73\u8861\u4e13\u5bb6\u91cd\u8981\u6027\u548c\u91cf\u5316\u8bef\u5dee\uff1bOnline Top-any Pruning (OTP)\u4f7f\u7528Gumbel-Softmax\u91c7\u6837\u52a8\u6001\u9009\u62e9\u4e13\u5bb6\u5b50\u96c6\u3002", "result": "\u5728DeepSeek-VL2\u4e0a\u5b9e\u73b06.2\u500d\u6743\u91cd\u538b\u7f29\uff0c\u5e73\u57472.57\u4f4d\uff0c\u4ec5\u635f\u59311.7%\u51c6\u786e\u7387\uff1bOTP\u51cf\u5c1120%\u4ee5\u4e0a\u4e13\u5bb6\u6fc0\u6d3b\uff0c\u6027\u80fd\u4e0b\u964d\u5c0f\u4e8e1%\u3002", "conclusion": "MC#\u901a\u8fc7PMQ\u548cOTP\u7684\u7ec4\u5408\u5b9e\u73b0\u4e86\u6781\u81f4\u7684MoE\u6a21\u578b\u538b\u7f29\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u5c55\u793a\u4e86\u9ad8\u6548\u90e8\u7f72MoE\u6a21\u578b\u7684\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2510.10964", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10964", "abs": "https://arxiv.org/abs/2510.10964", "authors": ["Junhyuck Kim", "Ethan Ewer", "Taehong Moon", "Jongho Park", "Dimitris Papailiopoulos"], "title": "Not All Bits Are Equal: Scale-Dependent Memory Optimization Strategies for Reasoning Models", "comment": "20 pages, 12 figures", "summary": "While 4-bit quantization has emerged as a memory-optimal choice for\nnon-reasoning models and zero-shot tasks across scales, we show that this\nuniversal prescription fails for reasoning models, where the KV cache rather\nthan model size can dominate memory. Through systematic experiments across\n1,700 inference scenarios on AIME25 and GPQA-Diamond, we find a scale-dependent\ntrade-off: models with an effective size below 8-bit 4B parameters achieve\nbetter accuracy by allocating memory to more weights rather than longer\ngeneration, while larger models achieve better accuracy by allocating memory to\nlonger generations. This scale threshold also determines when parallel scaling\nbecomes memory-efficient and whether KV cache eviction outperforms KV\nquantization. Our findings show that memory optimization for LLMs cannot be\nscale-agnostic, while providing principled guidelines: for small reasoning\nmodels, prioritize model capacity over test-time compute, while for larger\nones, maximize test-time compute. Our results suggest that optimizing reasoning\nmodels for deployment requires fundamentally different strategies from those\nestablished for non-reasoning models.", "AI": {"tldr": "4-bit\u91cf\u5316\u5728\u63a8\u7406\u6a21\u578b\u4e2d\u5e76\u975e\u6700\u4f18\u9009\u62e9\uff0cKV\u7f13\u5b58\u800c\u975e\u6a21\u578b\u5927\u5c0f\u4e3b\u5bfc\u5185\u5b58\u4f7f\u7528\u3002\u7814\u7a76\u53d1\u73b0\u5b58\u5728\u89c4\u6a21\u4f9d\u8d56\u7684\u6743\u8861\uff1a8B\u53c2\u6570\u4ee5\u4e0b\u7684\u6a21\u578b\u901a\u8fc7\u5206\u914d\u66f4\u591a\u5185\u5b58\u7ed9\u6743\u91cd\u83b7\u5f97\u66f4\u597d\u7cbe\u5ea6\uff0c\u800c\u66f4\u5927\u6a21\u578b\u901a\u8fc7\u5206\u914d\u5185\u5b58\u7ed9\u66f4\u957f\u751f\u6210\u83b7\u5f97\u66f4\u597d\u7cbe\u5ea6\u3002", "motivation": "\u7814\u7a76\u63a8\u7406\u6a21\u578b\u7684\u5185\u5b58\u4f18\u5316\u7b56\u7565\uff0c\u56e0\u4e3a\u73b0\u6709\u76844-bit\u91cf\u5316\u901a\u7528\u65b9\u6848\u5728\u63a8\u7406\u6a21\u578b\u4e2d\u5931\u6548\uff0cKV\u7f13\u5b58\u6210\u4e3a\u5185\u5b58\u4e3b\u5bfc\u56e0\u7d20\u3002", "method": "\u5728AIME25\u548cGPQA-Diamond\u6570\u636e\u96c6\u4e0a\u8fdb\u884c1,700\u4e2a\u63a8\u7406\u573a\u666f\u7684\u7cfb\u7edf\u5b9e\u9a8c\uff0c\u5206\u6790\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u5728\u5185\u5b58\u5206\u914d\u3001\u5e76\u884c\u6269\u5c55\u548cKV\u7f13\u5b58\u4f18\u5316\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b08B\u53c2\u6570\u662f\u89c4\u6a21\u9608\u503c\uff1a\u5c0f\u6a21\u578b\u5e94\u4f18\u5148\u6a21\u578b\u5bb9\u91cf\uff0c\u5927\u6a21\u578b\u5e94\u6700\u5927\u5316\u63a8\u7406\u65f6\u8ba1\u7b97\u3002\u5e76\u884c\u6269\u5c55\u5728\u9608\u503c\u4ee5\u4e0a\u624d\u5185\u5b58\u9ad8\u6548\uff0cKV\u7f13\u5b58\u9a71\u9010\u5728\u9608\u503c\u4ee5\u4e0a\u4f18\u4e8eKV\u91cf\u5316\u3002", "conclusion": "\u63a8\u7406\u6a21\u578b\u7684\u5185\u5b58\u4f18\u5316\u4e0d\u80fd\u89c4\u6a21\u65e0\u5173\uff0c\u9700\u8981\u4e0e\u65e0\u63a8\u7406\u6a21\u578b\u5b8c\u5168\u4e0d\u540c\u7684\u90e8\u7f72\u7b56\u7565\uff1a\u5c0f\u6a21\u578b\u4f18\u5148\u6a21\u578b\u5bb9\u91cf\uff0c\u5927\u6a21\u578b\u4f18\u5148\u63a8\u7406\u65f6\u8ba1\u7b97\u3002"}}
{"id": "2510.10968", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.10968", "abs": "https://arxiv.org/abs/2510.10968", "authors": ["Hongkai Zheng", "Austin Wang", "Zihui Wu", "Zhengyu Huang", "Ricardo Baptista", "Yisong Yue"], "title": "Blade: A Derivative-free Bayesian Inversion Method using Diffusion Priors", "comment": null, "summary": "Derivative-free Bayesian inversion is an important task in many science and\nengineering applications, particularly when computing the forward model\nderivative is computationally and practically challenging. In this paper, we\nintroduce Blade, which can produce accurate and well-calibrated posteriors for\nBayesian inversion using an ensemble of interacting particles. Blade leverages\npowerful data-driven priors based on diffusion models, and can handle nonlinear\nforward models that permit only black-box access (i.e., derivative-free).\nTheoretically, we establish a non-asymptotic convergence analysis to\ncharacterize the effects of forward model and prior estimation errors.\nEmpirically, Blade achieves superior performance compared to existing\nderivative-free Bayesian inversion methods on various inverse problems,\nincluding challenging highly nonlinear fluid dynamics.", "AI": {"tldr": "Blade\u662f\u4e00\u79cd\u65e0\u5bfc\u6570\u8d1d\u53f6\u65af\u53cd\u6f14\u65b9\u6cd5\uff0c\u4f7f\u7528\u4ea4\u4e92\u7c92\u5b50\u96c6\u5408\u751f\u6210\u51c6\u786e\u4e14\u6821\u51c6\u826f\u597d\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u5229\u7528\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6570\u636e\u9a71\u52a8\u5148\u9a8c\uff0c\u53ef\u5904\u7406\u4ec5\u652f\u6301\u9ed1\u76d2\u8bbf\u95ee\u7684\u975e\u7ebf\u6027\u524d\u5411\u6a21\u578b\u3002", "motivation": "\u5728\u8bb8\u591a\u79d1\u5b66\u548c\u5de5\u7a0b\u5e94\u7528\u4e2d\uff0c\u5f53\u8ba1\u7b97\u524d\u5411\u6a21\u578b\u5bfc\u6570\u5728\u8ba1\u7b97\u548c\u5b9e\u9645\u5e94\u7528\u4e0a\u5177\u6709\u6311\u6218\u6027\u65f6\uff0c\u65e0\u5bfc\u6570\u8d1d\u53f6\u65af\u53cd\u6f14\u662f\u4e00\u4e2a\u91cd\u8981\u4efb\u52a1\u3002", "method": "Blade\u5229\u7528\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6570\u636e\u9a71\u52a8\u5148\u9a8c\uff0c\u901a\u8fc7\u4ea4\u4e92\u7c92\u5b50\u96c6\u5408\u8fdb\u884c\u8d1d\u53f6\u65af\u53cd\u6f14\uff0c\u53ef\u4ee5\u5904\u7406\u4ec5\u652f\u6301\u9ed1\u76d2\u8bbf\u95ee\u7684\u975e\u7ebf\u6027\u524d\u5411\u6a21\u578b\u3002", "result": "\u7406\u8bba\u4e0a\u5efa\u7acb\u4e86\u975e\u6e10\u8fd1\u6536\u655b\u5206\u6790\u6765\u8868\u5f81\u524d\u5411\u6a21\u578b\u548c\u5148\u9a8c\u4f30\u8ba1\u8bef\u5dee\u7684\u5f71\u54cd\u3002\u5b9e\u8bc1\u4e0a\uff0cBlade\u5728\u5404\u79cd\u53cd\u6f14\u95ee\u9898\uff08\u5305\u62ec\u5177\u6709\u6311\u6218\u6027\u7684\u9ad8\u5ea6\u975e\u7ebf\u6027\u6d41\u4f53\u52a8\u529b\u5b66\uff09\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u65e0\u5bfc\u6570\u8d1d\u53f6\u65af\u53cd\u6f14\u65b9\u6cd5\u3002", "conclusion": "Blade\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u5bfc\u6570\u8d1d\u53f6\u65af\u53cd\u6f14\u65b9\u6cd5\uff0c\u80fd\u591f\u4ea7\u751f\u51c6\u786e\u4e14\u6821\u51c6\u826f\u597d\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u7279\u522b\u9002\u7528\u4e8e\u524d\u5411\u6a21\u578b\u5bfc\u6570\u96be\u4ee5\u8ba1\u7b97\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2510.10980", "categories": ["cs.LG", "cs.CV", "cs.IT", "math.IT", "math.ST", "stat.ML", "stat.TH", "68T07, 62B11, 94A17, 53B12", "I.2.6; I.5.1; G.3; H.1.1"], "pdf": "https://arxiv.org/pdf/2510.10980", "abs": "https://arxiv.org/abs/2510.10980", "authors": ["Di Zhang"], "title": "On the Optimal Representation Efficiency of Barlow Twins: An Information-Geometric Interpretation", "comment": "7 pages", "summary": "Self-supervised learning (SSL) has achieved remarkable success by learning\nmeaningful representations without labeled data. However, a unified theoretical\nframework for understanding and comparing the efficiency of different SSL\nparadigms remains elusive. In this paper, we introduce a novel\ninformation-geometric framework to quantify representation efficiency. We\ndefine representation efficiency $\\eta$ as the ratio between the effective\nintrinsic dimension of the learned representation space and its ambient\ndimension, where the effective dimension is derived from the spectral\nproperties of the Fisher Information Matrix (FIM) on the statistical manifold\ninduced by the encoder. Within this framework, we present a theoretical\nanalysis of the Barlow Twins method. Under specific but natural assumptions, we\nprove that Barlow Twins achieves optimal representation efficiency ($\\eta = 1$)\nby driving the cross-correlation matrix of representations towards the identity\nmatrix, which in turn induces an isotropic FIM. This work provides a rigorous\ntheoretical foundation for understanding the effectiveness of Barlow Twins and\noffers a new geometric perspective for analyzing SSL algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4fe1\u606f\u51e0\u4f55\u6846\u67b6\u6765\u91cf\u5316\u8868\u793a\u6548\u7387\uff0c\u5e76\u8bc1\u660eBarlow Twins\u65b9\u6cd5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u80fd\u8fbe\u5230\u6700\u4f18\u8868\u793a\u6548\u7387\u3002", "motivation": "\u81ea\u76d1\u7763\u5b66\u4e60\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u548c\u6bd4\u8f83\u4e0d\u540cSSL\u8303\u5f0f\u7684\u6548\u7387\u3002", "method": "\u5f15\u5165\u4fe1\u606f\u51e0\u4f55\u6846\u67b6\uff0c\u5c06\u8868\u793a\u6548\u7387\u5b9a\u4e49\u4e3a\u5b66\u4e60\u8868\u793a\u7a7a\u95f4\u7684\u6709\u6548\u5185\u5728\u7ef4\u5ea6\u4e0e\u73af\u5883\u7ef4\u5ea6\u7684\u6bd4\u7387\uff0c\u5176\u4e2d\u6709\u6548\u7ef4\u5ea6\u6765\u81ea\u7f16\u7801\u5668\u8bf1\u5bfc\u7684\u7edf\u8ba1\u6d41\u5f62\u4e0aFisher\u4fe1\u606f\u77e9\u9635\u7684\u5149\u8c31\u7279\u6027\u3002", "result": "\u5728\u7279\u5b9a\u81ea\u7136\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660eBarlow Twins\u901a\u8fc7\u5c06\u8868\u793a\u7684\u4e92\u76f8\u5173\u77e9\u9635\u63a8\u5411\u5355\u4f4d\u77e9\u9635\u6765\u5b9e\u73b0\u6700\u4f18\u8868\u793a\u6548\u7387\uff08\u03b7=1\uff09\uff0c\u4ece\u800c\u8bf1\u5bfc\u5404\u5411\u540c\u6027\u7684Fisher\u4fe1\u606f\u77e9\u9635\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u7406\u89e3Barlow Twins\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u5206\u6790SSL\u7b97\u6cd5\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u89c6\u89d2\u3002"}}
{"id": "2510.11016", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11016", "abs": "https://arxiv.org/abs/2510.11016", "authors": ["Ziyi Gao", "Yike Xu", "Jiahao Yuan", "Baokun Wang", "Jinyong Wen", "Xiaotong Lin", "Yun Liu", "Xing Fu", "Yu Cheng", "Yongchao Liu", "Weiqiang Wang", "Zhongle Xie"], "title": "Instruction-aware User Embedding via Synergistic Language and Representation Modeling", "comment": null, "summary": "User representation modeling has become increasingly crucial for personalized\napplications, yet existing approaches struggle with generalizability across\ndomains and sensitivity to noisy behavioral signals. We present InstructUE, an\ninstruction-aware user embedding foundation model that leverages large language\nmodels (LLMs) to generate general and instruction-aware user representations.\nInstructUE introduces a multi-encoder architecture with a lightweight adapter\nthat efficiently processes heterogeneous data from six different sources while\npreserving their structural characteristics. Additionally, it proposes a novel\ncontrastive-autoregressive training framework that bridges language and\nrepresentation spaces through a curated UserQA dataset. The\ncontrastive-autoregressive training framework simultaneously leverages\nautoregressive learning to capture domain knowledge in language space and\ncontrastive learning to align user-text embeddings in representation space,\nthereby enhancing the instruction-awareness and noise-robustness of user\nembeddings. Through extensive experiments on real-world applications, we\ndemonstrate that InstructUE significantly outperforms existing methods across\nmultiple domains including user prediction, marketing, and recommendation\nscenarios. Our results show that instruction-aware user modeling can\neffectively achieve instruction-guided denoising of user information in\nspecific scenarios, paving the way for more generalizable and robust user\nrepresentation learning.", "AI": {"tldr": "InstructUE\u662f\u4e00\u4e2a\u57fa\u4e8e\u6307\u4ee4\u611f\u77e5\u7684\u7528\u6237\u5d4c\u5165\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u7f16\u7801\u5668\u67b6\u6784\u548c\u5bf9\u6bd4-\u81ea\u56de\u5f52\u8bad\u7ec3\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u901a\u7528\u4e14\u6307\u4ee4\u611f\u77e5\u7684\u7528\u6237\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u9886\u57df\u7528\u6237\u5efa\u6a21\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7528\u6237\u8868\u793a\u5efa\u6a21\u65b9\u6cd5\u5728\u8de8\u9886\u57df\u6cdb\u5316\u6027\u548c\u5bf9\u566a\u58f0\u884c\u4e3a\u4fe1\u53f7\u7684\u654f\u611f\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u901a\u7528\u548c\u9c81\u68d2\u7684\u7528\u6237\u8868\u793a\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u591a\u7f16\u7801\u5668\u67b6\u6784\u5904\u7406\u5f02\u6784\u6570\u636e\uff0c\u5f15\u5165\u5bf9\u6bd4-\u81ea\u56de\u5f52\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7UserQA\u6570\u636e\u96c6\u6865\u63a5\u8bed\u8a00\u548c\u8868\u793a\u7a7a\u95f4\uff0c\u540c\u65f6\u5229\u7528\u81ea\u56de\u5f52\u5b66\u4e60\u6355\u83b7\u9886\u57df\u77e5\u8bc6\u548c\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u7528\u6237-\u6587\u672c\u5d4c\u5165\u3002", "result": "\u5728\u7528\u6237\u9884\u6d4b\u3001\u8425\u9500\u548c\u63a8\u8350\u7b49\u591a\u4e2a\u9886\u57df\u7684\u771f\u5b9e\u5e94\u7528\u5b9e\u9a8c\u4e2d\uff0cInstructUE\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u7279\u5b9a\u573a\u666f\u4e0b\u7684\u6307\u4ee4\u5f15\u5bfc\u53bb\u566a\u3002", "conclusion": "\u6307\u4ee4\u611f\u77e5\u7684\u7528\u6237\u5efa\u6a21\u53ef\u4ee5\u6709\u6548\u5b9e\u73b0\u7279\u5b9a\u573a\u666f\u4e0b\u7684\u6307\u4ee4\u5f15\u5bfc\u7528\u6237\u4fe1\u606f\u53bb\u566a\uff0c\u4e3a\u66f4\u901a\u7528\u548c\u9c81\u68d2\u7684\u7528\u6237\u8868\u793a\u5b66\u4e60\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.11018", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.11018", "abs": "https://arxiv.org/abs/2510.11018", "authors": ["Pranav Ramesh", "Arjun Roy", "Deepak Ravikumar", "Kaushik Roy", "Gopalakrishnan Srinivasan"], "title": "The Easy Path to Robustness: Coreset Selection using Sample Hardness", "comment": null, "summary": "Designing adversarially robust models from a data-centric perspective\nrequires understanding which input samples are most crucial for learning\nresilient features. While coreset selection provides a mechanism for efficient\ntraining on data subsets, current algorithms are designed for clean accuracy\nand fall short in preserving robustness. To address this, we propose a\nframework linking a sample's adversarial vulnerability to its\n\\textit{hardness}, which we quantify using the average input gradient norm\n(AIGN) over training. We demonstrate that \\textit{easy} samples (with low AIGN)\nare less vulnerable and occupy regions further from the decision boundary.\nLeveraging this insight, we present EasyCore, a coreset selection algorithm\nthat retains only the samples with low AIGN for training. We empirically show\nthat models trained on EasyCore-selected data achieve significantly higher\nadversarial accuracy than those trained with competing coreset methods under\nboth standard and adversarial training. As AIGN is a model-agnostic dataset\nproperty, EasyCore is an efficient and widely applicable data-centric method\nfor improving adversarial robustness. We show that EasyCore achieves up to 7\\%\nand 5\\% improvement in adversarial accuracy under standard training and TRADES\nadversarial training, respectively, compared to existing coreset methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEasyCore\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u5e73\u5747\u8f93\u5165\u68af\u5ea6\u8303\u6570(AIGN)\u7684\u6837\u672c\u786c\u5ea6\u8bc4\u4f30\u6765\u7b5b\u9009\u6838\u5fc3\u96c6\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u6838\u5fc3\u96c6\u9009\u62e9\u7b97\u6cd5\u4e3b\u8981\u5173\u6ce8\u5e72\u51c0\u7cbe\u5ea6\uff0c\u65e0\u6cd5\u6709\u6548\u4fdd\u6301\u5bf9\u6297\u9c81\u68d2\u6027\u3002\u9700\u8981\u4ece\u6570\u636e\u4e2d\u5fc3\u89c6\u89d2\u7406\u89e3\u54ea\u4e9b\u6837\u672c\u5bf9\u5b66\u4e60\u9c81\u68d2\u7279\u5f81\u6700\u4e3a\u5173\u952e\u3002", "method": "\u63d0\u51fa\u5c06\u6837\u672c\u5bf9\u6297\u8106\u5f31\u6027\u4e0e\u786c\u5ea6\u5173\u8054\uff0c\u4f7f\u7528\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5e73\u5747\u8f93\u5165\u68af\u5ea6\u8303\u6570(AIGN)\u91cf\u5316\u6837\u672c\u786c\u5ea6\u3002EasyCore\u7b97\u6cd5\u4ec5\u4fdd\u7559\u4f4eAIGN\u7684\u7b80\u5355\u6837\u672c\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u4f7f\u7528EasyCore\u9009\u62e9\u7684\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6807\u51c6\u8bad\u7ec3\u548c\u5bf9\u6297\u8bad\u7ec3\u4e0b\uff0c\u5bf9\u6297\u7cbe\u5ea6\u663e\u8457\u9ad8\u4e8e\u5176\u4ed6\u6838\u5fc3\u96c6\u65b9\u6cd5\uff0c\u5206\u522b\u63d0\u53477%\u548c5%\u3002", "conclusion": "AIGN\u662f\u6a21\u578b\u65e0\u5173\u7684\u6570\u636e\u96c6\u5c5e\u6027\uff0cEasyCore\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u6570\u636e\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u53ef\u663e\u8457\u6539\u5584\u5bf9\u6297\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.11049", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.11049", "abs": "https://arxiv.org/abs/2510.11049", "authors": ["Sonakshi Dua", "Gonzalo Mateos", "Sundeep Prabhakar Chepuri"], "title": "Conformal Inference for Time Series over Graphs", "comment": null, "summary": "Trustworthy decision making in networked, dynamic environments calls for\ninnovative uncertainty quantification substrates in predictive models for graph\ntime series. Existing conformal prediction (CP) methods have been applied\nseparately to multivariate time series and static graphs, but they either\nignore the underlying graph topology or neglect temporal dynamics. To bridge\nthis gap, here we develop a CP-based sequential prediction region framework\ntailored for graph time series. A key technical innovation is to leverage the\ngraph structure and thus capture pairwise dependencies across nodes, while\nproviding user-specified coverage guarantees on the predictive outcomes. We\nformally establish that our scheme yields an exponential shrinkage in the\nvolume of the ellipsoidal prediction set relative to its graph-agnostic\ncounterpart. Using real-world datasets, we demonstrate that the novel\nuncertainty quantification framework maintains desired empirical coverage while\nachieving markedly smaller (up to 80% reduction) prediction regions than\nexisting approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u56fe\u65f6\u95f4\u5e8f\u5217\u7684\u4fdd\u5f62\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u56fe\u7ed3\u6784\u6355\u6349\u8282\u70b9\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u4fdd\u8bc1\u8986\u76d6\u6982\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c0f\u9884\u6d4b\u533a\u57df\u4f53\u79ef\u3002", "motivation": "\u73b0\u6709\u4fdd\u5f62\u9884\u6d4b\u65b9\u6cd5\u5206\u522b\u5e94\u7528\u4e8e\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u548c\u9759\u6001\u56fe\uff0c\u4f46\u8981\u4e48\u5ffd\u7565\u4e86\u5e95\u5c42\u56fe\u62d3\u6251\u7ed3\u6784\uff0c\u8981\u4e48\u5ffd\u89c6\u4e86\u65f6\u95f4\u52a8\u6001\u6027\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5904\u7406\u56fe\u7ed3\u6784\u548c\u65f6\u95f4\u52a8\u6001\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u7684\u987a\u5e8f\u9884\u6d4b\u533a\u57df\u6846\u67b6\uff0c\u5229\u7528\u56fe\u7ed3\u6784\u6355\u6349\u8282\u70b9\u95f4\u6210\u5bf9\u4f9d\u8d56\u5173\u7cfb\uff0c\u540c\u65f6\u63d0\u4f9b\u7528\u6237\u6307\u5b9a\u7684\u8986\u76d6\u4fdd\u8bc1\u3002", "result": "\u8be5\u65b9\u6848\u4f7f\u692d\u7403\u9884\u6d4b\u96c6\u7684\u4f53\u79ef\u76f8\u5bf9\u4e8e\u56fe\u65e0\u5173\u5bf9\u5e94\u7269\u5448\u6307\u6570\u7ea7\u6536\u7f29\u3002\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u65b0\u6846\u67b6\u4fdd\u6301\u671f\u671b\u7684\u7ecf\u9a8c\u8986\u76d6\u6982\u7387\uff0c\u540c\u65f6\u5b9e\u73b0\u660e\u663e\u66f4\u5c0f\uff08\u51cf\u5c11\u9ad8\u8fbe80%\uff09\u7684\u9884\u6d4b\u533a\u57df\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\u6210\u529f\u7ed3\u5408\u4e86\u56fe\u7ed3\u6784\u548c\u65f6\u95f4\u52a8\u6001\uff0c\u5728\u4fdd\u8bc1\u8986\u76d6\u6982\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2510.11057", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11057", "abs": "https://arxiv.org/abs/2510.11057", "authors": ["Youngrok Park", "Hojung Jung", "Sangmin Bae", "Se-Young Yun"], "title": "Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models", "comment": "54 pages, 17 figures, 18 tables", "summary": "Diffusion models have achieved remarkable success as generative models.\nHowever, even a well-trained model can accumulate errors throughout the\ngeneration process. These errors become particularly problematic when arbitrary\nguidance is applied to steer samples toward desired properties, which often\nbreaks sample fidelity. In this paper, we propose a general solution to address\nthe off-manifold phenomenon observed in diffusion models. Our approach\nleverages a time predictor to estimate deviations from the desired data\nmanifold at each timestep, identifying that a larger time gap is associated\nwith reduced generation quality. We then design a novel guidance mechanism,\n`Temporal Alignment Guidance' (TAG), attracting the samples back to the desired\nmanifold at every timestep during generation. Through extensive experiments, we\ndemonstrate that TAG consistently produces samples closely aligned with the\ndesired manifold at each timestep, leading to significant improvements in\ngeneration quality across various downstream tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u6269\u6563\u6a21\u578b\u4e2d\u79bb\u6d41\u5f62\u73b0\u8c61\u7684\u65b0\u65b9\u6cd5TAG\uff0c\u901a\u8fc7\u65f6\u95f4\u9884\u6d4b\u5668\u4f30\u8ba1\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u504f\u79bb\u7a0b\u5ea6\uff0c\u5e76\u4f7f\u7528\u65f6\u95f4\u5bf9\u9f50\u6307\u5bfc\u5c06\u6837\u672c\u62c9\u56de\u671f\u671b\u6d41\u5f62\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4f1a\u7d2f\u79ef\u8bef\u5dee\uff0c\u7279\u522b\u662f\u5728\u5e94\u7528\u4efb\u610f\u6307\u5bfc\u65f6\uff0c\u8fd9\u4f1a\u7834\u574f\u6837\u672c\u4fdd\u771f\u5ea6\uff0c\u5bfc\u81f4\u79bb\u6d41\u5f62\u73b0\u8c61\u3002", "method": "\u4f7f\u7528\u65f6\u95f4\u9884\u6d4b\u5668\u4f30\u8ba1\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u504f\u79bb\u7a0b\u5ea6\uff0c\u8bbe\u8ba1\u65f6\u95f4\u5bf9\u9f50\u6307\u5bfc\u673a\u5236\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5c06\u6837\u672c\u62c9\u56de\u671f\u671b\u6d41\u5f62\u3002", "result": "TAG\u65b9\u6cd5\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u90fd\u80fd\u4ea7\u751f\u4e0e\u671f\u671b\u6d41\u5f62\u7d27\u5bc6\u5bf9\u9f50\u7684\u6837\u672c\uff0c\u663e\u8457\u6539\u5584\u4e86\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "TAG\u662f\u4e00\u79cd\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6269\u6563\u6a21\u578b\u4e2d\u7684\u79bb\u6d41\u5f62\u95ee\u9898\uff0c\u63d0\u5347\u751f\u6210\u6837\u672c\u7684\u4fdd\u771f\u5ea6\u548c\u8d28\u91cf\u3002"}}
{"id": "2510.11068", "categories": ["cs.LG", "eess.AS", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.11068", "abs": "https://arxiv.org/abs/2510.11068", "authors": ["Xinyu Luo", "Jie Liu", "Kecheng Chen", "Junyi Yang", "Bo Ding", "Arindam Basu", "Haoliang Li"], "title": "Efficient Edge Test-Time Adaptation via Latent Feature Coordinate Correction", "comment": "Under review", "summary": "Edge devices face significant challenges due to limited computational\nresources and distribution shifts, making efficient and adaptable machine\nlearning essential. Existing test-time adaptation (TTA) methods often rely on\ngradient-based optimization or batch processing, which are inherently\nunsuitable for resource-constrained edge scenarios due to their reliance on\nbackpropagation and high computational demands. Gradient-free alternatives\naddress these issues but often suffer from limited learning capacity, lack\nflexibility, or impose architectural constraints. To overcome these\nlimitations, we propose a novel single-instance TTA method tailored for edge\ndevices (TED), which employs forward-only coordinate optimization in the\nprincipal subspace of latent using the covariance matrix adaptation evolution\nstrategy (CMA-ES). By updating a compact low-dimensional vector, TED not only\nenhances output confidence but also aligns the latent representation closer to\nthe source latent distribution within the latent principal subspace. This is\nachieved without backpropagation, keeping the model parameters frozen, and\nenabling efficient, forgetting-free adaptation with minimal memory and\ncomputational overhead. Experiments on image classification and keyword\nspotting tasks across the ImageNet and Google Speech Commands series datasets\ndemonstrate that TED achieves state-of-the-art performance while\n$\\textit{reducing computational complexity by up to 63 times}$, offering a\npractical and scalable solution for real-world edge applications. Furthermore,\nwe successfully $\\textit{deployed TED on the ZYNQ-7020 platform}$,\ndemonstrating its feasibility and effectiveness for resource-constrained edge\ndevices in real-world deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u8fb9\u7f18\u8bbe\u5907\u8bbe\u8ba1\u7684\u5355\u5b9e\u4f8b\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5TED\uff0c\u4f7f\u7528CMA-ES\u5728\u6f5c\u5728\u4e3b\u5b50\u7a7a\u95f4\u8fdb\u884c\u524d\u5411\u5750\u6807\u4f18\u5316\uff0c\u65e0\u9700\u53cd\u5411\u4f20\u64ad\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea663\u500d\uff0c\u5e76\u5728ZYNQ-7020\u5e73\u53f0\u4e0a\u6210\u529f\u90e8\u7f72\u3002", "motivation": "\u8fb9\u7f18\u8bbe\u5907\u9762\u4e34\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u548c\u5206\u5e03\u504f\u79fb\u7684\u6311\u6218\uff0c\u73b0\u6709\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\u4f9d\u8d56\u68af\u5ea6\u4f18\u5316\u6216\u6279\u5904\u7406\uff0c\u4e0d\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u573a\u666f\u3002\u68af\u5ea6\u81ea\u7531\u66ff\u4ee3\u65b9\u6848\u5b58\u5728\u5b66\u4e60\u80fd\u529b\u6709\u9650\u3001\u7f3a\u4e4f\u7075\u6d3b\u6027\u6216\u67b6\u6784\u7ea6\u675f\u7b49\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u534f\u65b9\u5dee\u77e9\u9635\u81ea\u9002\u5e94\u8fdb\u5316\u7b56\u7565\uff08CMA-ES\uff09\u5728\u6f5c\u5728\u4e3b\u5b50\u7a7a\u95f4\u8fdb\u884c\u524d\u5411\u5750\u6807\u4f18\u5316\uff0c\u901a\u8fc7\u66f4\u65b0\u7d27\u51d1\u7684\u4f4e\u7ef4\u5411\u91cf\u6765\u589e\u5f3a\u8f93\u51fa\u7f6e\u4fe1\u5ea6\u5e76\u4f7f\u6f5c\u5728\u8868\u793a\u66f4\u63a5\u8fd1\u6e90\u6f5c\u5728\u5206\u5e03\uff0c\u4fdd\u6301\u6a21\u578b\u53c2\u6570\u51bb\u7ed3\u3002", "result": "\u5728ImageNet\u548cGoogle Speech Commands\u6570\u636e\u96c6\u4e0a\u7684\u56fe\u50cf\u5206\u7c7b\u548c\u5173\u952e\u8bcd\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0cTED\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\u4e8663\u500d\uff0c\u5e76\u5728ZYNQ-7020\u5e73\u53f0\u4e0a\u6210\u529f\u90e8\u7f72\u3002", "conclusion": "TED\u4e3a\u8fb9\u7f18\u8bbe\u5907\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u73b0\u5b9e\u4e16\u754c\u8fb9\u7f18\u5e94\u7528\u4e2d\u5b9e\u73b0\u9ad8\u6548\u3001\u65e0\u9057\u5fd8\u7684\u81ea\u9002\u5e94\uff0c\u5177\u6709\u6700\u5c0f\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2510.11084", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11084", "abs": "https://arxiv.org/abs/2510.11084", "authors": ["Wonah Kim", "Jeonghyeon Park", "Dongsan Jun", "Jungkyu Han", "Sejin Chun"], "title": "Causal Disentanglement Learning for Accurate Anomaly Detection in Multivariate Time Series", "comment": "20 pages, 4 Figures,", "summary": "Disentangling complex causal relationships is important for accurate\ndetection of anomalies. In multivariate time series analysis, dynamic\ninteractions among data variables over time complicate the interpretation of\ncausal relationships. Traditional approaches assume statistical independence\nbetween variables in unsupervised settings, whereas recent methods capture\nfeature correlations through graph representation learning. However, their\nrepresentations fail to explicitly infer the causal relationships over\ndifferent time periods. To solve the problem, we propose Causally Disentangled\nRepresentation Learning for Anomaly Detection (CDRL4AD) to detect anomalies and\nidentify their causal relationships in multivariate time series. First, we\ndesign the causal process as model input, the temporal heterogeneous graph, and\ncausal relationships. Second, our representation identifies causal\nrelationships over different time periods and disentangles latent variables to\ninfer the corresponding causal factors. Third, our experiments on real-world\ndatasets demonstrate that CDRL4AD outperforms state-of-the-art methods in terms\nof accuracy and root cause analysis. Fourth, our model analysis validates\nhyperparameter sensitivity and the time complexity of CDRL4AD. Last, we conduct\na case study to show how our approach assists human experts in diagnosing the\nroot causes of anomalies.", "AI": {"tldr": "\u63d0\u51faCDRL4AD\u65b9\u6cd5\uff0c\u901a\u8fc7\u56e0\u679c\u89e3\u8026\u8868\u793a\u5b66\u4e60\u6765\u68c0\u6d4b\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u5f02\u5e38\u5e76\u8bc6\u522b\u5176\u56e0\u679c\u5173\u7cfb\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u6839\u56e0\u5206\u6790\u80fd\u529b\u3002", "motivation": "\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u4e2d\u6570\u636e\u53d8\u91cf\u95f4\u7684\u52a8\u6001\u4ea4\u4e92\u4f7f\u5f97\u56e0\u679c\u5173\u7cfb\u89e3\u91ca\u590d\u6742\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u660e\u786e\u63a8\u65ad\u4e0d\u540c\u65f6\u95f4\u6bb5\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u663e\u5f0f\u5efa\u6a21\u56e0\u679c\u5173\u7cfb\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u65f6\u95f4\u5f02\u6784\u56fe\u4f5c\u4e3a\u6a21\u578b\u8f93\u5165\uff0c\u901a\u8fc7\u8868\u793a\u5b66\u4e60\u8bc6\u522b\u4e0d\u540c\u65f6\u95f4\u6bb5\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u89e3\u8026\u6f5c\u5728\u53d8\u91cf\u4ee5\u63a8\u65ad\u76f8\u5e94\u7684\u56e0\u679c\u56e0\u7d20\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCDRL4AD\u5728\u51c6\u786e\u6027\u548c\u6839\u56e0\u5206\u6790\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u6a21\u578b\u5206\u6790\u9a8c\u8bc1\u4e86\u8d85\u53c2\u6570\u654f\u611f\u6027\u548c\u65f6\u95f4\u590d\u6742\u6027\u3002", "conclusion": "CDRL4AD\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5f02\u5e38\u5e76\u8bc6\u522b\u56e0\u679c\u5173\u7cfb\uff0c\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u8bca\u65ad\u5f02\u5e38\u7684\u6839\u672c\u539f\u56e0\u3002"}}
{"id": "2510.11121", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11121", "abs": "https://arxiv.org/abs/2510.11121", "authors": ["Rongjie Zhu", "Cong Zhang", "Zhiguang Cao"], "title": "Refining Hybrid Genetic Search for CVRP via Reinforcement Learning-Finetuned LLM", "comment": null, "summary": "While large language models (LLMs) are increasingly used as automated\nheuristic designers for vehicle routing problems (VRPs), current\nstate-of-the-art methods predominantly rely on prompting massive,\ngeneral-purpose models like GPT-4. This work challenges that paradigm by\ndemonstrating that a smaller, specialized LLM, when meticulously fine-tuned,\ncan generate components that surpass expert-crafted heuristics within advanced\nsolvers. We propose RFTHGS, a novel Reinforcement learning (RL) framework for\nFine-Tuning a small LLM to generate high-performance crossover operators for\nthe Hybrid Genetic Search (HGS) solver, applied to the Capacitated VRP (CVRP).\nOur method employs a multi-tiered, curriculum-based reward function that\nprogressively guides the LLM to master generating first compilable, then\nexecutable, and finally, superior-performing operators that exceed human expert\ndesigns. This is coupled with an operator caching mechanism that discourages\nplagiarism and promotes diversity during training. Comprehensive experiments\nshow that our fine-tuned LLM produces crossover operators which significantly\noutperform the expert-designed ones in HGS. The performance advantage remains\nconsistent, generalizing from small-scale instances to large-scale problems\nwith up to 1000 nodes. Furthermore, RFTHGS exceeds the performance of leading\nneuro-combinatorial baselines, prompt-based methods, and commercial LLMs such\nas GPT-4o and GPT-4o-mini.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRFTHGS\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5c0f\u578b\u4e13\u7528LLM\u6765\u4e3a\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u751f\u6210\u9ad8\u6027\u80fd\u4ea4\u53c9\u7b97\u5b50\uff0c\u8d85\u8d8a\u4e86\u4e13\u5bb6\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u548cGPT-4\u7b49\u5927\u578b\u901a\u7528\u6a21\u578b\u3002", "motivation": "\u6311\u6218\u5f53\u524d\u4f9d\u8d56\u5927\u578b\u901a\u7528LLM\uff08\u5982GPT-4\uff09\u4f5c\u4e3aVRP\u542f\u53d1\u5f0f\u8bbe\u8ba1\u5668\u7684\u8303\u5f0f\uff0c\u8bc1\u660e\u7ecf\u8fc7\u7cbe\u5fc3\u5fae\u8c03\u7684\u5c0f\u578b\u4e13\u7528LLM\u53ef\u4ee5\u751f\u6210\u8d85\u8d8a\u4e13\u5bb6\u8bbe\u8ba1\u7684\u7ec4\u4ef6\u3002", "method": "\u63d0\u51faRFTHGS\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528\u591a\u5c42\u7ea7\u8bfe\u7a0b\u5956\u52b1\u51fd\u6570\u9010\u6b65\u5f15\u5bfcLLM\u751f\u6210\u53ef\u7f16\u8bd1\u3001\u53ef\u6267\u884c\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u4ea4\u53c9\u7b97\u5b50\uff0c\u7ed3\u5408\u7b97\u5b50\u7f13\u5b58\u673a\u5236\u9632\u6b62\u6284\u88ad\u5e76\u4fc3\u8fdb\u591a\u6837\u6027\u3002", "result": "\u5fae\u8c03\u540e\u7684LLM\u751f\u6210\u7684\u4ea4\u53c9\u7b97\u5b50\u663e\u8457\u4f18\u4e8eHGS\u4e2d\u7684\u4e13\u5bb6\u8bbe\u8ba1\u7b97\u5b50\uff0c\u6027\u80fd\u4f18\u52bf\u4ece\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u6269\u5c55\u52301000\u8282\u70b9\u7684\u5927\u89c4\u6a21\u95ee\u9898\uff0c\u8d85\u8d8a\u4e86\u9886\u5148\u7684\u795e\u7ecf\u7ec4\u5408\u57fa\u7ebf\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u548cGPT-4o\u7b49\u5546\u4e1aLLM\u3002", "conclusion": "\u5c0f\u578b\u4e13\u7528LLM\u7ecf\u8fc7\u9002\u5f53\u5fae\u8c03\u53ef\u4ee5\u8d85\u8d8a\u5927\u578b\u901a\u7528\u6a21\u578b\u548c\u4e13\u5bb6\u8bbe\u8ba1\uff0c\u4e3a\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11128", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.11128", "abs": "https://arxiv.org/abs/2510.11128", "authors": ["Qiyi Tong", "Olivia Nocentini", "Marta Lagomarsino", "Kuanqi Cai", "Marta Lorenzini", "Arash Ajoudani"], "title": "Lightweight Facial Landmark Detection in Thermal Images via Multi-Level Cross-Modal Knowledge Transfer", "comment": null, "summary": "Facial Landmark Detection (FLD) in thermal imagery is critical for\napplications in challenging lighting conditions, but it is hampered by the lack\nof rich visual cues. Conventional cross-modal solutions, like feature fusion or\nimage translation from RGB data, are often computationally expensive or\nintroduce structural artifacts, limiting their practical deployment. To address\nthis, we propose Multi-Level Cross-Modal Knowledge Distillation (MLCM-KD), a\nnovel framework that decouples high-fidelity RGB-to-thermal knowledge transfer\nfrom model compression to create both accurate and efficient thermal FLD\nmodels. A central challenge during knowledge transfer is the profound modality\ngap between RGB and thermal data, where traditional unidirectional distillation\nfails to enforce semantic consistency across disparate feature spaces. To\novercome this, we introduce Dual-Injected Knowledge Distillation (DIKD), a\nbidirectional mechanism designed specifically for this task. DIKD establishes a\nconnection between modalities: it not only guides the thermal student with rich\nRGB features but also validates the student's learned representations by\nfeeding them back into the frozen teacher's prediction head. This closed-loop\nsupervision forces the student to learn modality-invariant features that are\nsemantically aligned with the teacher, ensuring a robust and profound knowledge\ntransfer. Experiments show that our approach sets a new state-of-the-art on\npublic thermal FLD benchmarks, notably outperforming previous methods while\ndrastically reducing computational overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMLCM-KD\u7684\u591a\u5c42\u6b21\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u70ed\u6210\u50cf\u4e2d\u9762\u90e8\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u53cc\u5411\u77e5\u8bc6\u84b8\u998f\u673a\u5236\u6709\u6548\u7f29\u5c0fRGB\u548c\u70ed\u6210\u50cf\u4e4b\u95f4\u7684\u6a21\u6001\u5dee\u8ddd\u3002", "motivation": "\u70ed\u6210\u50cf\u9762\u90e8\u5173\u952e\u70b9\u68c0\u6d4b\u5728\u6076\u52a3\u5149\u7167\u6761\u4ef6\u4e0b\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u4f46\u7f3a\u4e4f\u4e30\u5bcc\u7684\u89c6\u89c9\u7ebf\u7d22\u3002\u4f20\u7edf\u7684\u8de8\u6a21\u6001\u89e3\u51b3\u65b9\u6848\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u5f15\u5165\u7ed3\u6784\u4f2a\u5f71\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51faMLCM-KD\u6846\u67b6\uff0c\u5c06\u9ad8\u4fdd\u771fRGB\u5230\u70ed\u6210\u50cf\u77e5\u8bc6\u8f6c\u79fb\u4e0e\u6a21\u578b\u538b\u7f29\u89e3\u8026\u3002\u5f15\u5165DIKD\u53cc\u5411\u673a\u5236\uff1a\u4e0d\u4ec5\u7528RGB\u7279\u5f81\u6307\u5bfc\u5b66\u751f\uff0c\u8fd8\u5c06\u5b66\u751f\u5b66\u5230\u7684\u8868\u5f81\u53cd\u9988\u5230\u51bb\u7ed3\u6559\u5e08\u7684\u9884\u6d4b\u5934\u4e2d\uff0c\u5f62\u6210\u95ed\u73af\u76d1\u7763\u3002", "result": "\u5728\u516c\u5f00\u7684\u70ed\u6210\u50cf\u9762\u90e8\u5173\u952e\u70b9\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u663e\u8457\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u53cc\u5411\u77e5\u8bc6\u84b8\u998f\u6709\u6548\u89e3\u51b3\u4e86RGB\u548c\u70ed\u6210\u50cf\u4e4b\u95f4\u7684\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u4e14\u6df1\u5165\u7684\u77e5\u8bc6\u8f6c\u79fb\uff0c\u4e3a\u70ed\u6210\u50cf\u9762\u90e8\u5173\u952e\u70b9\u68c0\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11133", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11133", "abs": "https://arxiv.org/abs/2510.11133", "authors": ["Yingnan Liu", "Rui Qiao", "Mong Li Lee", "Wynne Hsu"], "title": "Test-Time Adaptation by Causal Trimming", "comment": "Accepted to the Thirty-Ninth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2025); Code is available at\n  https://github.com/NancyQuris/TACT", "summary": "Test-time adaptation aims to improve model robustness under distribution\nshifts by adapting models with access to unlabeled target samples. A primary\ncause of performance degradation under such shifts is the model's reliance on\nfeatures that lack a direct causal relationship with the prediction target. We\nintroduce Test-time Adaptation by Causal Trimming (TACT), a method that\nidentifies and removes non-causal components from representations for test\ndistributions. TACT applies data augmentations that preserve causal features\nwhile varying non-causal ones. By analyzing the changes in the representations\nusing Principal Component Analysis, TACT identifies the highest variance\ndirections associated with non-causal features. It trims the representations by\nremoving their projections on the identified directions, and uses the trimmed\nrepresentations for the predictions. During adaptation, TACT continuously\ntracks and refines these directions to get a better estimate of non-causal\nfeatures. We theoretically analyze the effectiveness of this approach and\nempirically validate TACT on real-world out-of-distribution benchmarks. TACT\nconsistently outperforms state-of-the-art methods by a significant margin.", "AI": {"tldr": "TACT\u662f\u4e00\u79cd\u6d4b\u8bd5\u65f6\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u56e0\u679c\u4fee\u526a\u53bb\u9664\u8868\u793a\u4e2d\u7684\u975e\u56e0\u679c\u6210\u5206\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u6a21\u578b\u6027\u80fd\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u4e0b\u964d\u7684\u4e3b\u8981\u539f\u56e0\u662f\u6a21\u578b\u4f9d\u8d56\u4e0e\u9884\u6d4b\u76ee\u6807\u7f3a\u4e4f\u76f4\u63a5\u56e0\u679c\u5173\u7cfb\u7684\u7279\u5f81\u3002", "method": "TACT\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u4fdd\u7559\u56e0\u679c\u7279\u5f81\u540c\u65f6\u53d8\u5316\u975e\u56e0\u679c\u7279\u5f81\uff0c\u4f7f\u7528\u4e3b\u6210\u5206\u5206\u6790\u8bc6\u522b\u975e\u56e0\u679c\u7279\u5f81\u7684\u9ad8\u65b9\u5dee\u65b9\u5411\uff0c\u4fee\u526a\u8868\u793a\u4e2d\u8fd9\u4e9b\u65b9\u5411\u7684\u6295\u5f71\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u5206\u5e03\u5916\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTACT\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u8bc6\u522b\u548c\u53bb\u9664\u8868\u793a\u4e2d\u7684\u975e\u56e0\u679c\u6210\u5206\uff0cTACT\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.11140", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11140", "abs": "https://arxiv.org/abs/2510.11140", "authors": ["Zhijian Zhou", "Xunye Tian", "Liuhua Peng", "Chao Lei", "Antonin Schrab", "Danica J. Sutherland", "Feng Liu"], "title": "DUAL: Learning Diverse Kernels for Aggregated Two-sample and Independence Testing", "comment": null, "summary": "To adapt kernel two-sample and independence testing to complex structured\ndata, aggregation of multiple kernels is frequently employed to boost testing\npower compared to single-kernel tests. However, we observe a phenomenon that\ndirectly maximizing multiple kernel-based statistics may result in highly\nsimilar kernels that capture highly overlapping information, limiting the\neffectiveness of aggregation. To address this, we propose an aggregated\nstatistic that explicitly incorporates kernel diversity based on the covariance\nbetween different kernels. Moreover, we identify a fundamental challenge: a\ntrade-off between the diversity among kernels and the test power of individual\nkernels, i.e., the selected kernels should be both effective and diverse. This\nmotivates a testing framework with selection inference, which leverages\ninformation from the training phase to select kernels with strong individual\nperformance from the learned diverse kernel pool. We provide rigorous\ntheoretical statements and proofs to show the consistency on the test power and\ncontrol of Type-I error, along with asymptotic analysis of the proposed\nstatistics. Lastly, we conducted extensive empirical experiments demonstrating\nthe superior performance of our proposed approach across various benchmarks for\nboth two-sample and independence testing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u6838\u591a\u6837\u6027\u7684\u805a\u5408\u7edf\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5f15\u5165\u6838\u95f4\u534f\u65b9\u5dee\u6765\u63d0\u5347\u591a\u6838\u4e24\u6837\u672c\u548c\u72ec\u7acb\u6027\u68c0\u9a8c\u7684\u6548\u679c\uff0c\u89e3\u51b3\u4e86\u76f4\u63a5\u6700\u5927\u5316\u591a\u6838\u7edf\u8ba1\u91cf\u53ef\u80fd\u5bfc\u81f4\u6838\u76f8\u4f3c\u5ea6\u9ad8\u3001\u4fe1\u606f\u91cd\u53e0\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u805a\u5408\u591a\u4e2a\u6838\u65f6\u53ef\u80fd\u9009\u62e9\u9ad8\u5ea6\u76f8\u4f3c\u7684\u6838\uff0c\u5bfc\u81f4\u4fe1\u606f\u91cd\u53e0\uff0c\u9650\u5236\u4e86\u805a\u5408\u6548\u679c\u3002\u9700\u8981\u5e73\u8861\u6838\u7684\u591a\u6837\u6027\u548c\u5355\u4e2a\u6838\u7684\u68c0\u9a8c\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u663e\u5f0f\u5305\u542b\u6838\u591a\u6837\u6027\u7684\u805a\u5408\u7edf\u8ba1\u91cf\uff0c\u57fa\u4e8e\u6838\u95f4\u534f\u65b9\u5dee\uff1b\u5efa\u7acb\u9009\u62e9\u63a8\u65ad\u6846\u67b6\uff0c\u4ece\u5b66\u4e60\u7684\u591a\u6837\u5316\u6838\u6c60\u4e2d\u9009\u62e9\u5177\u6709\u5f3a\u4e2a\u4f53\u6027\u80fd\u7684\u6838\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u68c0\u9a8c\u529f\u6548\u4e0a\u5177\u6709\u4e00\u81f4\u6027\u5e76\u80fd\u63a7\u5236I\u7c7b\u9519\u8bef\uff1b\u5927\u91cf\u5b9e\u8bc1\u5b9e\u9a8c\u8868\u660e\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e24\u6837\u672c\u548c\u72ec\u7acb\u6027\u68c0\u9a8c\u6027\u80fd\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5e73\u8861\u6838\u591a\u6837\u6027\u548c\u4e2a\u4f53\u68c0\u9a8c\u80fd\u529b\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u591a\u6838\u4e24\u6837\u672c\u548c\u72ec\u7acb\u6027\u68c0\u9a8c\u7684\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u7ed3\u6784\u5316\u6570\u636e\u7684\u6838\u68c0\u9a8c\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11141", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11141", "abs": "https://arxiv.org/abs/2510.11141", "authors": ["Mohammad Karami", "Mostafa Jalali", "Fatemeh Ghassemi"], "title": "A Comprehensive Forecasting-Based Framework for Time Series Anomaly Detection: Benchmarking on the Numenta Anomaly Benchmark (NAB)", "comment": null, "summary": "Time series anomaly detection is critical for modern digital infrastructures,\nyet existing methods lack systematic cross-domain evaluation. We present a\ncomprehensive forecasting-based framework unifying classical methods\n(Holt-Winters, SARIMA) with deep learning architectures (LSTM, Informer) under\na common residual-based detection interface. Our modular pipeline integrates\npreprocessing (normalization, STL decomposition), four forecasting models, four\ndetection methods, and dual evaluation through forecasting metrics (MAE, RMSE,\nPCC) and detection metrics (Precision, Recall, F1, AUC). We conduct the first\ncomplete evaluation on the Numenta Anomaly Benchmark (58 datasets, 7\ncategories) with 232 model training runs and 464 detection evaluations\nachieving 100\\% success rate. LSTM achieves best performance (F1: 0.688,\nranking first or second on 81\\% of datasets) with exceptional correlation on\ncomplex patterns (PCC: 0.999). Informer provides competitive accuracy (F1:\n0.683) with 30\\% faster training. Classical methods achieve perfect predictions\non simple synthetic data with 60 lower cost but show 2-3 worse F1-scores on\nreal-world datasets. Forecasting quality dominates detection performance:\ndifferences between detection methods (F1: 0.621-0.688) are smaller than\nbetween forecasting models (F1: 0.344-0.688). Our findings provide\nevidence-based guidance: use LSTM for complex patterns, Informer for\nefficiency-critical deployments, and classical methods for simple periodic data\nwith resource constraints. The complete implementation and results establish\nbaselines for future forecasting-based anomaly detection research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u9884\u6d4b\u5f0f\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u7ecf\u5178\u65b9\u6cd5\uff08Holt-Winters\u3001SARIMA\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08LSTM\u3001Informer\uff09\u572858\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002LSTM\u5728\u590d\u6742\u6a21\u5f0f\u4e0a\u8868\u73b0\u6700\u4f73\uff0cInformer\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\uff0c\u7ecf\u5178\u65b9\u6cd5\u5728\u7b80\u5355\u5468\u671f\u6027\u6570\u636e\u4e0a\u6210\u672c\u6548\u76ca\u9ad8\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u8de8\u9886\u57df\u8bc4\u4f30\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u9884\u6d4b\u5f0f\u6846\u67b6\u6765\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u6784\u5efa\u6a21\u5757\u5316\u6d41\u6c34\u7ebf\uff0c\u96c6\u6210\u9884\u5904\u7406\uff08\u5f52\u4e00\u5316\u3001STL\u5206\u89e3\uff09\u3001\u56db\u79cd\u9884\u6d4b\u6a21\u578b\u3001\u56db\u79cd\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u6b8b\u5dee\u68c0\u6d4b\u63a5\u53e3\uff0c\u901a\u8fc7\u9884\u6d4b\u6307\u6807\uff08MAE\u3001RMSE\u3001PCC\uff09\u548c\u68c0\u6d4b\u6307\u6807\uff08\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u3001AUC\uff09\u8fdb\u884c\u53cc\u91cd\u8bc4\u4f30\u3002", "result": "\u5728Numenta\u5f02\u5e38\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b8c\u6210232\u6b21\u6a21\u578b\u8bad\u7ec3\u548c464\u6b21\u68c0\u6d4b\u8bc4\u4f30\uff0c\u6210\u529f\u7387100%\u3002LSTM\u8868\u73b0\u6700\u4f73\uff08F1\uff1a0.688\uff0c\u572881%\u6570\u636e\u96c6\u4e0a\u6392\u540d\u524d\u4e8c\uff09\uff0cInformer\u63d0\u4f9b\u7ade\u4e89\u6027\u51c6\u786e\u5ea6\uff08F1\uff1a0.683\uff09\u4e14\u8bad\u7ec3\u901f\u5ea6\u5feb30%\uff0c\u7ecf\u5178\u65b9\u6cd5\u5728\u7b80\u5355\u5408\u6210\u6570\u636e\u4e0a\u5b9e\u73b0\u5b8c\u7f8e\u9884\u6d4b\u4f46\u771f\u5b9e\u6570\u636e\u96c6F1\u5f97\u5206\u4f4e2-3\u500d\u3002", "conclusion": "\u9884\u6d4b\u8d28\u91cf\u4e3b\u5bfc\u68c0\u6d4b\u6027\u80fd\uff1a\u68c0\u6d4b\u65b9\u6cd5\u95f4\u5dee\u5f02\u5c0f\u4e8e\u9884\u6d4b\u6a21\u578b\u95f4\u5dee\u5f02\u3002\u5efa\u8bae\u590d\u6742\u6a21\u5f0f\u4f7f\u7528LSTM\uff0c\u6548\u7387\u5173\u952e\u90e8\u7f72\u4f7f\u7528Informer\uff0c\u8d44\u6e90\u53d7\u9650\u7684\u7b80\u5355\u5468\u671f\u6027\u6570\u636e\u4f7f\u7528\u7ecf\u5178\u65b9\u6cd5\u3002\u5b8c\u6574\u5b9e\u73b0\u4e3a\u672a\u6765\u9884\u6d4b\u5f0f\u5f02\u5e38\u68c0\u6d4b\u7814\u7a76\u5efa\u7acb\u4e86\u57fa\u51c6\u3002"}}
{"id": "2510.11168", "categories": ["cs.LG", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.11168", "abs": "https://arxiv.org/abs/2510.11168", "authors": ["Jinbin Zhang", "Nasib Ullah", "Erik Schultheis", "Rohit Babbar"], "title": "ELMO: Efficiency via Low-precision and Peak Memory Optimization in Large Output Spaces", "comment": "Accepted to ICML 2025", "summary": "Large output spaces, also referred to as Extreme multilabel classification\n(XMC), is a setting that arises, e.g., in large-scale tagging and\nproduct-to-product recommendation, and is characterized by the number of labels\nranging from hundreds of thousands to millions. This means that the linear\nclassification head, usually only a tiny fraction of the overall model, turns\ninto the main driver for compute and memory demand. Current state-of-the-art\nXMC methods predominantly rely on FP16-FP32 mixed-precision training, which we\nshow can be unstable, and inefficient in terms of memory usage and\ncomputational overhead. Meanwhile, existing low-precision methods typically\nretain higher precision for the classification layer. In this work, we propose\nELMO, a pure low-precision training framework for XMC models using BFloat16 and\nFloat8 data types. By leveraging Kahan summation and stochastic rounding, we\ndemonstrate that XMC models can be effectively trained entirely in Float8,\nwithout relying on single-precision master weights or tensor scaling.\nLow-precision training, combined with our proposed memory optimizations --\ngradient fusion and chunking -- enables significant reductions in GPU memory\nusage. For example, we train a 3-million-label XMC model with only 6.6 GiB of\nGPU memory, compared to the 39.7 GiB required by the optimized SOTA method,\nRenee without compromising accuracy.", "AI": {"tldr": "ELMO\u662f\u4e00\u4e2a\u7eaf\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u6781\u7aef\u591a\u6807\u7b7e\u5206\u7c7b(XMC)\u6a21\u578b\uff0c\u4f7f\u7528BFloat16\u548cFloat8\u6570\u636e\u7c7b\u578b\uff0c\u901a\u8fc7Kahan\u6c42\u548c\u548c\u968f\u673a\u820d\u5165\u5b9e\u73b0\u5b8c\u5168Float8\u8bad\u7ec3\uff0c\u663e\u8457\u51cf\u5c11GPU\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u5f53\u524dXMC\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56FP16-FP32\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u5b58\u5728\u4e0d\u7a33\u5b9a\u3001\u5185\u5b58\u4f7f\u7528\u548c\u8ba1\u7b97\u5f00\u9500\u4f4e\u6548\u7684\u95ee\u9898\uff0c\u800c\u73b0\u6709\u4f4e\u7cbe\u5ea6\u65b9\u6cd5\u901a\u5e38\u4e3a\u5206\u7c7b\u5c42\u4fdd\u7559\u66f4\u9ad8\u7cbe\u5ea6\u3002", "method": "\u63d0\u51faELMO\u6846\u67b6\uff0c\u4f7f\u7528BFloat16\u548cFloat8\u6570\u636e\u7c7b\u578b\uff0c\u7ed3\u5408Kahan\u6c42\u548c\u548c\u968f\u673a\u820d\u5165\u6280\u672f\uff0c\u5b9e\u73b0\u5b8c\u5168Float8\u8bad\u7ec3\uff0c\u65e0\u9700\u5355\u7cbe\u5ea6\u4e3b\u6743\u91cd\u6216\u5f20\u91cf\u7f29\u653e\uff0c\u5e76\u91c7\u7528\u68af\u5ea6\u878d\u5408\u548c\u5206\u5757\u5185\u5b58\u4f18\u5316\u3002", "result": "\u6210\u529f\u8bad\u7ec3300\u4e07\u6807\u7b7e\u7684XMC\u6a21\u578b\u4ec5\u97006.6 GiB GPU\u5185\u5b58\uff0c\u800c\u4f18\u5316SOTA\u65b9\u6cd5Renee\u9700\u898139.7 GiB\uff0c\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u6027\u3002", "conclusion": "ELMO\u8bc1\u660e\u4e86XMC\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u5b8c\u5168\u5728Float8\u4e2d\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5185\u5b58\u4f7f\u7528\u51cf\u5c11\uff0c\u4e3a\u5927\u89c4\u6a21\u591a\u6807\u7b7e\u5206\u7c7b\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11170", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11170", "abs": "https://arxiv.org/abs/2510.11170", "authors": ["Daniel Scalena", "Leonidas Zotos", "Elisabetta Fersini", "Malvina Nissim", "Ahmet \u00dcst\u00fcn"], "title": "EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling", "comment": null, "summary": "With the rise of reasoning language models and test-time scaling methods as a\nparadigm for improving model performance, substantial computation is often\nrequired to generate multiple candidate sequences from the same prompt. This\nenables exploration of different reasoning paths toward the correct solution,\nhowever, allocates the same compute budget for each prompt. Grounded on the\nassumption that different prompts carry different degrees of complexity, and\nthus different computation needs, we propose EAGer, a training-free generation\nmethod that leverages model uncertainty through token-wise entropy distribution\nto reduce redundant computation and concurrently improve overall performance.\nEAGer allows branching to multiple reasoning paths only in the presence of\nhigh-entropy tokens, and then reallocates the saved compute budget to the\ninstances where exploration of alternative paths is most needed. We find that\nacross multiple open-source models on complex reasoning benchmarks such as AIME\n2025, EAGer can reallocate the budget without accessing target labels,\nachieving the best efficiency-performance trade-off in terms of reasoning\nlength and Pass@k. When target labels are accessible, EAGer generates up to 65%\nfewer tokens (hence saving compute) and achieves up to 37% improvement in\nPass@k compared to the Full Parallel Sampling.", "AI": {"tldr": "EAGer\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u4ee4\u724c\u71b5\u5206\u5e03\u52a8\u6001\u5206\u914d\u8ba1\u7b97\u9884\u7b97\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u548c\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u901a\u5e38\u4e3a\u6bcf\u4e2a\u63d0\u793a\u5206\u914d\u76f8\u540c\u7684\u8ba1\u7b97\u9884\u7b97\uff0c\u4f46\u4e0d\u540c\u63d0\u793a\u7684\u590d\u6742\u5ea6\u548c\u8ba1\u7b97\u9700\u6c42\u4e0d\u540c\uff0c\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u3002", "method": "\u5229\u7528\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u901a\u8fc7\u4ee4\u724c\u7ea7\u71b5\u5206\u5e03\uff0c\u4ec5\u5728\u51fa\u73b0\u9ad8\u71b5\u4ee4\u724c\u65f6\u5206\u652f\u5230\u591a\u4e2a\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u5c06\u8282\u7701\u7684\u8ba1\u7b97\u9884\u7b97\u91cd\u65b0\u5206\u914d\u7ed9\u6700\u9700\u8981\u63a2\u7d22\u66ff\u4ee3\u8def\u5f84\u7684\u5b9e\u4f8b\u3002", "result": "\u5728AIME 2025\u7b49\u590d\u6742\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEAGer\u65e0\u9700\u8bbf\u95ee\u76ee\u6807\u6807\u7b7e\u5373\u53ef\u91cd\u65b0\u5206\u914d\u9884\u7b97\uff0c\u5728\u63a8\u7406\u957f\u5ea6\u548cPass@k\u65b9\u9762\u5b9e\u73b0\u6700\u4f73\u6548\u7387-\u6027\u80fd\u6743\u8861\uff1b\u5f53\u53ef\u8bbf\u95ee\u76ee\u6807\u6807\u7b7e\u65f6\uff0c\u76f8\u6bd4\u5168\u5e76\u884c\u91c7\u6837\u53ef\u51cf\u5c1165%\u4ee4\u724c\u751f\u6210\u5e76\u63d0\u534737%\u7684Pass@k\u3002", "conclusion": "EAGer\u901a\u8fc7\u52a8\u6001\u8ba1\u7b97\u9884\u7b97\u5206\u914d\u6709\u6548\u63d0\u5347\u4e86\u63a8\u7406\u6a21\u578b\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u4e3a\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u7684\u8ba1\u7b97\u8d44\u6e90\u7ba1\u7406\u65b9\u6848\u3002"}}
{"id": "2510.11188", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2510.11188", "abs": "https://arxiv.org/abs/2510.11188", "authors": ["Xinhui Chen", "Zuchao Li", "Mengqi Gao", "Yufeng Zhang", "Chak Tou Leong", "Haoyang Li", "Jiaqi Chen"], "title": "Protein as a Second Language for LLMs", "comment": "Main paper: 9 pages, 6 figures. With references and appendix: 18\n  pages, 9 figures total. Submitted to ICLR 2026 (under review)", "summary": "Deciphering the function of unseen protein sequences is a fundamental\nchallenge with broad scientific impact, yet most existing methods depend on\ntask-specific adapters or large-scale supervised fine-tuning. We introduce the\n\"Protein-as-Second-Language\" framework, which reformulates amino-acid sequences\nas sentences in a novel symbolic language that large language models can\ninterpret through contextual exemplars. Our approach adaptively constructs\nsequence-question-answer triples that reveal functional cues in a zero-shot\nsetting, without any further training. To support this process, we curate a\nbilingual corpus of 79,926 protein-QA instances spanning attribute prediction,\ndescriptive understanding, and extended reasoning. Empirically, our method\ndelivers consistent gains across diverse open-source LLMs and GPT-4, achieving\nup to 17.2% ROUGE-L improvement (average +7%) and even surpassing fine-tuned\nprotein-specific language models. These results highlight that generic LLMs,\nwhen guided with protein-as-language cues, can outperform domain-specialized\nmodels, offering a scalable pathway for protein understanding in foundation\nmodels.", "AI": {"tldr": "\u63d0\u51fa'\u86cb\u767d\u8d28\u4f5c\u4e3a\u7b2c\u4e8c\u8bed\u8a00'\u6846\u67b6\uff0c\u5c06\u6c28\u57fa\u9178\u5e8f\u5217\u8f6c\u5316\u4e3a\u7b26\u53f7\u8bed\u8a00\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u901a\u8fc7\u4e0a\u4e0b\u6587\u793a\u4f8b\u89e3\u91ca\u86cb\u767d\u8d28\u529f\u80fd\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u86cb\u767d\u8d28\u529f\u80fd\u9884\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4efb\u52a1\u7279\u5b9a\u9002\u914d\u5668\u6216\u5927\u89c4\u6a21\u76d1\u7763\u5fae\u8c03\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u86cb\u767d\u8d28\u7406\u89e3\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u6784\u5efa\u5e8f\u5217-\u95ee\u9898-\u7b54\u6848\u4e09\u5143\u7ec4\uff0c\u5c06\u6c28\u57fa\u9178\u5e8f\u5217\u91cd\u65b0\u8868\u8ff0\u4e3a\u7b26\u53f7\u8bed\u8a00\u53e5\u5b50\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u793a\u4f8b\u8fdb\u884c\u96f6\u6837\u672c\u63a8\u7406\u3002", "result": "\u5728\u591a\u79cd\u5f00\u6e90LLM\u548cGPT-4\u4e0a\u5b9e\u73b0\u4e00\u81f4\u6027\u80fd\u63d0\u5347\uff0cROUGE-L\u6700\u9ad8\u63d0\u534717.2%\uff08\u5e73\u5747+7%\uff09\uff0c\u751a\u81f3\u8d85\u8d8a\u4e13\u95e8\u8bad\u7ec3\u7684\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u86cb\u767d\u8d28\u8bed\u8a00\u7ebf\u7d22\u5f15\u5bfc\u4e0b\u80fd\u8d85\u8d8a\u9886\u57df\u4e13\u7528\u6a21\u578b\uff0c\u4e3a\u86cb\u767d\u8d28\u7406\u89e3\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2510.11202", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.11202", "abs": "https://arxiv.org/abs/2510.11202", "authors": ["Marco Pintore", "Giorgio Piras", "Angelo Sotgiu", "Maura Pintor", "Battista Biggio"], "title": "Evaluating Line-level Localization Ability of Learning-based Code Vulnerability Detection Models", "comment": "Preprint", "summary": "To address the extremely concerning problem of software vulnerability, system\nsecurity is often entrusted to Machine Learning (ML) algorithms. Despite their\nnow established detection capabilities, such models are limited by design to\nflagging the entire input source code function as vulnerable, rather than\nprecisely localizing the concerned code lines. However, the detection\ngranularity is crucial to support human operators during software development,\nensuring that such predictions reflect the true code semantics to help debug,\nevaluate, and fix the detected vulnerabilities. To address this issue, recent\nwork made progress toward improving the detector's localization ability, thus\nnarrowing down the vulnerability detection \"window\" and providing more\nfine-grained predictions. Such approaches, however, implicitly disregard the\npresence of spurious correlations and biases in the data, which often\npredominantly influence the performance of ML algorithms. In this work, we\ninvestigate how detectors comply with this requirement by proposing an\nexplainability-based evaluation procedure. Our approach, defined as Detection\nAlignment (DA), quantifies the agreement between the input source code lines\nthat most influence the prediction and the actual localization of the\nvulnerability as per the ground truth. Through DA, which is model-agnostic and\nadaptable to different detection tasks, not limited to our use case, we analyze\nmultiple learning-based vulnerability detectors and datasets. As a result, we\nshow how the predictions of such models are consistently biased by\nnon-vulnerable lines, ultimately highlighting the high impact of biases and\nspurious correlations. The code is available at\nhttps://github.com/pralab/vuln-localization-eval.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u89e3\u91ca\u6027\u7684\u68c0\u6d4b\u5bf9\u9f50\uff08DA\uff09\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u5668\u7684\u5b9a\u4f4d\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u7684\u504f\u89c1\u548c\u4f2a\u76f8\u5173\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6f0f\u6d1e\u68c0\u6d4b\u5668\u53ea\u80fd\u6807\u8bb0\u6574\u4e2a\u6e90\u4ee3\u7801\u51fd\u6570\u4e3a\u6613\u53d7\u653b\u51fb\uff0c\u800c\u65e0\u6cd5\u7cbe\u786e\u5b9a\u4f4d\u5177\u4f53\u4ee3\u7801\u884c\u3002\u68c0\u6d4b\u7c92\u5ea6\u5bf9\u4e8e\u652f\u6301\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u8c03\u8bd5\u548c\u4fee\u590d\u6f0f\u6d1e\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u68c0\u6d4b\u5bf9\u9f50\uff08DA\uff09\u65b9\u6cd5\uff0c\u91cf\u5316\u6a21\u578b\u9884\u6d4b\u4e2d\u6700\u6709\u5f71\u54cd\u7684\u8f93\u5165\u4ee3\u7801\u884c\u4e0e\u771f\u5b9e\u6f0f\u6d1e\u4f4d\u7f6e\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u3002\u8be5\u65b9\u6cd5\u4e0e\u6a21\u578b\u65e0\u5173\uff0c\u53ef\u9002\u5e94\u4e0d\u540c\u7684\u68c0\u6d4b\u4efb\u52a1\u3002", "result": "\u5206\u6790\u591a\u4e2a\u57fa\u4e8e\u5b66\u4e60\u7684\u6f0f\u6d1e\u68c0\u6d4b\u5668\u548c\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u7684\u9884\u6d4b\u6301\u7eed\u53d7\u5230\u975e\u6613\u53d7\u653b\u51fb\u4ee3\u7801\u884c\u7684\u504f\u89c1\u5f71\u54cd\uff0c\u7a81\u663e\u4e86\u504f\u89c1\u548c\u4f2a\u76f8\u5173\u6027\u7684\u9ad8\u5f71\u54cd\u3002", "conclusion": "\u73b0\u6709\u6f0f\u6d1e\u68c0\u6d4b\u5668\u5728\u5b9a\u4f4d\u80fd\u529b\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u5176\u9884\u6d4b\u53d7\u5230\u6570\u636e\u4e2d\u504f\u89c1\u548c\u4f2a\u76f8\u5173\u6027\u7684\u4e25\u91cd\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u6539\u8fdb\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.11234", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11234", "abs": "https://arxiv.org/abs/2510.11234", "authors": ["Jegwang Ryu", "Minkyu Kim", "Seungjun Shin", "Hee Min Choi", "Dokwan Oh", "Jaeho Lee"], "title": "Neural Weight Compression for Language Models", "comment": null, "summary": "The efficient storage and transmission of language model weights is becoming\nincreasingly important, as their scale and adoption continue to grow. However,\nas our understanding of this new data modality is limited, designing a good\ncompression algorithm for language model weights heavily relies on manual,\ntrial-and-error approaches. In this paper, we propose a learned compression\nframework that trains neural codecs directly from pretrained language model\nweights. Unlike conventional data (e.g., images), language model weights pose\nunique challenges: the sizes and shapes of weight tensors vary significantly,\nand the reconstruction quality must be judged by downstream model predictions\nrather than na\\\"ive MSE loss. To address this, we introduce Neural Weight\nCompression (NWC), a novel autoencoder-based neural codec tailored to model\nweight compression. The proposed method inherits the advantages of\nautoencoder-based codecs while incorporating three technical components: (1)\ncolumn-wise tensor chunking and normalization; (2) an importance-aware training\nloss; (3) an inference-time error compensation mechanism guided by model\noutputs. Experiments on open-weight language models show that NWC achieves\ncompetitive or state-of-the-art accuracy-compression tradeoffs, with\nparticularly strong results at 4-6 bit precisions where accuracy remains nearly\non par with FP16 models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f16\u89e3\u7801\u5668\u7684\u8bed\u8a00\u6a21\u578b\u6743\u91cd\u538b\u7f29\u6846\u67b6NWC\uff0c\u901a\u8fc7\u81ea\u52a8\u7f16\u7801\u5668\u65b9\u6cd5\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u6743\u91cd\u538b\u7f29\u7684\u72ec\u7279\u6311\u6218\uff0c\u57284-6\u6bd4\u7279\u7cbe\u5ea6\u4e0b\u5b9e\u73b0\u4e0eFP16\u6a21\u578b\u76f8\u8fd1\u7684\u6027\u80fd\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u6743\u91cd\u7684\u5b58\u50a8\u548c\u4f20\u8f93\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u7531\u4e8e\u5bf9\u8be5\u6570\u636e\u6a21\u6001\u7406\u89e3\u6709\u9650\uff0c\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u8bd5\u9519\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u538b\u7f29\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u6743\u91cd\u538b\u7f29(NWC)\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a\u5217\u5411\u5f20\u91cf\u5206\u5757\u548c\u5f52\u4e00\u5316\u3001\u91cd\u8981\u6027\u611f\u77e5\u8bad\u7ec3\u635f\u5931\u3001\u57fa\u4e8e\u6a21\u578b\u8f93\u51fa\u7684\u63a8\u7406\u65f6\u8bef\u5dee\u8865\u507f\u673a\u5236\u3002", "result": "\u5728\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNWC\u5728\u7cbe\u5ea6-\u538b\u7f29\u6743\u8861\u65b9\u9762\u8fbe\u5230\u7ade\u4e89\u6027\u6216\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u7279\u522b\u662f\u57284-6\u6bd4\u7279\u7cbe\u5ea6\u4e0b\u4fdd\u6301\u4e0eFP16\u6a21\u578b\u51e0\u4e4e\u76f8\u540c\u7684\u51c6\u786e\u6027\u3002", "conclusion": "NWC\u6846\u67b6\u4e3a\u8bed\u8a00\u6a21\u578b\u6743\u91cd\u538b\u7f29\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b66\u4e60\u578b\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5b58\u50a8\u548c\u4f20\u8f93\u9700\u6c42\u3002"}}
{"id": "2510.11250", "categories": ["cs.LG", "I.5.2"], "pdf": "https://arxiv.org/pdf/2510.11250", "abs": "https://arxiv.org/abs/2510.11250", "authors": ["Sujan Chakraborty", "Rahul Bordoloi", "Anindya Sengupta", "Olaf Wolkenhauer", "Saptarshi Bej"], "title": "FUSE: Fast Semi-Supervised Node Embedding Learning via Structural and Label-Aware Optimization", "comment": null, "summary": "Graph-based learning is a cornerstone for analyzing structured data, with\nnode classification as a central task. However, in many real-world graphs,\nnodes lack informative feature vectors, leaving only neighborhood connectivity\nand class labels as available signals. In such cases, effective classification\nhinges on learning node embeddings that capture structural roles and\ntopological context. We introduce a fast semi-supervised embedding framework\nthat jointly optimizes three complementary objectives: (i) unsupervised\nstructure preservation via scalable modularity approximation, (ii) supervised\nregularization to minimize intra-class variance among labeled nodes, and (iii)\nsemi-supervised propagation that refines unlabeled nodes through\nrandom-walk-based label spreading with attention-weighted similarity. These\ncomponents are unified into a single iterative optimization scheme, yielding\nhigh-quality node embeddings. On standard benchmarks, our method consistently\nachieves classification accuracy at par with or superior to state-of-the-art\napproaches, while requiring significantly less computational cost.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u534a\u76d1\u7763\u56fe\u5d4c\u5165\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u7ed3\u6784\u4fdd\u6301\u3001\u76d1\u7763\u6b63\u5219\u5316\u548c\u534a\u76d1\u7763\u4f20\u64ad\u4e09\u4e2a\u76ee\u6807\uff0c\u5728\u7f3a\u4e4f\u8282\u70b9\u7279\u5f81\u4fe1\u606f\u7684\u56fe\u4e2d\u5b9e\u73b0\u9ad8\u6548\u8282\u70b9\u5206\u7c7b\u3002", "motivation": "\u8bb8\u591a\u73b0\u5b9e\u56fe\u6570\u636e\u4e2d\u8282\u70b9\u7f3a\u4e4f\u4fe1\u606f\u4e30\u5bcc\u7684\u7279\u5f81\u5411\u91cf\uff0c\u4ec5\u80fd\u5229\u7528\u90bb\u57df\u8fde\u901a\u6027\u548c\u7c7b\u522b\u6807\u7b7e\u4f5c\u4e3a\u53ef\u7528\u4fe1\u53f7\uff0c\u9700\u8981\u5b66\u4e60\u80fd\u591f\u6355\u6349\u7ed3\u6784\u89d2\u8272\u548c\u62d3\u6251\u4e0a\u4e0b\u6587\u7684\u8282\u70b9\u5d4c\u5165\u3002", "method": "\u8054\u5408\u4f18\u5316\u4e09\u4e2a\u4e92\u8865\u76ee\u6807\uff1a\u901a\u8fc7\u53ef\u6269\u5c55\u6a21\u5757\u5316\u8fd1\u4f3c\u5b9e\u73b0\u65e0\u76d1\u7763\u7ed3\u6784\u4fdd\u6301\uff1b\u76d1\u7763\u6b63\u5219\u5316\u6700\u5c0f\u5316\u6807\u8bb0\u8282\u70b9\u7684\u7c7b\u5185\u65b9\u5dee\uff1b\u57fa\u4e8e\u968f\u673a\u6e38\u8d70\u7684\u6ce8\u610f\u529b\u52a0\u6743\u76f8\u4f3c\u6027\u6807\u7b7e\u4f20\u64ad\u6765\u7ec6\u5316\u672a\u6807\u8bb0\u8282\u70b9\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u8282\u70b9\u5d4c\u5165\uff0c\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u7f3a\u4e4f\u8282\u70b9\u7279\u5f81\u7684\u56fe\u6570\u636e\u5206\u7c7b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11274", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11274", "abs": "https://arxiv.org/abs/2510.11274", "authors": ["Jianzhe Zhao", "Hailin Zhu", "Yu Zhang", "Ziqi Chen", "Guibing Guo"], "title": "FedLoRA-Optimizer: Federated LoRA Fine-Tuning with Global and Local Optimization in Heterogeneous Data Scenarios", "comment": null, "summary": "Federated efficient fine-tuning has emerged as an approach that leverages\ndistributed data and computational resources across nodes to address the\nchallenges of large-scale fine-tuning and privacy preservation. The Low-Rank\nAdaptation (LoRA) enables efficient fine-tuning of large-scale pre-trained\nmodels by introducing trainable low-rank matrices into weight updates.However,\nin heterogeneous data scenarios, client drift weakens the generalization of the\nglobal model, and local models often fail to meet the personalized needs of\nindividual clients.Moreover, existing federated LoRA efficient fine-tuning\ntechniques overlook fine-grained analysis of the tuning matrices. To address\nthis, we conducted preliminary experiments and found that different LoRA\nmatrices exhibit different sensitivity to changes in the direction and\nmagnitude of their vectors.We thus propose a fine-grained federated LoRA tuning\nmethod. By fine-tuning the more sensitive directional vectors in the A matrix,\nwhich encode shared knowledge, our method learns shared features more\neffectively across clients and enhances global generalization. Simultaneously,\nby fine-tuning the more sensitive magnitude vectors in the B matrix, which\nencode personalized knowledge, our method better captures personalized\nknowledge, enabling detailed adaptation to local data. The method uses a\npipeline combining global and local optimizers. Global optimization further\nimproves local models, achieving collaborative optimization between global and\nlocal levels. This improves both the generalization ability of the global model\nand the personalized adaptation of local models under heterogeneous data\nscenarios. Experiments on Databricks-Dolly-15k and Natural Instructions with\nLLaMA2-7B and Deepseek-7B confirm that our method improves global performance\nby 0.39% and local performance by 0.59%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ec6\u7c92\u5ea6\u8054\u90a6LoRA\u8c03\u4f18\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u522b\u8c03\u6574A\u77e9\u9635\u4e2d\u66f4\u654f\u611f\u7684\u65b9\u5411\u5411\u91cf\u548cB\u77e9\u9635\u4e2d\u66f4\u654f\u611f\u7684\u5e45\u5ea6\u5411\u91cf\uff0c\u5728\u5f02\u6784\u6570\u636e\u573a\u666f\u4e0b\u540c\u65f6\u63d0\u5347\u5168\u5c40\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u672c\u5730\u6a21\u578b\u7684\u4e2a\u6027\u5316\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u9ad8\u6548\u5fae\u8c03\u4e2d\u5ba2\u6237\u7aef\u6f02\u79fb\u524a\u5f31\u5168\u5c40\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u4ee5\u53ca\u672c\u5730\u6a21\u578b\u65e0\u6cd5\u6ee1\u8db3\u4e2a\u6027\u5316\u9700\u6c42\u7684\u95ee\u9898\uff0c\u540c\u65f6\u73b0\u6709\u8054\u90a6LoRA\u6280\u672f\u7f3a\u4e4f\u5bf9\u8c03\u4f18\u77e9\u9635\u7684\u7ec6\u7c92\u5ea6\u5206\u6790\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\u4e0d\u540cLoRA\u77e9\u9635\u5bf9\u5176\u5411\u91cf\u65b9\u5411\u548c\u5e45\u5ea6\u7684\u53d8\u5316\u5177\u6709\u4e0d\u540c\u654f\u611f\u6027\uff0c\u63d0\u51fa\u7ec6\u7c92\u5ea6\u8054\u90a6LoRA\u8c03\u4f18\u65b9\u6cd5\uff1a\u5fae\u8c03A\u77e9\u9635\u4e2d\u66f4\u654f\u611f\u7684\u65b9\u5411\u5411\u91cf\u5b66\u4e60\u5171\u4eab\u7279\u5f81\uff0c\u5fae\u8c03B\u77e9\u9635\u4e2d\u66f4\u654f\u611f\u7684\u5e45\u5ea6\u5411\u91cf\u6355\u83b7\u4e2a\u6027\u5316\u77e5\u8bc6\uff0c\u91c7\u7528\u5168\u5c40\u548c\u5c40\u90e8\u4f18\u5316\u5668\u7ec4\u5408\u7684\u6d41\u6c34\u7ebf\u5b9e\u73b0\u534f\u540c\u4f18\u5316\u3002", "result": "\u5728Databricks-Dolly-15k\u548cNatural Instructions\u6570\u636e\u96c6\u4e0a\u4f7f\u7528LLaMA2-7B\u548cDeepseek-7B\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5168\u5c40\u6027\u80fd\u63d0\u53470.39%\uff0c\u5c40\u90e8\u6027\u80fd\u63d0\u53470.59%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5f02\u6784\u6570\u636e\u573a\u666f\u4e0b\u6709\u6548\u63d0\u5347\u4e86\u5168\u5c40\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u672c\u5730\u6a21\u578b\u7684\u4e2a\u6027\u5316\u9002\u5e94\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u4e0e\u5c40\u90e8\u5c42\u9762\u7684\u534f\u540c\u4f18\u5316\u3002"}}
{"id": "2510.11278", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.11278", "abs": "https://arxiv.org/abs/2510.11278", "authors": ["Gareth Seneque", "Lap-Hang Ho", "Nafise Erfanian Saeedi", "Jeffrey Molendijk", "Ariel Kupermann", "Tim Elson"], "title": "ENIGMA: The Geometry of Reasoning and Alignment in Large-Language Models", "comment": "52 pages, 10 figures", "summary": "We present Entropic Mutual-Information Geometry Large-Language Model\nAlignment (ENIGMA), a novel approach to Large-Language Model (LLM) training\nthat jointly improves reasoning, alignment and robustness by treating an\norganisation's policies/principles as directions to move on a model's\ninformation manifold. Our single-loop trainer combines Group-Relative Policy\nOptimisation (GRPO), an on-policy, critic-free RL method with Chain-of-Thought\n(CoT)-format only rewards; a Self-Supervised Alignment with Mutual Information\n(SAMI)-style symmetric InfoNCE auxiliary; and an entropic Sinkhorn\noptimal-transport regulariser on hidden-state distributions to bound geometry\ndrift. We also introduce infoNCE metrics that specialise to a standard MI lower\nbound under matched negatives to measure how strongly a model's CoT encodes\nthese policies. These metrics include a Sufficiency Index (SI) that enables the\nselection and creation of principles that maximise downstream performance prior\nto training. In our experiments using small (1B) LLMs, high-SI principles\npredict steadier training dynamics and improved benchmark performance over GRPO\nablations. Our information-geometry analysis of trained models validates\ndesirable structural change in the manifold. These results support our\nhypothesis that reasoning, alignment, and robustness are projections of a\nsingle informationgeometric objective, and that models trained using ENIGMA\ndemonstrate principled reasoning without the use of a reward model, offering a\npath to trusted capability", "AI": {"tldr": "ENIGMA\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7ec4\u7ec7\u653f\u7b56/\u539f\u5219\u89c6\u4e3a\u4fe1\u606f\u6d41\u5f62\u4e0a\u7684\u79fb\u52a8\u65b9\u5411\uff0c\u8054\u5408\u6539\u8fdb\u63a8\u7406\u3001\u5bf9\u9f50\u548c\u9c81\u68d2\u6027\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86GRPO\u5f3a\u5316\u5b66\u4e60\u3001SAMI\u98ce\u683c\u7684\u4fe1\u606f\u5bf9\u6bd4\u8f85\u52a9\u548c\u71b5\u6b63\u5219\u5316\uff0c\u65e0\u9700\u5956\u52b1\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u539f\u5219\u6027\u63a8\u7406\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u63a8\u7406\u3001\u5bf9\u9f50\u548c\u9c81\u68d2\u6027\u901a\u5e38\u662f\u5206\u5f00\u4f18\u5316\u7684\uff0c\u4f5c\u8005\u5047\u8bbe\u8fd9\u4e9b\u662f\u5355\u4e00\u4fe1\u606f\u51e0\u4f55\u76ee\u6807\u7684\u4e0d\u540c\u6295\u5f71\uff0c\u5e0c\u671b\u901a\u8fc7\u7edf\u4e00\u7684\u4fe1\u606f\u51e0\u4f55\u6846\u67b6\u6765\u540c\u65f6\u6539\u8fdb\u8fd9\u4e9b\u80fd\u529b\u3002", "method": "\u5355\u5faa\u73af\u8bad\u7ec3\u5668\u7ed3\u5408\uff1a1) GRPO\u7b56\u7565\u4f18\u5316\uff08\u57fa\u4e8eCoT\u683c\u5f0f\u5956\u52b1\u7684\u65e0\u8bc4\u8bba\u8005RL\u65b9\u6cd5\uff09\uff1b2) SAMI\u98ce\u683c\u7684\u5bf9\u79f0InfoNCE\u8f85\u52a9\uff1b3) \u9690\u72b6\u6001\u5206\u5e03\u7684\u71b5Sinkhorn\u6700\u4f18\u4f20\u8f93\u6b63\u5219\u5316\u3002\u8fd8\u5f15\u5165\u4e86infoNCE\u6307\u6807\u6765\u6d4b\u91cf\u6a21\u578bCoT\u5bf9\u539f\u5219\u7684\u7f16\u7801\u5f3a\u5ea6\u3002", "result": "\u57281B\u53c2\u6570\u7684\u5c0f\u6a21\u578b\u5b9e\u9a8c\u4e2d\uff0c\u9ad8\u5145\u5206\u6027\u6307\u6570(SI)\u7684\u539f\u5219\u9884\u6d4b\u4e86\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u52a8\u6001\u548c\u4f18\u4e8eGRPO\u6d88\u878d\u5b9e\u9a8c\u7684\u57fa\u51c6\u6027\u80fd\u3002\u4fe1\u606f\u51e0\u4f55\u5206\u6790\u9a8c\u8bc1\u4e86\u6d41\u5f62\u7ed3\u6784\u7684\u7406\u60f3\u53d8\u5316\u3002", "conclusion": "ENIGMA\u652f\u6301\u4e86\u63a8\u7406\u3001\u5bf9\u9f50\u548c\u9c81\u68d2\u6027\u662f\u5355\u4e00\u4fe1\u606f\u51e0\u4f55\u76ee\u6807\u6295\u5f71\u7684\u5047\u8bbe\uff0c\u65e0\u9700\u5956\u52b1\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u539f\u5219\u6027\u63a8\u7406\uff0c\u4e3a\u53ef\u4fe1\u80fd\u529b\u63d0\u4f9b\u4e86\u8def\u5f84\u3002"}}
{"id": "2510.11282", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11282", "abs": "https://arxiv.org/abs/2510.11282", "authors": ["Ning Yang", "Hengyu Zhong", "Haijun Zhang", "Randall Berry"], "title": "Vision-LLMs for Spatiotemporal Traffic Forecasting", "comment": null, "summary": "Accurate spatiotemporal traffic forecasting is a critical prerequisite for\nproactive resource management in dense urban mobile networks. While Large\nLanguage Models (LLMs) have shown promise in time series analysis, they\ninherently struggle to model the complex spatial dependencies of grid-based\ntraffic data. Effectively extending LLMs to this domain is challenging, as\nrepresenting the vast amount of information from dense geographical grids can\nbe inefficient and overwhelm the model's context. To address these challenges,\nwe propose ST-Vision-LLM, a novel framework that reframes spatiotemporal\nforecasting as a vision-language fusion problem. Our approach leverages a\nVision-LLM visual encoder to process historical global traffic matrices as\nimage sequences, providing the model with a comprehensive global view to inform\ncell-level predictions. To overcome the inefficiency of LLMs in handling\nnumerical data, we introduce an efficient encoding scheme that represents\nfloating-point values as single tokens via a specialized vocabulary, coupled\nwith a two-stage numerical alignment fine-tuning process. The model is first\ntrained with Supervised Fine-Tuning (SFT) and then further optimized for\npredictive accuracy using Group Relative Policy Optimization (GRPO), a\nmemory-efficient reinforcement learning method. Evaluations on real-world\nmobile traffic datasets demonstrate that ST-Vision-LLM outperforms existing\nmethods by 15.6% in long-term prediction accuracy and exceeds the second-best\nbaseline by over 30.04% in cross-domain few-shot scenarios. Our extensive\nexperiments validate the model's strong generalization capabilities across\nvarious data-scarce environments.", "AI": {"tldr": "ST-Vision-LLM\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u65f6\u7a7a\u4ea4\u901a\u9884\u6d4b\u6846\u67b6\uff0c\u5c06\u9884\u6d4b\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u89c6\u89c9-\u8bed\u8a00\u878d\u5408\u95ee\u9898\uff0c\u901a\u8fc7Vision-LLM\u89c6\u89c9\u7f16\u7801\u5668\u5904\u7406\u5386\u53f2\u4ea4\u901a\u77e9\u9635\u5e8f\u5217\uff0c\u5e76\u5f15\u5165\u9ad8\u6548\u7f16\u7801\u65b9\u6848\u548c\u4e24\u9636\u6bb5\u5bf9\u9f50\u5fae\u8c03\uff0c\u5728\u771f\u5b9e\u79fb\u52a8\u6d41\u91cf\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u5efa\u6a21\u57fa\u4e8e\u7f51\u683c\u7684\u4ea4\u901a\u6570\u636e\u590d\u6742\u7a7a\u95f4\u4f9d\u8d56\u6027\u65b9\u9762\u7684\u56fa\u6709\u56f0\u96be\uff0c\u4ee5\u53ca\u8868\u793a\u5bc6\u96c6\u5730\u7406\u7f51\u683c\u4fe1\u606f\u65f6\u6548\u7387\u4f4e\u4e0b\u548c\u4e0a\u4e0b\u6587\u8fc7\u8f7d\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528Vision-LLM\u89c6\u89c9\u7f16\u7801\u5668\u5904\u7406\u5386\u53f2\u5168\u5c40\u4ea4\u901a\u77e9\u9635\u4f5c\u4e3a\u56fe\u50cf\u5e8f\u5217\uff1b\u5f15\u5165\u9ad8\u6548\u7f16\u7801\u65b9\u6848\u5c06\u6d6e\u70b9\u503c\u8868\u793a\u4e3a\u5355\u4e2atoken\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u5fae\u8c03\uff1a\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u57fa\u4e8eGRPO\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u3002", "result": "\u5728\u771f\u5b9e\u79fb\u52a8\u6d41\u91cf\u6570\u636e\u96c6\u4e0a\uff0c\u957f\u671f\u9884\u6d4b\u51c6\u786e\u7387\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad815.6%\uff1b\u5728\u8de8\u57df\u5c11\u6837\u672c\u573a\u666f\u4e0b\uff0c\u6bd4\u7b2c\u4e8c\u597d\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u8d85\u8fc730.04%\uff1b\u5728\u5404\u79cd\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "ST-Vision-LLM\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u65f6\u7a7a\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u89c6\u89c9-\u8bed\u8a00\u878d\u5408\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.11283", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11283", "abs": "https://arxiv.org/abs/2510.11283", "authors": ["Antoine Mouchamps", "Arthur Malherbe", "Adrien Bolland", "Damien Ernst"], "title": "Gym-TORAX: Open-source software for integrating RL with plasma control simulators", "comment": null, "summary": "This paper presents Gym-TORAX, a Python package enabling the implementation\nof Reinforcement Learning (RL) environments for simulating plasma dynamics and\ncontrol in tokamaks. Users define succinctly a set of control actions and\nobservations, and a control objective from which Gym-TORAX creates a Gymnasium\nenvironment that wraps TORAX for simulating the plasma dynamics. The objective\nis formulated through rewards depending on the simulated state of the plasma\nand control action to optimize specific characteristics of the plasma, such as\nperformance and stability. The resulting environment instance is then\ncompatible with a wide range of RL algorithms and libraries and will facilitate\nRL research in plasma control. In its current version, one environment is\nreadily available, based on a ramp-up scenario of the International\nThermonuclear Experimental Reactor (ITER).", "AI": {"tldr": "Gym-TORAX\u662f\u4e00\u4e2aPython\u5305\uff0c\u7528\u4e8e\u521b\u5efa\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u6765\u6a21\u62df\u6258\u5361\u9a6c\u514b\u4e2d\u7684\u7b49\u79bb\u5b50\u4f53\u52a8\u529b\u5b66\u548c\u63a7\u5236\u3002\u7528\u6237\u53ef\u5b9a\u4e49\u63a7\u5236\u52a8\u4f5c\u3001\u89c2\u6d4b\u503c\u548c\u76ee\u6807\uff0c\u7cfb\u7edf\u81ea\u52a8\u751f\u6210\u517c\u5bb9\u591a\u79cdRL\u7b97\u6cd5\u7684\u73af\u5883\u3002", "motivation": "\u4fc3\u8fdb\u7b49\u79bb\u5b50\u4f53\u63a7\u5236\u9886\u57df\u7684\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4fbf\u6377\u7684\u5de5\u5177\u6765\u6a21\u62df\u548c\u4f18\u5316\u6258\u5361\u9a6c\u514b\u7b49\u79bb\u5b50\u4f53\u52a8\u529b\u5b66\u3002", "method": "\u901a\u8fc7\u5305\u88c5TORAX\u6a21\u62df\u5668\uff0c\u5141\u8bb8\u7528\u6237\u5b9a\u4e49\u63a7\u5236\u52a8\u4f5c\u3001\u89c2\u6d4b\u503c\u548c\u57fa\u4e8e\u7b49\u79bb\u5b50\u4f53\u72b6\u6001\u4e0e\u63a7\u5236\u7684\u5956\u52b1\u51fd\u6570\uff0c\u81ea\u52a8\u751f\u6210Gymnasium\u517c\u5bb9\u7684\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eITER\u542f\u52a8\u573a\u666f\u7684\u73b0\u6210\u73af\u5883\uff0c\u4f7fRL\u7b97\u6cd5\u80fd\u591f\u5e94\u7528\u4e8e\u7b49\u79bb\u5b50\u4f53\u63a7\u5236\u95ee\u9898\u7684\u7814\u7a76\u3002", "conclusion": "Gym-TORAX\u4e3a\u7b49\u79bb\u5b50\u4f53\u63a7\u5236\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u4fc3\u8fdb\u8be5\u9886\u57dfRL\u65b9\u6cd5\u7684\u53d1\u5c55\u548c\u5e94\u7528\u3002"}}
{"id": "2510.11292", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11292", "abs": "https://arxiv.org/abs/2510.11292", "authors": ["Wenbo Wu", "Qingyi Si", "Xiurui Pan", "Ye Wang", "Jie Zhang"], "title": "LouisKV: Efficient KV Cache Retrieval for Long Input-Output Sequences", "comment": null, "summary": "While Key-Value (KV) cache succeeds in reducing redundant computations in\nauto-regressive models, it introduces significant memory overhead, limiting its\npractical deployment in long-sequence scenarios. Existing KV retrieval methods\nmitigate this by dynamically retaining only a subset of KV entries on the GPU.\nHowever, they still suffer from notable efficiency and accuracy bottlenecks due\nto per-token retrieval and coarse-grained page-level KV management, especially\nin long-output reasoning scenarios. With the emergence of large reasoning\nmodels, efficiently handling such scenarios has become increasingly important.\nTo address this issue, we present two key observations: (1) critical KVs\nexhibit strong temporal locality during decoding, and (2) these KVs exhibit\ndistinct distribution patterns across the input prompt and generated output.\nBuilding on these observations, we propose LouisKV, an efficient KV cache\nretrieval framework designed for various long-sequence scenarios. Specifically,\nLouisKV introduces a semantic-aware retrieval strategy leveraging temporal\nlocality to trigger retrieval only at semantic boundaries, drastically reducing\ncomputation and data transfer overhead. LouisKV also designs a decoupled,\nfine-grained management scheme that tailors differentiated strategies for input\nand output sequences to create retrieval units that better match the model's\nattention patterns, enabling precise identification of critical KVs.\nFurthermore, to boost efficiency, LouisKV incorporates several kernel-level\noptimizations, including custom Triton and CUDA kernels to accelerate the KV\nclustering and retrieval. Evaluations show that LouisKV achieves up to\n4.7$\\times$ speedup over state-of-the-art KV retrieval methods while\nmaintaining near-lossless accuracy across diverse long-sequence tasks,\nincluding long-input short-output, short-input long-output, and long-input\nlong-output scenarios.", "AI": {"tldr": "LouisKV\u662f\u4e00\u4e2a\u9ad8\u6548\u7684KV\u7f13\u5b58\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7684\u68c0\u7d22\u7b56\u7565\u548c\u7ec6\u7c92\u5ea6\u7ba1\u7406\u65b9\u6848\uff0c\u5728\u957f\u5e8f\u5217\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u65e0\u635f\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684KV\u7f13\u5b58\u65b9\u6cd5\u5728\u957f\u5e8f\u5217\u573a\u666f\u4e2d\u5b58\u5728\u663e\u8457\u7684\u5185\u5b58\u5f00\u9500\u95ee\u9898\uff0c\u4e14\u73b0\u6709KV\u68c0\u7d22\u65b9\u6cd5\u7531\u4e8e\u9010\u4ee4\u724c\u68c0\u7d22\u548c\u7c97\u7c92\u5ea6\u9875\u9762\u7ea7KV\u7ba1\u7406\uff0c\u5728\u957f\u8f93\u51fa\u63a8\u7406\u573a\u666f\u4e2d\u4ecd\u5b58\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u74f6\u9888\u3002", "method": "\u57fa\u4e8e\u5173\u952eKV\u5728\u89e3\u7801\u8fc7\u7a0b\u4e2d\u5177\u6709\u5f3a\u65f6\u95f4\u5c40\u90e8\u6027\u548c\u5728\u8f93\u5165\u63d0\u793a\u4e0e\u751f\u6210\u8f93\u51fa\u4e2d\u5448\u73b0\u4e0d\u540c\u5206\u5e03\u6a21\u5f0f\u7684\u89c2\u5bdf\uff0cLouisKV\u5f15\u5165\u4e86\u8bed\u4e49\u611f\u77e5\u68c0\u7d22\u7b56\u7565\uff08\u4ec5\u5728\u8bed\u4e49\u8fb9\u754c\u89e6\u53d1\u68c0\u7d22\uff09\u548c\u89e3\u8026\u7684\u7ec6\u7c92\u5ea6\u7ba1\u7406\u65b9\u6848\uff08\u4e3a\u8f93\u5165\u548c\u8f93\u51fa\u5e8f\u5217\u5b9a\u5236\u5dee\u5f02\u5316\u7b56\u7565\uff09\uff0c\u5e76\u5305\u542b\u5185\u6838\u7ea7\u4f18\u5316\uff08\u81ea\u5b9a\u4e49Triton\u548cCUDA\u5185\u6838\u52a0\u901fKV\u805a\u7c7b\u548c\u68c0\u7d22\uff09\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0cLouisKV\u76f8\u6bd4\u6700\u5148\u8fdb\u7684KV\u68c0\u7d22\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe4.7\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u5728\u5404\u79cd\u957f\u5e8f\u5217\u4efb\u52a1\uff08\u5305\u62ec\u957f\u8f93\u5165\u77ed\u8f93\u51fa\u3001\u77ed\u8f93\u5165\u957f\u8f93\u51fa\u548c\u957f\u8f93\u5165\u957f\u8f93\u51fa\u573a\u666f\uff09\u4e2d\u4fdd\u6301\u63a5\u8fd1\u65e0\u635f\u7684\u51c6\u786e\u6027\u3002", "conclusion": "LouisKV\u901a\u8fc7\u5229\u7528\u65f6\u95f4\u5c40\u90e8\u6027\u548c\u8bed\u4e49\u8fb9\u754c\uff0c\u7ed3\u5408\u7ec6\u7c92\u5ea6\u7ba1\u7406\u548c\u5185\u6838\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5e8f\u5217\u573a\u666f\u4e2dKV\u7f13\u5b58\u7684\u5185\u5b58\u548c\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11335", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11335", "abs": "https://arxiv.org/abs/2510.11335", "authors": ["Mayank Nagda", "Phil Ostheimer", "Justus Arweiler", "Indra Jungjohann", "Jennifer Werner", "Dennis Wagner", "Aparna Muraleedharan", "Pouya Jafari", "Jochen Schmid", "Fabian Jirasek", "Jakob Burger", "Michael Bortz", "Hans Hasse", "Stephan Mandt", "Marius Kloft", "Sophie Fellenz"], "title": "DiffStyleTS: Diffusion Model for Style Transfer in Time Series", "comment": null, "summary": "Style transfer combines the content of one signal with the style of another.\nIt supports applications such as data augmentation and scenario simulation,\nhelping machine learning models generalize in data-scarce domains. While well\ndeveloped in vision and language, style transfer methods for time series data\nremain limited. We introduce DiffTSST, a diffusion-based framework that\ndisentangles a time series into content and style representations via\nconvolutional encoders and recombines them through a self-supervised\nattention-based diffusion process. At inference, encoders extract content and\nstyle from two distinct series, enabling conditional generation of novel\nsamples to achieve style transfer. We demonstrate both qualitatively and\nquantitatively that DiffTSST achieves effective style transfer. We further\nvalidate its real-world utility by showing that data augmentation with DiffTSST\nimproves anomaly detection in data-scarce regimes.", "AI": {"tldr": "DiffTSST\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u98ce\u683c\u8fc1\u79fb\uff0c\u901a\u8fc7\u5377\u79ef\u7f16\u7801\u5668\u5c06\u65f6\u95f4\u5e8f\u5217\u89e3\u8026\u4e3a\u5185\u5bb9\u548c\u98ce\u683c\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u81ea\u76d1\u7763\u6ce8\u610f\u529b\u6269\u6563\u8fc7\u7a0b\u91cd\u65b0\u7ec4\u5408\u5b83\u4eec\u3002", "motivation": "\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u9886\u57df\u98ce\u683c\u8fc1\u79fb\u65b9\u6cd5\u5df2\u7ecf\u6210\u719f\uff0c\u4f46\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u98ce\u683c\u8fc1\u79fb\u65b9\u6cd5\u4ecd\u7136\u6709\u9650\uff0c\u8fd9\u9650\u5236\u4e86\u5728\u6570\u636e\u7a00\u7f3a\u9886\u57df\u7684\u6570\u636e\u589e\u5f3a\u548c\u573a\u666f\u6a21\u62df\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u5377\u79ef\u7f16\u7801\u5668\u89e3\u8026\u65f6\u95f4\u5e8f\u5217\u7684\u5185\u5bb9\u548c\u98ce\u683c\u8868\u793a\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u6ce8\u610f\u529b\u6269\u6563\u8fc7\u7a0b\u91cd\u65b0\u7ec4\u5408\uff0c\u5728\u63a8\u7406\u65f6\u4ece\u4e24\u4e2a\u4e0d\u540c\u7684\u5e8f\u5217\u63d0\u53d6\u5185\u5bb9\u548c\u98ce\u683c\uff0c\u5b9e\u73b0\u6761\u4ef6\u751f\u6210\u4ee5\u5b9e\u73b0\u98ce\u683c\u8fc1\u79fb\u3002", "result": "\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u8868\u660eDiffTSST\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u98ce\u683c\u8fc1\u79fb\uff0c\u901a\u8fc7DiffTSST\u8fdb\u884c\u6570\u636e\u589e\u5f3a\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "DiffTSST\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u65f6\u95f4\u5e8f\u5217\u7684\u98ce\u683c\u8fc1\u79fb\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u5176\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u6539\u5584\u5f02\u5e38\u68c0\u6d4b\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.11339", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11339", "abs": "https://arxiv.org/abs/2510.11339", "authors": ["Xingtong Yu", "Ruijuan Liang", "Xinming Zhang", "Yuan Fang"], "title": "Event-Aware Prompt Learning for Dynamic Graphs", "comment": "Under review", "summary": "Real-world graph typically evolve via a series of events, modeling dynamic\ninteractions between objects across various domains. For dynamic graph\nlearning, dynamic graph neural networks (DGNNs) have emerged as popular\nsolutions. Recently, prompt learning methods have been explored on dynamic\ngraphs. However, existing methods generally focus on capturing the relationship\nbetween nodes and time, while overlooking the impact of historical events. In\nthis paper, we propose EVP, an event-aware dynamic graph prompt learning\nframework that can serve as a plug-in to existing methods, enhancing their\nability to leverage historical events knowledge. First, we extract a series of\nhistorical events for each node and introduce an event adaptation mechanism to\nalign the fine-grained characteristics of these events with downstream tasks.\nSecond, we propose an event aggregation mechanism to effectively integrate\nhistorical knowledge into node representations. Finally, we conduct extensive\nexperiments on four public datasets to evaluate and analyze EVP.", "AI": {"tldr": "EVP\u662f\u4e00\u4e2a\u4e8b\u4ef6\u611f\u77e5\u7684\u52a8\u6001\u56fe\u63d0\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u53ef\u4f5c\u4e3a\u73b0\u6709\u65b9\u6cd5\u7684\u63d2\u4ef6\uff0c\u901a\u8fc7\u5229\u7528\u5386\u53f2\u4e8b\u4ef6\u77e5\u8bc6\u6765\u589e\u5f3a\u52a8\u6001\u56fe\u5b66\u4e60\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u6001\u56fe\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8282\u70b9\u4e0e\u65f6\u95f4\u7684\u5173\u7cfb\uff0c\u4f46\u5ffd\u89c6\u4e86\u5386\u53f2\u4e8b\u4ef6\u7684\u5f71\u54cd\u3002\u4e3a\u4e86\u66f4\u6709\u6548\u5730\u5229\u7528\u5386\u53f2\u4e8b\u4ef6\u77e5\u8bc6\uff0c\u63d0\u51fa\u4e86EVP\u6846\u67b6\u3002", "method": "\u9996\u5148\u4e3a\u6bcf\u4e2a\u8282\u70b9\u63d0\u53d6\u4e00\u7cfb\u5217\u5386\u53f2\u4e8b\u4ef6\uff0c\u901a\u8fc7\u4e8b\u4ef6\u9002\u5e94\u673a\u5236\u5c06\u4e8b\u4ef6\u7684\u7ec6\u7c92\u5ea6\u7279\u5f81\u4e0e\u4e0b\u6e38\u4efb\u52a1\u5bf9\u9f50\uff1b\u7136\u540e\u63d0\u51fa\u4e8b\u4ef6\u805a\u5408\u673a\u5236\uff0c\u5c06\u5386\u53f2\u77e5\u8bc6\u6709\u6548\u6574\u5408\u5230\u8282\u70b9\u8868\u793a\u4e2d\u3002", "result": "\u5728\u56db\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5bf9EVP\u8fdb\u884c\u4e86\u8bc4\u4f30\u548c\u5206\u6790\u3002", "conclusion": "EVP\u80fd\u591f\u6709\u6548\u589e\u5f3a\u73b0\u6709\u52a8\u6001\u56fe\u5b66\u4e60\u65b9\u6cd5\u5229\u7528\u5386\u53f2\u4e8b\u4ef6\u77e5\u8bc6\u7684\u80fd\u529b\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.11345", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11345", "abs": "https://arxiv.org/abs/2510.11345", "authors": ["Han Lu", "Zichen Liu", "Shaopan Xiong", "Yancheng He", "Wei Gao", "Yanan Wu", "Weixun Wang", "Jiashun Liu", "Yang Li", "Haizhou Zhao", "Ju Huang", "Siran Yang", "Xiaoyang Li", "Yijia Luo", "Zihe Liu", "Ling Pan", "Junchi Yan", "Wei Wang", "Wenbo Su", "Jiamang Wang", "Lin Qu", "Bo Zheng"], "title": "Part II: ROLL Flash -- Accelerating RLVR and Agentic Training with Asynchrony", "comment": null, "summary": "Synchronous Reinforcement Learning (RL) post-training has emerged as a\ncrucial step for enhancing Large Language Models (LLMs) with diverse\ncapabilities. However, many systems designed to accelerate RL post-training\nstill suffer from low resource utilization and limited scalability. We present\nROLL Flash, a system that extends ROLL with native support for asynchronous RL\npost-training. ROLL Flash is built upon two core design principles:\nfine-grained parallelism and rollout-train decoupling. Guided by these\nprinciples, ROLL Flash provides flexible programming interfaces that enable a\nfully asynchronous training architecture and support efficient rollout\nmechanisms, including queue scheduling and environment-level asynchronous\nexecution. Through comprehensive theoretical analysis and extensive\nexperiments, we demonstrate that ROLL Flash significantly improves resource\nutilization and scalability over synchronous RL post-training. ROLL Flash\nachieves up to 2.24x speedup on RLVR tasks and 2.72x on agentic tasks, using\nthe same GPU budget as synchronous baselines. Furthermore, we implement several\npopular off-policy algorithms and verify that asynchronous training can achieve\nperformance on par with synchronous training.", "AI": {"tldr": "ROLL Flash\u662f\u4e00\u4e2a\u652f\u6301\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5e76\u884c\u5316\u548crollout-train\u89e3\u8026\u8bbe\u8ba1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8d44\u6e90\u5229\u7528\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u540c\u6b65\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u7cfb\u7edf\u5b58\u5728\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u548c\u53ef\u6269\u5c55\u6027\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u5f02\u6b65\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u7ec6\u7c92\u5ea6\u5e76\u884c\u5316\u548crollout-train\u89e3\u8026\u4e24\u5927\u8bbe\u8ba1\u539f\u5219\uff0c\u63d0\u4f9b\u7075\u6d3b\u7684\u7f16\u7a0b\u63a5\u53e3\uff0c\u652f\u6301\u5b8c\u5168\u5f02\u6b65\u8bad\u7ec3\u67b6\u6784\u548c\u9ad8\u6548\u7684rollout\u673a\u5236\uff0c\u5305\u62ec\u961f\u5217\u8c03\u5ea6\u548c\u73af\u5883\u7ea7\u5f02\u6b65\u6267\u884c\u3002", "result": "ROLL Flash\u76f8\u6bd4\u540c\u6b65RL\u540e\u8bad\u7ec3\u663e\u8457\u63d0\u9ad8\u4e86\u8d44\u6e90\u5229\u7528\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5728RLVR\u4efb\u52a1\u4e0a\u8fbe\u52302.24\u500d\u52a0\u901f\uff0c\u5728\u667a\u80fd\u4f53\u4efb\u52a1\u4e0a\u8fbe\u52302.72\u500d\u52a0\u901f\uff0c\u4f7f\u7528\u76f8\u540c\u7684GPU\u9884\u7b97\u3002\u5f02\u6b65\u8bad\u7ec3\u6027\u80fd\u4e0e\u540c\u6b65\u8bad\u7ec3\u76f8\u5f53\u3002", "conclusion": "ROLL Flash\u901a\u8fc7\u5f02\u6b65RL\u540e\u8bad\u7ec3\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u540c\u6b65\u8bad\u7ec3\u7684\u8d44\u6e90\u5229\u7528\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11390", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11390", "abs": "https://arxiv.org/abs/2510.11390", "authors": ["Razvan Marinescu", "Victoria-Elisabeth Gruber", "Diego Fajardo"], "title": "Medical Interpretability and Knowledge Maps of Large Language Models", "comment": "29 pages, 34 figures, 5 tables", "summary": "We present a systematic study of medical-domain interpretability in Large\nLanguage Models (LLMs). We study how the LLMs both represent and process\nmedical knowledge through four different interpretability techniques: (1) UMAP\nprojections of intermediate activations, (2) gradient-based saliency with\nrespect to the model weights, (3) layer lesioning/removal and (4) activation\npatching. We present knowledge maps of five LLMs which show, at a\ncoarse-resolution, where knowledge about patient's ages, medical symptoms,\ndiseases and drugs is stored in the models. In particular for Llama3.3-70B, we\nfind that most medical knowledge is processed in the first half of the model's\nlayers. In addition, we find several interesting phenomena: (i) age is often\nencoded in a non-linear and sometimes discontinuous manner at intermediate\nlayers in the models, (ii) the disease progression representation is\nnon-monotonic and circular at certain layers of the model, (iii) in\nLlama3.3-70B, drugs cluster better by medical specialty rather than mechanism\nof action, especially for Llama3.3-70B and (iv) Gemma3-27B and MedGemma-27B\nhave activations that collapse at intermediate layers but recover by the final\nlayers. These results can guide future research on fine-tuning, un-learning or\nde-biasing LLMs for medical tasks by suggesting at which layers in the model\nthese techniques should be applied.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u56db\u79cd\u6280\u672f\u5206\u6790\u4e86LLMs\u5982\u4f55\u8868\u793a\u548c\u5904\u7406\u533b\u5b66\u77e5\u8bc6\uff0c\u53d1\u73b0\u4e86\u533b\u5b66\u77e5\u8bc6\u4e3b\u8981\u5206\u5e03\u5728\u6a21\u578b\u524d\u534a\u5c42\uff0c\u5e76\u63ed\u793a\u4e86\u5e74\u9f84\u7f16\u7801\u3001\u75be\u75c5\u8fdb\u5c55\u8868\u793a\u3001\u836f\u7269\u805a\u7c7b\u7b49\u6709\u8da3\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u4e2d\u7684\u77e5\u8bc6\u8868\u793a\u548c\u5904\u7406\u673a\u5236\uff0c\u4e3a\u672a\u6765\u9488\u5bf9\u533b\u5b66\u4efb\u52a1\u7684\u5fae\u8c03\u3001\u77e5\u8bc6\u9057\u5fd8\u6216\u53bb\u504f\u7f6e\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u4f7f\u7528\u56db\u79cd\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff1aUMAP\u4e2d\u95f4\u6fc0\u6d3b\u6295\u5f71\u3001\u57fa\u4e8e\u68af\u5ea6\u7684\u6743\u91cd\u663e\u8457\u6027\u5206\u6790\u3001\u5c42\u5207\u9664/\u79fb\u9664\u3001\u6fc0\u6d3b\u8865\u4e01\uff0c\u5bf9\u4e94\u4e2aLLMs\u8fdb\u884c\u7cfb\u7edf\u7814\u7a76\u3002", "result": "\u53d1\u73b0\u533b\u5b66\u77e5\u8bc6\u4e3b\u8981\u5206\u5e03\u5728\u6a21\u578b\u524d\u534a\u5c42\uff1b\u5e74\u9f84\u7f16\u7801\u5728\u4e2d\u95f4\u5c42\u5448\u73b0\u975e\u7ebf\u6027\u548c\u4e0d\u8fde\u7eed\u6027\uff1b\u75be\u75c5\u8fdb\u5c55\u8868\u793a\u5728\u67d0\u4e9b\u5c42\u5448\u975e\u5355\u8c03\u548c\u5faa\u73af\u6027\uff1b\u836f\u7269\u6309\u533b\u5b66\u4e13\u4e1a\u800c\u975e\u4f5c\u7528\u673a\u5236\u805a\u7c7b\uff1b\u67d0\u4e9b\u6a21\u578b\u4e2d\u95f4\u5c42\u6fc0\u6d3b\u5d29\u6e83\u4f46\u6700\u7ec8\u5c42\u6062\u590d\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u672a\u6765\u9488\u5bf9\u533b\u5b66\u4efb\u52a1\u7684LLMs\u4f18\u5316\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\uff0c\u5efa\u8bae\u5728\u7279\u5b9a\u6a21\u578b\u5c42\u5e94\u7528\u5fae\u8c03\u3001\u77e5\u8bc6\u9057\u5fd8\u6216\u53bb\u504f\u7f6e\u6280\u672f\u3002"}}
{"id": "2510.11400", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11400", "abs": "https://arxiv.org/abs/2510.11400", "authors": ["Kahou Tam", "Chunlin Tian", "Li Li", "Haikai Zhao", "ChengZhong Xu"], "title": "FedHybrid: Breaking the Memory Wall of Federated Learning via Hybrid Tensor Management", "comment": "Sensys 2024", "summary": "Federated Learning (FL) emerges as a new learning paradigm that enables\nmultiple devices to collaboratively train a shared model while preserving data\nprivacy. However, one fundamental and prevailing challenge that hinders the\ndeployment of FL on mobile devices is the memory limitation. This paper\nproposes \\textit{FedHybrid}, a novel framework that effectively reduces the\nmemory footprint during the training process while guaranteeing the model\naccuracy and the overall training progress. Specifically, \\textit{FedHybrid}\nfirst selects the participating devices for each training round by jointly\nevaluating their memory budget, computing capability, and data diversity. After\nthat, it judiciously analyzes the computational graph and generates an\nexecution plan for each selected client in order to meet the corresponding\nmemory budget while minimizing the training delay through employing a hybrid of\nrecomputation and compression techniques according to the characteristic of\neach tensor. During the local training process, \\textit{FedHybrid} carries out\nthe execution plan with a well-designed activation compression technique to\neffectively achieve memory reduction with minimum accuracy loss. We conduct\nextensive experiments to evaluate \\textit{FedHybrid} on both simulation and\noff-the-shelf mobile devices. The experiment results demonstrate that\n\\textit{FedHybrid} achieves up to a 39.1\\% increase in model accuracy and a\n15.5$\\times$ reduction in wall clock time under various memory budgets compared\nwith the baselines.", "AI": {"tldr": "FedHybrid\u662f\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8bc4\u4f30\u8bbe\u5907\u5185\u5b58\u9884\u7b97\u3001\u8ba1\u7b97\u80fd\u529b\u548c\u6570\u636e\u591a\u6837\u6027\u6765\u9009\u62e9\u53c2\u4e0e\u8bbe\u5907\uff0c\u5e76\u91c7\u7528\u91cd\u8ba1\u7b97\u548c\u538b\u7f29\u6df7\u5408\u6280\u672f\u6765\u51cf\u5c11\u5185\u5b58\u5360\u7528\uff0c\u540c\u65f6\u4fdd\u8bc1\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u79fb\u52a8\u8bbe\u5907\u90e8\u7f72\u9762\u4e34\u5185\u5b58\u9650\u5236\u7684\u6311\u6218\uff0c\u9700\u8981\u5728\u4e0d\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\u548c\u8bad\u7ec3\u8fdb\u5ea6\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u5185\u5b58\u5360\u7528\u3002", "method": "1) \u57fa\u4e8e\u5185\u5b58\u9884\u7b97\u3001\u8ba1\u7b97\u80fd\u529b\u548c\u6570\u636e\u591a\u6837\u6027\u9009\u62e9\u53c2\u4e0e\u8bbe\u5907\uff1b2) \u5206\u6790\u8ba1\u7b97\u56fe\u5e76\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u751f\u6210\u6267\u884c\u8ba1\u5212\uff1b3) \u91c7\u7528\u91cd\u8ba1\u7b97\u548c\u538b\u7f29\u6df7\u5408\u6280\u672f\uff1b4) \u4f7f\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6fc0\u6d3b\u538b\u7f29\u6280\u672f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFedHybrid\u5728\u5404\u79cd\u5185\u5b58\u9884\u7b97\u4e0b\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6a21\u578b\u7cbe\u5ea6\u63d0\u5347\u9ad8\u8fbe39.1%\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1115.5\u500d\u3002", "conclusion": "FedHybrid\u80fd\u6709\u6548\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u5185\u5b58\u9650\u5236\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u6a21\u578b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5185\u5b58\u5360\u7528\u548c\u8bad\u7ec3\u65f6\u95f4\u3002"}}
{"id": "2510.11409", "categories": ["cs.LG", "cs.DL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.11409", "abs": "https://arxiv.org/abs/2510.11409", "authors": ["Lucas Joos", "Daniel A. Keim", "Maximilian T. Fischer"], "title": "Leveraging LLMs for Semi-Automatic Corpus Filtration in Systematic Literature Reviews", "comment": null, "summary": "The creation of systematic literature reviews (SLR) is critical for analyzing\nthe landscape of a research field and guiding future research directions.\nHowever, retrieving and filtering the literature corpus for an SLR is highly\ntime-consuming and requires extensive manual effort, as keyword-based searches\nin digital libraries often return numerous irrelevant publications. In this\nwork, we propose a pipeline leveraging multiple large language models (LLMs),\nclassifying papers based on descriptive prompts and deciding jointly using a\nconsensus scheme. The entire process is human-supervised and interactively\ncontrolled via our open-source visual analytics web interface, LLMSurver, which\nenables real-time inspection and modification of model outputs. We evaluate our\napproach using ground-truth data from a recent SLR comprising over 8,000\ncandidate papers, benchmarking both open and commercial state-of-the-art LLMs\nfrom mid-2024 and fall 2025. Results demonstrate that our pipeline\nsignificantly reduces manual effort while achieving lower error rates than\nsingle human annotators. Furthermore, modern open-source models prove\nsufficient for this task, making the method accessible and cost-effective.\nOverall, our work demonstrates how responsible human-AI collaboration can\naccelerate and enhance systematic literature reviews within academic workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u591aLLM\u7684\u7ba1\u9053\uff0c\u901a\u8fc7\u63cf\u8ff0\u6027\u63d0\u793a\u5206\u7c7b\u8bba\u6587\u5e76\u4f7f\u7528\u5171\u8bc6\u673a\u5236\u8054\u5408\u51b3\u7b56\uff0c\u663e\u8457\u51cf\u5c11\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u7684\u624b\u52a8\u5de5\u4f5c\u91cf\u5e76\u964d\u4f4e\u9519\u8bef\u7387\u3002", "motivation": "\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u7684\u6587\u732e\u68c0\u7d22\u548c\u7b5b\u9009\u8fc7\u7a0b\u8017\u65f6\u4e14\u9700\u8981\u5927\u91cf\u4eba\u5de5\u52aa\u529b\uff0c\u4f20\u7edf\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u641c\u7d22\u65b9\u6cd5\u5f80\u5f80\u8fd4\u56de\u5927\u91cf\u4e0d\u76f8\u5173\u6587\u732e\u3002", "method": "\u5229\u7528\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u7ba1\u9053\uff0c\u57fa\u4e8e\u63cf\u8ff0\u6027\u63d0\u793a\u5bf9\u8bba\u6587\u8fdb\u884c\u5206\u7c7b\uff0c\u91c7\u7528\u5171\u8bc6\u65b9\u6848\u8fdb\u884c\u8054\u5408\u51b3\u7b56\uff0c\u6574\u4e2a\u8fc7\u7a0b\u901a\u8fc7\u5f00\u6e90\u53ef\u89c6\u5316\u5206\u6790\u754c\u9762LLMSurver\u8fdb\u884c\u4eba\u5de5\u76d1\u7763\u548c\u4ea4\u4e92\u63a7\u5236\u3002", "result": "\u5728\u5305\u542b8000\u591a\u7bc7\u5019\u9009\u8bba\u6587\u7684\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7ba1\u9053\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u6bd4\u5355\u4e2a\u4eba\u7c7b\u6807\u6ce8\u8005\u66f4\u4f4e\u7684\u9519\u8bef\u7387\uff0c\u73b0\u4ee3\u5f00\u6e90\u6a21\u578b\u8db3\u4ee5\u80dc\u4efb\u6b64\u4efb\u52a1\u3002", "conclusion": "\u8d1f\u8d23\u4efb\u7684\u4eba\u673a\u534f\u4f5c\u53ef\u4ee5\u52a0\u901f\u548c\u589e\u5f3a\u5b66\u672f\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff0c\u4f7f\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u8bbf\u95ee\u6027\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2510.11442", "categories": ["cs.LG", "cs.AI", "68T05", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.11442", "abs": "https://arxiv.org/abs/2510.11442", "authors": ["Xinyan Guan", "Yongfan Lai", "Jiarui Jin", "Jun Li", "Haoyu Wang", "Qinghao Zhao", "Deyun Zhang", "Shijia Geng", "Shenda Hong"], "title": "Reconstructing 12-Lead ECG from 3-Lead ECG using Variational Autoencoder to Improve Cardiac Disease Detection of Wearable ECG Devices", "comment": "24 pages, 5 figures, submitted to Nature Communications", "summary": "Twelve-lead electrocardiograms (ECGs) are the clinical gold standard for\ncardiac diagnosis, providing comprehensive spatial coverage of the heart\nnecessary to detect conditions such as myocardial infarction (MI). However,\ntheir lack of portability limits continuous and large-scale use. Three-lead ECG\nsystems are widely used in wearable devices due to their simplicity and\nmobility, but they often fail to capture pathologies in unmeasured regions. To\naddress this, we propose WearECG, a Variational Autoencoder (VAE) method that\nreconstructs twelve-lead ECGs from three leads: II, V1, and V5. Our model\nincludes architectural improvements to better capture temporal and spatial\ndependencies in ECG signals. We evaluate generation quality using MSE, MAE, and\nFrechet Inception Distance (FID), and assess clinical validity via a Turing\ntest with expert cardiologists. To further validate diagnostic utility, we\nfine-tune ECGFounder, a large-scale pretrained ECG model, on a multi-label\nclassification task involving over 40 cardiac conditions, including six\ndifferent myocardial infarction locations, using both real and generated\nsignals. Experiments on the MIMIC dataset show that our method produces\nphysiologically realistic and diagnostically informative signals, with robust\nperformance in downstream tasks. This work demonstrates the potential of\ngenerative modeling for ECG reconstruction and its implications for scalable,\nlow-cost cardiac screening.", "AI": {"tldr": "WearECG\u662f\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4ece\u4e09\u4e2a\u5bfc\u8054\uff08II\u3001V1\u3001V5\uff09\u91cd\u5efa\u5341\u4e8c\u5bfc\u8054\u5fc3\u7535\u56fe\uff0c\u89e3\u51b3\u4e86\u53ef\u7a7f\u6234\u8bbe\u5907\u65e0\u6cd5\u5168\u9762\u76d1\u6d4b\u5fc3\u810f\u75c5\u7406\u7684\u95ee\u9898\u3002", "motivation": "\u5341\u4e8c\u5bfc\u8054\u5fc3\u7535\u56fe\u662f\u5fc3\u810f\u8bca\u65ad\u7684\u4e34\u5e8a\u91d1\u6807\u51c6\uff0c\u4f46\u7f3a\u4e4f\u4fbf\u643a\u6027\u9650\u5236\u4e86\u5176\u8fde\u7eed\u548c\u5927\u89c4\u6a21\u4f7f\u7528\u3002\u4e09\u5bfc\u8054\u7cfb\u7edf\u867d\u7136\u4fbf\u643a\uff0c\u4f46\u65e0\u6cd5\u68c0\u6d4b\u672a\u6d4b\u91cf\u533a\u57df\u7684\u5fc3\u810f\u75c5\u7406\u3002", "method": "\u63d0\u51faWearECG\u65b9\u6cd5\uff0c\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u4ece\u4e09\u4e2a\u5bfc\u8054\u91cd\u5efa\u5341\u4e8c\u5bfc\u8054\u5fc3\u7535\u56fe\uff0c\u6539\u8fdb\u4e86\u67b6\u6784\u4ee5\u66f4\u597d\u5730\u6355\u6349ECG\u4fe1\u53f7\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u3002", "result": "\u5728MIMIC\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u751f\u7406\u771f\u5b9e\u4e14\u5177\u6709\u8bca\u65ad\u4ef7\u503c\u7684\u4fe1\u53f7\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c55\u793a\u4e86\u751f\u6210\u6a21\u578b\u5728ECG\u91cd\u5efa\u4e2d\u7684\u6f5c\u529b\uff0c\u5bf9\u53ef\u6269\u5c55\u3001\u4f4e\u6210\u672c\u7684\u5fc3\u810f\u7b5b\u67e5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.11471", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11471", "abs": "https://arxiv.org/abs/2510.11471", "authors": ["Sarthak Mittal", "Divyat Mahajan", "Guillaume Lajoie", "Mohammad Pezeshki"], "title": "Iterative Amortized Inference: Unifying In-Context Learning and Learned Optimizers", "comment": null, "summary": "Modern learning systems increasingly rely on amortized learning - the idea of\nreusing computation or inductive biases shared across tasks to enable rapid\ngeneralization to novel problems. This principle spans a range of approaches,\nincluding meta-learning, in-context learning, prompt tuning, learned optimizers\nand more. While motivated by similar goals, these approaches differ in how they\nencode and leverage task-specific information, often provided as in-context\nexamples. In this work, we propose a unified framework which describes how such\nmethods differ primarily in the aspects of learning they amortize - such as\ninitializations, learned updates, or predictive mappings - and how they\nincorporate task data at inference. We introduce a taxonomy that categorizes\namortized models into parametric, implicit, and explicit regimes, based on\nwhether task adaptation is externalized, internalized, or jointly modeled.\nBuilding on this view, we identify a key limitation in current approaches: most\nmethods struggle to scale to large datasets because their capacity to process\ntask data at inference (e.g., context length) is often limited. To address\nthis, we propose iterative amortized inference, a class of models that refine\nsolutions step-by-step over mini-batches, drawing inspiration from stochastic\noptimization. Our formulation bridges optimization-based meta-learning with\nforward-pass amortization in models like LLMs, offering a scalable and\nextensible foundation for general-purpose task adaptation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u6765\u5206\u6790\u644a\u9500\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u5176\u5206\u7c7b\u4e3a\u53c2\u6570\u5316\u3001\u9690\u5f0f\u548c\u663e\u5f0f\u673a\u5236\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u65b9\u6cd5\u5728\u5904\u7406\u5927\u6570\u636e\u96c6\u65f6\u7684\u5c40\u9650\u6027\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u8fed\u4ee3\u644a\u9500\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c0f\u6279\u91cf\u9010\u6b65\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u901a\u7528\u4efb\u52a1\u9002\u5e94\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002", "motivation": "\u73b0\u4ee3\u5b66\u4e60\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u644a\u9500\u5b66\u4e60\uff0c\u5373\u901a\u8fc7\u8de8\u4efb\u52a1\u5171\u4eab\u8ba1\u7b97\u6216\u5f52\u7eb3\u504f\u7f6e\u6765\u5b9e\u73b0\u5feb\u901f\u6cdb\u5316\u3002\u867d\u7136\u5143\u5b66\u4e60\u3001\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u63d0\u793a\u8c03\u4f18\u7b49\u65b9\u6cd5\u6709\u76f8\u4f3c\u76ee\u6807\uff0c\u4f46\u5b83\u4eec\u5728\u5982\u4f55\u7f16\u7801\u548c\u5229\u7528\u4efb\u52a1\u7279\u5b9a\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u5dee\u5f02\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u6839\u636e\u644a\u9500\u5b66\u4e60\u7684\u4e0d\u540c\u65b9\u9762\uff08\u5982\u521d\u59cb\u5316\u3001\u5b66\u4e60\u66f4\u65b0\u6216\u9884\u6d4b\u6620\u5c04\uff09\u4ee5\u53ca\u5982\u4f55\u5728\u63a8\u7406\u65f6\u6574\u5408\u4efb\u52a1\u6570\u636e\u6765\u5206\u7c7b\u65b9\u6cd5\u3002\u5c06\u644a\u9500\u6a21\u578b\u5206\u4e3a\u53c2\u6570\u5316\u3001\u9690\u5f0f\u548c\u663e\u5f0f\u673a\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u5f53\u524d\u65b9\u6cd5\u5728\u5927\u6570\u636e\u96c6\u4e0a\u7684\u6269\u5c55\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u8fed\u4ee3\u644a\u9500\u63a8\u7406\uff0c\u8fd9\u662f\u4e00\u79cd\u901a\u8fc7\u5c0f\u6279\u91cf\u9010\u6b65\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u7684\u65b9\u6cd5\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u80fd\u591f\u7edf\u4e00\u7406\u89e3\u5404\u79cd\u644a\u9500\u5b66\u4e60\u65b9\u6cd5\u3002\u8fed\u4ee3\u644a\u9500\u63a8\u7406\u65b9\u6cd5\u5c06\u57fa\u4e8e\u4f18\u5316\u7684\u5143\u5b66\u4e60\u4e0eLLMs\u7b49\u6a21\u578b\u4e2d\u7684\u524d\u5411\u4f20\u9012\u644a\u9500\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u4efb\u52a1\u9002\u5e94\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u7edf\u4e00\u6846\u67b6\u548c\u5206\u7c7b\u65b9\u6cd5\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u548c\u6bd4\u8f83\u4e0d\u540c\u7684\u644a\u9500\u5b66\u4e60\u6280\u672f\u3002\u8fed\u4ee3\u644a\u9500\u63a8\u7406\u4e3a\u89e3\u51b3\u5f53\u524d\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u4e3a\u901a\u7528\u4efb\u52a1\u9002\u5e94\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2510.11472", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11472", "abs": "https://arxiv.org/abs/2510.11472", "authors": ["Yanjie Zhu", "Zhen Zhang", "Yunli Wang", "Zhiqiang Wang", "Yu Li", "Rufan Zhou", "Shiyang Wen", "Peng Jiang", "Chenhao Lin", "Jian Yang"], "title": "Differentiable Fast Top-K Selection for Large-Scale Recommendation", "comment": "12 pages, 5 figures", "summary": "Cascade ranking is a widely adopted paradigm in large-scale information\nretrieval systems for Top-K item selection. However, the Top-K operator is\nnon-differentiable, hindering end-to-end training. Existing methods include\nLearning-to-Rank approaches (e.g., LambdaLoss), which optimize ranking metrics\nlike NDCG and suffer from objective misalignment, and differentiable\nsorting-based methods (e.g., ARF, LCRON), which relax permutation matrices for\ndirect Top-K optimization but introduce gradient conflicts through matrix\naggregation. A promising alternative is to directly construct a differentiable\napproximation of the Top-K selection operator, bypassing the use of soft\npermutation matrices. However, even state-of-the-art differentiable Top-K\noperator (e.g., LapSum) require $O(n \\log n)$ complexity due to their\ndependence on sorting for solving the threshold. Thus, we propose DFTopK, a\nnovel differentiable Top-K operator achieving optimal $O(n)$ time complexity.\nBy relaxing normalization constraints, DFTopK admits a closed-form solution and\navoids sorting. DFTopK also avoids the gradient conflicts inherent in\ndifferentiable sorting-based methods. We evaluate DFTopK on both the public\nbenchmark RecFLow and an industrial system. Experimental results show that\nDFTopK significantly improves training efficiency while achieving superior\nperformance, which enables us to scale up training samples more efficiently. In\nthe online A/B test, DFTopK yielded a +1.77\\% revenue lift with the same\ncomputational budget compared to the baseline. To the best of our knowledge,\nthis work is the first to introduce differentiable Top-K operators into\nrecommendation systems and the first to achieve theoretically optimal\nlinear-time complexity for Top-K selection. We have open-sourced our\nimplementation to facilitate future research in both academia and industry.", "AI": {"tldr": "\u63d0\u51faDFTopK\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u53ef\u5fae\u5206Top-K\u7b97\u5b50\uff0c\u5b9e\u73b0\u6700\u4f18O(n)\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u907f\u514d\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u68af\u5ea6\u51b2\u7a81\u548c\u6392\u5e8f\u4f9d\u8d56\u95ee\u9898\u3002", "motivation": "\u7ea7\u8054\u6392\u5e8f\u5728\u5927\u89c4\u6a21\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46Top-K\u7b97\u5b50\u4e0d\u53ef\u5fae\u5206\u963b\u788d\u7aef\u5230\u7aef\u8bad\u7ec3\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u76ee\u6807\u4e0d\u4e00\u81f4\u6216\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\uff0c\u4e14\u590d\u6742\u5ea6\u8f83\u9ad8\u3002", "method": "\u901a\u8fc7\u653e\u677e\u5f52\u4e00\u5316\u7ea6\u675f\uff0cDFTopK\u83b7\u5f97\u95ed\u5f0f\u89e3\u5e76\u907f\u514d\u6392\u5e8f\uff0c\u76f4\u63a5\u6784\u5efaTop-K\u9009\u62e9\u7b97\u5b50\u7684\u53ef\u5fae\u5206\u8fd1\u4f3c\uff0c\u4e0d\u4f9d\u8d56\u8f6f\u7f6e\u6362\u77e9\u9635\u3002", "result": "\u5728RecFLow\u57fa\u51c6\u548c\u5de5\u4e1a\u7cfb\u7edf\u4e2d\uff0cDFTopK\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u5e76\u5b9e\u73b0\u66f4\u4f18\u6027\u80fd\uff0c\u5728\u7ebfA/B\u6d4b\u8bd5\u83b7\u5f97+1.77%\u6536\u5165\u63d0\u5347\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06\u53ef\u5fae\u5206Top-K\u7b97\u5b50\u5f15\u5165\u63a8\u8350\u7cfb\u7edf\uff0c\u5e76\u9996\u6b21\u5b9e\u73b0\u7406\u8bba\u4e0a\u6700\u4f18\u7684\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6Top-K\u9009\u62e9\u3002"}}
{"id": "2510.11484", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2510.11484", "abs": "https://arxiv.org/abs/2510.11484", "authors": ["Lion Mueller", "Alberto Garcia-Ortiz", "Ardalan Najafi", "Adam Fuks", "Lennart Bamberg"], "title": "Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware", "comment": "Submitted to IEEE Embedded Systems Letters", "summary": "Integer AI inference significantly reduces computational complexity in\nembedded systems. Quantization-aware training (QAT) helps mitigate accuracy\ndegradation associated with post-training quantization but still overlooks the\nimpact of integer rescaling during inference, which is a hardware costly\noperation in integer-only AI inference. This work shows that rescaling cost can\nbe dramatically reduced post-training, by applying a stronger quantization to\nthe rescale multiplicands at no model-quality loss. Furthermore, we introduce\nRescale-Aware Training, a fine tuning method for ultra-low bit-width rescaling\nmultiplicands. Experiments show that even with 8x reduced rescaler widths, the\nfull accuracy is preserved through minimal incremental retraining. This enables\nmore energy-efficient and cost-efficient AI inference for resource-constrained\nembedded systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u964d\u4f4e\u6574\u6570AI\u63a8\u7406\u4e2d\u91cd\u7f29\u653e\u64cd\u4f5c\u6210\u672c\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u540e\u8bad\u7ec3\u65f6\u5bf9\u91cd\u7f29\u653e\u4e58\u6570\u8fdb\u884c\u66f4\u5f3a\u91cf\u5316\uff0c\u5e76\u5f15\u5165\u91cd\u7f29\u653e\u611f\u77e5\u8bad\u7ec3\u6765\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\uff0c\u5b9e\u73b08\u500d\u91cd\u7f29\u653e\u5668\u5bbd\u5ea6\u51cf\u5c11\u3002", "motivation": "\u6574\u6570AI\u63a8\u7406\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4f46\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u4ecd\u5ffd\u7565\u4e86\u6574\u6570\u91cd\u7f29\u653e\u64cd\u4f5c\u7684\u5f71\u54cd\uff0c\u8be5\u64cd\u4f5c\u5728\u6574\u6570AI\u63a8\u7406\u4e2d\u662f\u786c\u4ef6\u6210\u672c\u8f83\u9ad8\u7684\u64cd\u4f5c\u3002", "method": "\u63d0\u51fa\u5728\u540e\u8bad\u7ec3\u65f6\u5bf9\u91cd\u7f29\u653e\u4e58\u6570\u5e94\u7528\u66f4\u5f3a\u91cf\u5316\u4ee5\u964d\u4f4e\u91cd\u7f29\u653e\u6210\u672c\uff0c\u5e76\u5f15\u5165\u91cd\u7f29\u653e\u611f\u77e5\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5bf9\u8d85\u4f4e\u6bd4\u7279\u5bbd\u5ea6\u7684\u91cd\u7f29\u653e\u4e58\u6570\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u91cd\u7f29\u653e\u5668\u5bbd\u5ea6\u51cf\u5c118\u500d\uff0c\u901a\u8fc7\u6700\u5c0f\u589e\u91cf\u91cd\u65b0\u8bad\u7ec3\u4ecd\u80fd\u4fdd\u6301\u5b8c\u6574\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u5b9e\u73b0\u4e86\u66f4\u8282\u80fd\u3001\u6210\u672c\u66f4\u4f4e\u7684AI\u63a8\u7406\u3002"}}
{"id": "2510.11495", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.11495", "abs": "https://arxiv.org/abs/2510.11495", "authors": ["Nikolaos Tsilivis", "Eran Malach", "Karen Ullrich", "Julia Kempe"], "title": "How Reinforcement Learning After Next-Token Prediction Facilitates Learning", "comment": null, "summary": "Recent advances in reasoning domains with neural networks have primarily been\nenabled by a training recipe that optimizes Large Language Models, previously\ntrained to predict the next-token in a sequence, with reinforcement learning\nalgorithms. We introduce a framework to study the success of this paradigm, and\nwe theoretically expose the optimization mechanisms by which reinforcement\nlearning improves over next-token prediction in this setting. We study learning\nfrom mixture distributions of short and long ``chain-of-thought'' sequences\nencoding a single task. In particular, when the task consists of predicting the\nparity of $d$ bits and long sequences are rare, we show how reinforcement\nlearning after next-token prediction enables autoregressive transformers to\ngeneralize, whereas mere next-token prediction requires extreme statistical or\ncomputational resources to do so. We further explain how reinforcement learning\nleverages increased test-time computation, manifested in longer responses, to\nfacilitate this learning process. In a simplified setting, we theoretically\nprove that autoregressive linear models following this training recipe can\nefficiently learn to predict the parity of $d$ bits as long as the proportion\nof long demonstrations in the data mix is not exponentially small in the input\ndimension $d$. Finally, we demonstrate these same phenomena in other settings,\nincluding the post-training of Llama-series models on mixture variations of\ncommon mathematical reasoning benchmarks.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4f18\u5316\u673a\u5236\uff0c\u8bc1\u660e\u4e86\u5728\u9884\u6d4bd\u4f4d\u5947\u5076\u6027\u7684\u4efb\u52a1\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u76f8\u6bd4\u5355\u7eaf\u7684\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u80fd\u66f4\u6709\u6548\u5730\u5b9e\u73b0\u6cdb\u5316\uff0c\u7279\u522b\u662f\u5728\u957f\u5e8f\u5217\u6837\u672c\u7a00\u5c11\u7684\u60c5\u51b5\u4e0b\u3002", "motivation": "\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8303\u5f0f\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u673a\u5236\uff0c\u7406\u89e3\u5176\u76f8\u6bd4\u4f20\u7edf\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9700\u8981\u957f\u94fe\u63a8\u7406\u7684\u590d\u6742\u4efb\u52a1\u65f6\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u7814\u7a76\u6df7\u5408\u5206\u5e03\u4e2d\u7684\u77ed\u957f\u5e8f\u5217\u5b66\u4e60\uff0c\u4f7f\u7528\u81ea\u56de\u5f52\u7ebf\u6027\u6a21\u578b\u548cTransformer\u6a21\u578b\uff0c\u5728\u5947\u5076\u6027\u9884\u6d4b\u4efb\u52a1\u4e2d\u5bf9\u6bd4\u5f3a\u5316\u5b66\u4e60\u548c\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u7684\u6027\u80fd\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u5f53\u957f\u5e8f\u5217\u6837\u672c\u6bd4\u4f8b\u4e0d\u4f4e\u4e8e\u8f93\u5165\u7ef4\u5ea6d\u7684\u6307\u6570\u5c0f\u65f6\uff0c\u5f3a\u5316\u5b66\u4e60\u80fd\u6709\u6548\u5b66\u4e60\u5947\u5076\u6027\u9884\u6d4b\uff1b\u5b9e\u9a8c\u663e\u793a\u5f3a\u5316\u5b66\u4e60\u80fd\u5229\u7528\u66f4\u957f\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6765\u4fc3\u8fdb\u5b66\u4e60\u8fc7\u7a0b\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8303\u5f0f\u901a\u8fc7\u5229\u7528\u589e\u52a0\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u548c\u66f4\u957f\u7684\u54cd\u5e94\u5e8f\u5217\uff0c\u5728\u7a00\u5c11\u7684\u957f\u5e8f\u5217\u6837\u672c\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u6709\u6548\u6cdb\u5316\uff0c\u8fd9\u89e3\u91ca\u4e86\u5176\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u3002"}}
{"id": "2510.11499", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11499", "abs": "https://arxiv.org/abs/2510.11499", "authors": ["Xinsong Feng", "Leshu Tang", "Chenan Wang", "Haipeng Chen"], "title": "Offline Reinforcement Learning with Generative Trajectory Policies", "comment": "Preprint. Under review at ICLR 2026", "summary": "Generative models have emerged as a powerful class of policies for offline\nreinforcement learning (RL) due to their ability to capture complex,\nmulti-modal behaviors. However, existing methods face a stark trade-off: slow,\niterative models like diffusion policies are computationally expensive, while\nfast, single-step models like consistency policies often suffer from degraded\nperformance. In this paper, we demonstrate that it is possible to bridge this\ngap. The key to moving beyond the limitations of individual methods, we argue,\nlies in a unifying perspective that views modern generative models, including\ndiffusion, flow matching, and consistency models, as specific instances of\nlearning a continuous-time generative trajectory governed by an Ordinary\nDifferential Equation (ODE). This principled foundation provides a clearer\ndesign space for generative policies in RL and allows us to propose Generative\nTrajectory Policies (GTPs), a new and more general policy paradigm that learns\nthe entire solution map of the underlying ODE. To make this paradigm practical\nfor offline RL, we further introduce two key theoretically principled\nadaptations. Empirical results demonstrate that GTP achieves state-of-the-art\nperformance on D4RL benchmarks - it significantly outperforms prior generative\npolicies, achieving perfect scores on several notoriously hard AntMaze tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u751f\u6210\u8f68\u8ff9\u7b56\u7565(GTP)\uff0c\u901a\u8fc7\u7edf\u4e00\u89c6\u89d2\u5c06\u6269\u6563\u3001\u6d41\u5339\u914d\u548c\u4e00\u81f4\u6027\u6a21\u578b\u89c6\u4e3a\u5b66\u4e60ODE\u63a7\u5236\u7684\u8fde\u7eed\u65f6\u95f4\u751f\u6210\u8f68\u8ff9\u7684\u7279\u5b9a\u5b9e\u4f8b\uff0c\u514b\u670d\u4e86\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u8ba1\u7b97\u6548\u7387\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u9762\u4e34\u660e\u663e\u6743\u8861\uff1a\u6269\u6563\u7b56\u7565\u7b49\u8fed\u4ee3\u6a21\u578b\u8ba1\u7b97\u6602\u8d35\uff0c\u800c\u4e00\u81f4\u6027\u7b56\u7565\u7b49\u5355\u6b65\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u751f\u6210\u8f68\u8ff9\u7b56\u7565(GTP)\u4f5c\u4e3a\u65b0\u7684\u901a\u7528\u7b56\u7565\u8303\u5f0f\uff0c\u5b66\u4e60\u5e95\u5c42ODE\u7684\u6574\u4e2a\u89e3\u6620\u5c04\u3002\u5f15\u5165\u4e24\u4e2a\u7406\u8bba\u4e0a\u6709\u539f\u5219\u7684\u9002\u5e94\u65b9\u6cd5\uff0c\u4f7f\u8be5\u8303\u5f0f\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b9e\u7528\u5316\u3002", "result": "GTP\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u751f\u6210\u7b56\u7565\uff0c\u5728\u51e0\u4e2a\u8457\u540d\u7684\u56f0\u96beAntMaze\u4efb\u52a1\u4e0a\u83b7\u5f97\u5b8c\u7f8e\u5206\u6570\u3002", "conclusion": "\u901a\u8fc7\u5c06\u73b0\u4ee3\u751f\u6210\u6a21\u578b\u7edf\u4e00\u4e3a\u5b66\u4e60ODE\u63a7\u5236\u7684\u8fde\u7eed\u65f6\u95f4\u751f\u6210\u8f68\u8ff9\u7684\u5b9e\u4f8b\uff0c\u6210\u529f\u5f25\u5408\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u751f\u6210\u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.11501", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.11501", "abs": "https://arxiv.org/abs/2510.11501", "authors": ["Emran Yasser Moustafa", "Ivana Dusparic"], "title": "Context-Aware Model-Based Reinforcement Learning for Autonomous Racing", "comment": "Accepted to IEEE ICAR 2025", "summary": "Autonomous vehicles have shown promising potential to be a groundbreaking\ntechnology for improving the safety of road users. For these vehicles, as well\nas many other safety-critical robotic technologies, to be deployed in\nreal-world applications, we require algorithms that can generalize well to\nunseen scenarios and data. Model-based reinforcement learning algorithms (MBRL)\nhave demonstrated state-of-the-art performance and data efficiency across a\ndiverse set of domains. However, these algorithms have also shown\nsusceptibility to changes in the environment and its transition dynamics.\n  In this work, we explore the performance and generalization capabilities of\nMBRL algorithms for autonomous driving, specifically in the simulated\nautonomous racing environment, Roboracer (formerly F1Tenth). We frame the\nhead-to-head racing task as a learning problem using contextual Markov decision\nprocesses and parameterize the driving behavior of the adversaries using the\ncontext of the episode, thereby also parameterizing the transition and reward\ndynamics. We benchmark the behavior of MBRL algorithms in this environment and\npropose a novel context-aware extension of the existing literature, cMask. We\ndemonstrate that context-aware MBRL algorithms generalize better to\nout-of-distribution adversary behaviors relative to context-free approaches. We\nalso demonstrate that cMask displays strong generalization capabilities, as\nwell as further performance improvement relative to other context-aware MBRL\napproaches when racing against adversaries with in-distribution behaviors.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\uff08MBRL\uff09\u7b97\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7684cMask\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4e0a\u4e0b\u6587\u65e0\u5173\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u6cdb\u5316\u5230\u5206\u5e03\u5916\u5bf9\u624b\u884c\u4e3a\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u9700\u8981\u80fd\u591f\u6cdb\u5316\u5230\u672a\u89c1\u573a\u666f\u7684\u7b97\u6cd5\u3002\u867d\u7136MBRL\u7b97\u6cd5\u5728\u591a\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u73af\u5883\u53d8\u5316\u654f\u611f\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22MBRL\u5728\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u4e2d\u7684\u6cdb\u5316\u548c\u6027\u80fd\u8868\u73b0\u3002", "method": "\u5c06\u5934\u5bf9\u5934\u8d5b\u8f66\u4efb\u52a1\u5efa\u6a21\u4e3a\u4e0a\u4e0b\u6587\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u60c5\u8282\u4e0a\u4e0b\u6587\u53c2\u6570\u5316\u5bf9\u624b\u7684\u9a7e\u9a76\u884c\u4e3a\u3001\u8f6c\u79fb\u548c\u5956\u52b1\u52a8\u6001\u3002\u63d0\u51fa\u4e86\u65b0\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u6269\u5c55\u65b9\u6cd5cMask\uff0c\u5e76\u5728Roboracer\u6a21\u62df\u73af\u5883\u4e2d\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4e0a\u4e0b\u6587\u611f\u77e5\u7684MBRL\u7b97\u6cd5\u76f8\u6bd4\u4e0a\u4e0b\u6587\u65e0\u5173\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u6cdb\u5316\u5230\u5206\u5e03\u5916\u5bf9\u624b\u884c\u4e3a\u3002cMask\u5728\u5206\u5e03\u5185\u5bf9\u624b\u884c\u4e3a\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u8fdb\u4e00\u6b65\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u7684MBRL\u65b9\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u8d5b\u8f66\u4efb\u52a1\u4e2d\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0ccMask\u65b9\u6cd5\u5728\u5e94\u5bf9\u4e0d\u540c\u5bf9\u624b\u884c\u4e3a\u65f6\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.11502", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11502", "abs": "https://arxiv.org/abs/2510.11502", "authors": ["Alexis Ross", "Jacob Andreas"], "title": "Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key Errors", "comment": null, "summary": "Research on reasoning in language models (LMs) predominantly focuses on\nimproving the correctness of their outputs. But some important applications\nrequire modeling reasoning patterns that are incorrect. For example, automated\nsystems that can reason about and simulate student errors are useful for\nproviding real-time feedback in the classroom or offline practice for\neducators-in-training. This paper presents a new method, MISTAKE, that (1)\nconstructs high-quality synthetic examples of reasoning errors by leveraging\ncycle consistency between incorrect answers and latent misconceptions; and (2)\nuses the generated data to learn models for student simulation, misconception\nclassification, and answer generation. We evaluate MISTAKE on three educational\ntasks and find that it results in (1) higher accuracy when simulating incorrect\nstudent answers based on specific misconceptions, (2) increased performance\ninferring latent misconceptions from observed incorrect answers, and (3) higher\nalignment with expert-written distractor answers when generating incorrect\nanswers (e.g., for multiple-choice tests).", "AI": {"tldr": "MISTAKE\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u9519\u8bef\u7b54\u6848\u4e0e\u6f5c\u5728\u8bef\u89e3\u4e4b\u95f4\u7684\u5faa\u73af\u4e00\u81f4\u6027\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u9519\u8bef\u63a8\u7406\u793a\u4f8b\uff0c\u7528\u4e8e\u5b66\u751f\u6a21\u62df\u3001\u8bef\u89e3\u5206\u7c7b\u548c\u7b54\u6848\u751f\u6210\uff0c\u5728\u4e09\u4e2a\u6559\u80b2\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63d0\u9ad8\u8f93\u51fa\u6b63\u786e\u6027\uff0c\u4f46\u67d0\u4e9b\u91cd\u8981\u5e94\u7528\u9700\u8981\u5efa\u6a21\u9519\u8bef\u7684\u63a8\u7406\u6a21\u5f0f\uff0c\u5982\u6a21\u62df\u5b66\u751f\u9519\u8bef\u4ee5\u63d0\u4f9b\u5b9e\u65f6\u8bfe\u5802\u53cd\u9988\u6216\u6559\u5e08\u57f9\u8bad\u7ec3\u4e60\u3002", "method": "MISTAKE\u65b9\u6cd5\uff1a(1) \u5229\u7528\u9519\u8bef\u7b54\u6848\u4e0e\u6f5c\u5728\u8bef\u89e3\u4e4b\u95f4\u7684\u5faa\u73af\u4e00\u81f4\u6027\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u9519\u8bef\u63a8\u7406\u5408\u6210\u793a\u4f8b\uff1b(2) \u4f7f\u7528\u751f\u6210\u7684\u6570\u636e\u5b66\u4e60\u5b66\u751f\u6a21\u62df\u3001\u8bef\u89e3\u5206\u7c7b\u548c\u7b54\u6848\u751f\u6210\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u6559\u80b2\u4efb\u52a1\u4e2d\u8bc4\u4f30\u663e\u793a\uff1a(1) \u57fa\u4e8e\u7279\u5b9a\u8bef\u89e3\u6a21\u62df\u9519\u8bef\u5b66\u751f\u7b54\u6848\u7684\u51c6\u786e\u7387\u66f4\u9ad8\uff1b(2) \u4ece\u89c2\u5bdf\u5230\u7684\u9519\u8bef\u7b54\u6848\u63a8\u65ad\u6f5c\u5728\u8bef\u89e3\u7684\u6027\u80fd\u63d0\u5347\uff1b(3) \u751f\u6210\u9519\u8bef\u7b54\u6848\u65f6\u4e0e\u4e13\u5bb6\u7f16\u5199\u7684\u5e72\u6270\u7b54\u6848\u5bf9\u9f50\u5ea6\u66f4\u9ad8\u3002", "conclusion": "MISTAKE\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5efa\u6a21\u9519\u8bef\u63a8\u7406\u6a21\u5f0f\uff0c\u5728\u6559\u80b2\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u5b66\u751f\u9519\u8bef\u6a21\u62df\u548c\u8bef\u89e3\u5206\u7c7b\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.11561", "categories": ["cs.LG", "cs.SC"], "pdf": "https://arxiv.org/pdf/2510.11561", "abs": "https://arxiv.org/abs/2510.11561", "authors": ["Caglar Demir", "Alkid Baci", "N'Dah Jean Kouagou", "Leonie Nora Sieger", "Stefan Heindorf", "Simon Bin", "Lukas Bl\u00fcbaum", "Alexander Bigerl", "Axel-Cyrille Ngonga Ngomo"], "title": "Ontolearn-A Framework for Large-scale OWL Class Expression Learning in Python", "comment": null, "summary": "In this paper, we present Ontolearn-a framework for learning OWL class\nexpressions over large knowledge graphs. Ontolearn contains efficient\nimplementations of recent stateof-the-art symbolic and neuro-symbolic class\nexpression learners including EvoLearner and DRILL. A learned OWL class\nexpression can be used to classify instances in the knowledge graph.\nFurthermore, Ontolearn integrates a verbalization module based on an LLM to\ntranslate complex OWL class expressions into natural language sentences. By\nmapping OWL class expressions into respective SPARQL queries, Ontolearn can be\neasily used to operate over a remote triplestore. The source code of Ontolearn\nis available at https://github.com/dice-group/Ontolearn.", "AI": {"tldr": "Ontolearn\u662f\u4e00\u4e2a\u7528\u4e8e\u5728\u5927\u578b\u77e5\u8bc6\u56fe\u8c31\u4e0a\u5b66\u4e60OWL\u7c7b\u8868\u8fbe\u5f0f\u7684\u6846\u67b6\uff0c\u5305\u542b\u6700\u5148\u8fdb\u7684\u7b26\u53f7\u548c\u795e\u7ecf\u7b26\u53f7\u7c7b\u8868\u8fbe\u5f0f\u5b66\u4e60\u5668\uff0c\u5e76\u96c6\u6210\u4e86\u57fa\u4e8eLLM\u7684\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u6a21\u5757\u3002", "motivation": "\u4e3a\u4e86\u5728\u5927\u578b\u77e5\u8bc6\u56fe\u8c31\u4e0a\u9ad8\u6548\u5b66\u4e60OWL\u7c7b\u8868\u8fbe\u5f0f\uff0c\u5e76\u4f7f\u5176\u66f4\u6613\u4e8e\u7406\u89e3\u548c\u4f7f\u7528\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u96c6\u6210\u591a\u79cd\u5b66\u4e60\u65b9\u6cd5\u548c\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u529f\u80fd\u7684\u6846\u67b6\u3002", "method": "\u5b9e\u73b0\u4e86\u5305\u62ecEvoLearner\u548cDRILL\u5728\u5185\u7684\u6700\u65b0\u7b26\u53f7\u548c\u795e\u7ecf\u7b26\u53f7\u7c7b\u8868\u8fbe\u5f0f\u5b66\u4e60\u5668\uff0c\u96c6\u6210\u4e86\u57fa\u4e8eLLM\u7684\u8a00\u8bed\u5316\u6a21\u5757\uff0c\u53ef\u5c06OWL\u7c7b\u8868\u8fbe\u5f0f\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\uff0c\u5e76\u901a\u8fc7SPARQL\u67e5\u8be2\u652f\u6301\u8fdc\u7a0b\u4e09\u5143\u7ec4\u5b58\u50a8\u64cd\u4f5c\u3002", "result": "\u5f00\u53d1\u4e86Ontolearn\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u5b66\u4e60OWL\u7c7b\u8868\u8fbe\u5f0f\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\uff0c\u5e76\u53ef\u901a\u8fc7SPARQL\u67e5\u8be2\u5728\u8fdc\u7a0b\u4e09\u5143\u7ec4\u5b58\u50a8\u4e0a\u64cd\u4f5c\u3002", "conclusion": "Ontolearn\u63d0\u4f9b\u4e86\u4e00\u4e2a\u529f\u80fd\u5b8c\u6574\u7684\u6846\u67b6\uff0c\u652f\u6301\u5728\u5927\u578b\u77e5\u8bc6\u56fe\u8c31\u4e0a\u5b66\u4e60\u3001\u7406\u89e3\u548c\u5e94\u7528OWL\u7c7b\u8868\u8fbe\u5f0f\uff0c\u6e90\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.11590", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.11590", "abs": "https://arxiv.org/abs/2510.11590", "authors": ["Zihao Zhao", "Christopher Yeh", "Lingkai Kong", "Kai Wang"], "title": "Diffusion-DFL: Decision-focused Diffusion Models for Stochastic Optimization", "comment": null, "summary": "Decision-focused learning (DFL) integrates predictive modeling and\noptimization by training predictors to optimize the downstream decision target\nrather than merely minimizing prediction error. To date, existing DFL methods\ntypically rely on deterministic point predictions, which are often insufficient\nto capture the intrinsic stochasticity of real-world environments. To address\nthis challenge, we propose the first diffusion-based DFL approach, which trains\na diffusion model to represent the distribution of uncertain parameters and\noptimizes the decision by solving a stochastic optimization with samples drawn\nfrom the diffusion model. Our contributions are twofold. First, we formulate\ndiffusion DFL using the reparameterization trick, enabling end-to-end training\nthrough diffusion. While effective, it is memory and compute-intensive due to\nthe need to differentiate through the diffusion sampling process. Second, we\npropose a lightweight score function estimator that uses only several forward\ndiffusion passes and avoids backpropagation through the sampling. This follows\nfrom our results that backpropagating through stochastic optimization can be\napproximated by a weighted score function formulation. We empirically show that\nour diffusion DFL approach consistently outperforms strong baselines in\ndecision quality. The source code for all experiments is available at the\nproject repository: https://github.com/GT-KOALA/Diffusion_DFL.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u51b3\u7b56\u805a\u7126\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u6765\u8868\u793a\u4e0d\u786e\u5b9a\u53c2\u6570\u7684\u5206\u5e03\uff0c\u5e76\u4f7f\u7528\u4ece\u6269\u6563\u6a21\u578b\u4e2d\u62bd\u53d6\u7684\u6837\u672c\u6765\u4f18\u5316\u51b3\u7b56\uff0c\u4ece\u800c\u5728\u51b3\u7b56\u8d28\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u51b3\u7b56\u805a\u7126\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u786e\u5b9a\u6027\u70b9\u9884\u6d4b\uff0c\u65e0\u6cd5\u5145\u5206\u6355\u6349\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5185\u5728\u968f\u673a\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u91cd\u53c2\u6570\u5316\u6280\u5de7\u7684\u6269\u6563DFL\uff0c\u652f\u6301\u7aef\u5230\u7aef\u8bad\u7ec3\uff1b2\uff09\u8f7b\u91cf\u7ea7\u8bc4\u5206\u51fd\u6570\u4f30\u8ba1\u5668\uff0c\u4ec5\u9700\u51e0\u6b21\u524d\u5411\u6269\u6563\u4f20\u9012\uff0c\u907f\u514d\u901a\u8fc7\u91c7\u6837\u8fc7\u7a0b\u7684\u53cd\u5411\u4f20\u64ad\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6269\u6563DFL\u65b9\u6cd5\u5728\u51b3\u7b56\u8d28\u91cf\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6269\u6563DFL\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u9ad8\u51b3\u7b56\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8bc4\u5206\u51fd\u6570\u4f30\u8ba1\u5668\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2510.11616", "categories": ["cs.LG", "cs.AI", "q-fin.CP", "I.2.0"], "pdf": "https://arxiv.org/pdf/2510.11616", "abs": "https://arxiv.org/abs/2510.11616", "authors": ["Elliot L. Epstein", "Rose Wang", "Jaewon Choi", "Markus Pelger"], "title": "Attention Factors for Statistical Arbitrage", "comment": "Accepted to the 6th ACM International Conference on AI in Finance", "summary": "Statistical arbitrage exploits temporal price differences between similar\nassets. We develop a framework to jointly identify similar assets through\nfactors, identify mispricing and form a trading policy that maximizes\nrisk-adjusted performance after trading costs. Our Attention Factors are\nconditional latent factors that are the most useful for arbitrage trading. They\nare learned from firm characteristic embeddings that allow for complex\ninteractions. We identify time-series signals from the residual portfolios of\nour factors with a general sequence model. Estimating factors and the arbitrage\ntrading strategy jointly is crucial to maximize profitability after trading\ncosts. In a comprehensive empirical study we show that our Attention Factor\nmodel achieves an out-of-sample Sharpe ratio above 4 on the largest U.S.\nequities over a 24-year period. Our one-step solution yields an unprecedented\nSharpe ratio of 2.3 net of transaction costs. We show that weak factors are\nimportant for arbitrage trading.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u8054\u5408\u5b66\u4e60\u56e0\u5b50\u548c\u4ea4\u6613\u7b56\u7565\u7684\u7edf\u8ba1\u5957\u5229\u6846\u67b6\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u56e0\u5b50\u548c\u5e8f\u5217\u6a21\u578b\u8bc6\u522b\u8d44\u4ea7\u76f8\u4f3c\u6027\u548c\u9519\u8bef\u5b9a\u4ef7\uff0c\u5728\u8003\u8651\u4ea4\u6613\u6210\u672c\u540e\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u590f\u666e\u6bd4\u7387\u3002", "motivation": "\u4f20\u7edf\u7edf\u8ba1\u5957\u5229\u65b9\u6cd5\u901a\u5e38\u5206\u5f00\u5904\u7406\u56e0\u5b50\u8bc6\u522b\u548c\u4ea4\u6613\u7b56\u7565\uff0c\u65e0\u6cd5\u5728\u8003\u8651\u4ea4\u6613\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u6700\u5927\u5316\u98ce\u9669\u8c03\u6574\u540e\u6536\u76ca\u3002", "method": "\u63d0\u51fa\u6ce8\u610f\u529b\u56e0\u5b50\u4f5c\u4e3a\u6761\u4ef6\u6f5c\u5728\u56e0\u5b50\uff0c\u4ece\u516c\u53f8\u7279\u5f81\u5d4c\u5165\u4e2d\u5b66\u4e60\u590d\u6742\u4ea4\u4e92\uff0c\u4f7f\u7528\u5e8f\u5217\u6a21\u578b\u4ece\u56e0\u5b50\u6b8b\u5dee\u7ec4\u5408\u4e2d\u8bc6\u522b\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\uff0c\u5e76\u8054\u5408\u4f30\u8ba1\u56e0\u5b50\u548c\u4ea4\u6613\u7b56\u7565\u3002", "result": "\u572824\u5e74\u7f8e\u56fd\u6700\u5927\u80a1\u7968\u6570\u636e\u96c6\u4e0a\uff0c\u6ce8\u610f\u529b\u56e0\u5b50\u6a21\u578b\u5b9e\u73b0\u4e86\u8d85\u8fc74\u7684\u6837\u672c\u5916\u590f\u666e\u6bd4\u7387\uff0c\u8003\u8651\u4ea4\u6613\u6210\u672c\u540e\u4ecd\u8fbe\u52302.3\u7684\u590f\u666e\u6bd4\u7387\u3002", "conclusion": "\u8054\u5408\u5b66\u4e60\u56e0\u5b50\u548c\u4ea4\u6613\u7b56\u7565\u5bf9\u6700\u5927\u5316\u4ea4\u6613\u6210\u672c\u540e\u7684\u76c8\u5229\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u5f31\u56e0\u5b50\u5728\u5957\u5229\u4ea4\u6613\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2510.11653", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11653", "abs": "https://arxiv.org/abs/2510.11653", "authors": ["Prasanna Mayilvahanan", "Ricardo Dominguez-Olmedo", "Thadd\u00e4us Wiedemer", "Wieland Brendel"], "title": "MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model", "comment": null, "summary": "With the advent of DeepSeek-R1, a new wave of reinforcement learning (RL)\nmethods has emerged that seem to unlock stronger mathematical reasoning.\nHowever, a closer look at the open-source ecosystem reveals a critical\nlimitation: with sufficiently many draws (e.g., $\\texttt{pass@1024}$), many\nexisting base models already solve nearly all questions on widely used math\nbenchmarks such as MATH-500 and AIME 2024. This suggests that the RL\nfine-tuning methods prevalent in the LLM reasoning literature largely sharpen\nexisting solution modes rather than discovering entirely new ones. Such\nsharpening stands in contrast to the broader promise of RL: to foster\nexploration and to acquire new skills. To move beyond this plateau, we\nintroduce MATH-Beyond (MATH-B), a benchmark deliberately constructed to defeat\ncommon open-source models of up to 8B parameters even under large sampling\nbudgets. Improving performance on our benchmark via RL requires methods that\nlearn to reason in ways that go beyond base model capabilities in repeated\nsampling. Since the problems are drawn from subsets of DAPO-Math-17K and\nDeepScaleR datasets, they remain topically equivalent to standard high-school\nmath. Validating our premise, RL fine-tuned models such as\nNemotron-Research-Reasoning-Qwen-1.5B and DeepScaleR-1.5B-Preview perform\npoorly on MATH-B at $\\texttt{pass@1024}$, showing how existing approaches fall\nshort on tackling harder instances. We hope MATH-B will catalyze\nexploration-driven RL approaches that elicit deeper reasoning capabilities. We\nrelease MATH-B at https://huggingface.co/datasets/brendel-group/MATH-Beyond.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u4e0a\u4e3b\u8981\u662f\u5728\u4f18\u5316\u73b0\u6709\u89e3\u51b3\u6a21\u5f0f\u800c\u975e\u53d1\u73b0\u65b0\u65b9\u6cd5\uff0c\u4e3a\u6b64\u63d0\u51fa\u4e86MATH-B\u57fa\u51c6\u6d4b\u8bd5\u6765\u6311\u6218\u73b0\u6709\u6a21\u578b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u53ea\u662f\u4f18\u5316\u5df2\u6709\u89e3\u51b3\u6a21\u5f0f\uff0c\u672a\u80fd\u771f\u6b63\u5b9e\u73b0\u63a2\u7d22\u548c\u83b7\u53d6\u65b0\u6280\u80fd\u7684\u6838\u5fc3\u627f\u8bfa\uff0c\u9700\u8981\u6784\u5efa\u66f4\u5177\u6311\u6218\u6027\u7684\u57fa\u51c6\u6765\u63a8\u52a8\u7a81\u7834\u3002", "method": "\u6784\u5efaMATH-B\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u95e8\u8bbe\u8ba1\u6765\u51fb\u8d25\u5e38\u89c1\u5f00\u6e90\u6a21\u578b\uff08\u6700\u9ad88B\u53c2\u6570\uff09\uff0c\u5373\u4f7f\u5728\u5927\u89c4\u6a21\u91c7\u6837\u4e0b\u4e5f\u96be\u4ee5\u89e3\u51b3\uff0c\u95ee\u9898\u6765\u6e90\u4e8eDAPO-Math-17K\u548cDeepScaleR\u6570\u636e\u96c6\u3002", "result": "\u9a8c\u8bc1\u4e86\u73b0\u6709RL\u5fae\u8c03\u6a21\u578b\uff08\u5982Nemotron-Research-Reasoning-Qwen-1.5B\u548cDeepScaleR-1.5B-Preview\uff09\u5728MATH-B\u57fa\u51c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5373\u4f7f\u5728pass@1024\u91c7\u6837\u4e0b\u4e5f\u96be\u4ee5\u89e3\u51b3\u3002", "conclusion": "MATH-B\u57fa\u51c6\u5c06\u50ac\u5316\u63a2\u7d22\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u53d1\u5c55\uff0c\u6fc0\u53d1\u66f4\u6df1\u5c42\u6b21\u7684\u63a8\u7406\u80fd\u529b\uff0c\u63a8\u52a8\u8d85\u8d8a\u5f53\u524d\u5e73\u53f0\u671f\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2510.11657", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.11657", "abs": "https://arxiv.org/abs/2510.11657", "authors": ["Panos Tsimpos", "Youssef Marzouk"], "title": "An Eulerian Perspective on Straight-Line Sampling", "comment": null, "summary": "We study dynamic measure transport for generative modeling: specifically,\nflows induced by stochastic processes that bridge a specified source and target\ndistribution. The conditional expectation of the process' velocity defines an\nODE whose flow map achieves the desired transport. We ask \\emph{which processes\nproduce straight-line flows} -- i.e., flows whose pointwise acceleration\nvanishes and thus are exactly integrable with a first-order method? We provide\na concise PDE characterization of straightness as a balance between conditional\nacceleration and the divergence of a weighted covariance (Reynolds) tensor.\nUsing this lens, we fully characterize affine-in-time interpolants and show\nthat straightness occurs exactly under deterministic endpoint couplings. We\nalso derive necessary conditions that constrain flow geometry for general\nprocesses, offering broad guidance for designing transports that are easier to\nintegrate.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u52a8\u6001\u6d4b\u5ea6\u4f20\u8f93\u5728\u751f\u6210\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u5173\u6ce8\u7531\u8fde\u63a5\u6307\u5b9a\u6e90\u5206\u5e03\u548c\u76ee\u6807\u5206\u5e03\u7684\u968f\u673a\u8fc7\u7a0b\u8bf1\u5bfc\u7684\u6d41\u3002\u4f5c\u8005\u5206\u6790\u4e86\u54ea\u4e9b\u8fc7\u7a0b\u80fd\u4ea7\u751f\u76f4\u7ebf\u6d41\uff08\u5373\u70b9\u52a0\u901f\u5ea6\u4e3a\u96f6\u7684\u6d41\uff09\uff0c\u5e76\u7ed9\u51fa\u4e86\u76f4\u7ebf\u6027\u7684PDE\u7279\u5f81\u63cf\u8ff0\u3002", "motivation": "\u7814\u7a76\u76ee\u6807\u662f\u8bc6\u522b\u80fd\u591f\u4ea7\u751f\u76f4\u7ebf\u6d41\u7684\u968f\u673a\u8fc7\u7a0b\uff0c\u8fd9\u4e9b\u6d41\u66f4\u5bb9\u6613\u7528\u4e00\u9636\u65b9\u6cd5\u7cbe\u786e\u79ef\u5206\uff0c\u4ece\u800c\u7b80\u5316\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u5206\u6790\u968f\u673a\u8fc7\u7a0b\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u63a8\u5bfc\u51fa\u76f4\u7ebf\u6d41\u7684PDE\u7279\u5f81\u63cf\u8ff0\uff0c\u5c06\u5176\u8868\u5f81\u4e3a\u6761\u4ef6\u52a0\u901f\u5ea6\u4e0e\u52a0\u6743\u534f\u65b9\u5dee\u5f20\u91cf\u6563\u5ea6\u4e4b\u95f4\u7684\u5e73\u8861\u5173\u7cfb\u3002", "result": "\u5b8c\u5168\u523b\u753b\u4e86\u4eff\u5c04\u65f6\u95f4\u63d2\u503c\uff0c\u5e76\u8bc1\u660e\u76f4\u7ebf\u6027\u4ec5\u5728\u786e\u5b9a\u6027\u7aef\u70b9\u8026\u5408\u4e0b\u53d1\u751f\u3002\u8fd8\u63a8\u5bfc\u4e86\u7ea6\u675f\u4e00\u822c\u8fc7\u7a0b\u6d41\u51e0\u4f55\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "conclusion": "\u7814\u7a76\u4e3a\u8bbe\u8ba1\u66f4\u6613\u4e8e\u79ef\u5206\u7684\u4f20\u8f93\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u5e7f\u6cdb\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2510.11677", "categories": ["cs.LG", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2510.11677", "abs": "https://arxiv.org/abs/2510.11677", "authors": ["Songrun He", "Linying Lv", "Asaf Manela", "Jimmy Wu"], "title": "Chronologically Consistent Generative AI", "comment": null, "summary": "We introduce a family of chronologically consistent, instruction-following\nlarge language models to eliminate lookahead bias. Each model is trained only\non data available before a clearly defined knowledge-cutoff date, ensuring\nstrict temporal separation from any post-cutoff data. The resulting framework\noffers (i) a simple, conversational chat interface, (ii) fully open, fixed\nmodel weights that guarantee replicability, and (iii) a conservative lower\nbound on forecast accuracy, isolating the share of predictability that survives\nonce training leakage is removed. Together, these features provide researchers\nwith an easy-to-use generative AI tool useful for a wide range of prediction\ntasks that is free of lookahead bias.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u65f6\u95f4\u4e00\u81f4\u6027\u7684\u6307\u4ee4\u8ddf\u968f\u5927\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u660e\u786e\u7684\u77e5\u8bc6\u622a\u6b62\u65e5\u671f\u6d88\u9664\u524d\u77bb\u6027\u504f\u5dee\uff0c\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u9884\u6d4b\u5de5\u5177\u3002", "motivation": "\u6d88\u9664\u5927\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u524d\u77bb\u6027\u504f\u5dee\uff0c\u786e\u4fdd\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u4e25\u683c\u9650\u5b9a\u5728\u7279\u5b9a\u65f6\u95f4\u70b9\u4e4b\u524d\uff0c\u907f\u514d\u8bad\u7ec3\u6570\u636e\u6cc4\u9732\u5f71\u54cd\u9884\u6d4b\u51c6\u786e\u6027\u8bc4\u4f30\u3002", "method": "\u8bad\u7ec3\u4ec5\u4f7f\u7528\u622a\u6b62\u65e5\u671f\u524d\u53ef\u7528\u6570\u636e\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5efa\u7acb\u4e25\u683c\u7684\u65f6\u95f4\u5206\u79bb\uff0c\u63d0\u4f9b\u5bf9\u8bdd\u5f0f\u804a\u5929\u754c\u9762\u548c\u5b8c\u5168\u5f00\u653e\u7684\u56fa\u5b9a\u6a21\u578b\u6743\u91cd\u3002", "result": "\u5f00\u53d1\u51fa\u65e0\u524d\u77bb\u6027\u504f\u5dee\u7684\u751f\u6210\u5f0fAI\u5de5\u5177\uff0c\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u4fdd\u5b88\u7684\u9884\u6d4b\u51c6\u786e\u6027\u4e0b\u754c\uff0c\u9694\u79bb\u4e86\u8bad\u7ec3\u6570\u636e\u6cc4\u9732\u540e\u7684\u53ef\u9884\u6d4b\u6027\u90e8\u5206\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5e7f\u6cdb\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u6613\u4e8e\u4f7f\u7528\u4e14\u65e0\u524d\u77bb\u6027\u504f\u5dee\u7684\u751f\u6210\u5f0fAI\u5de5\u5177\uff0c\u786e\u4fdd\u4e86\u9884\u6d4b\u7ed3\u679c\u7684\u53ef\u590d\u73b0\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u3002"}}
{"id": "2510.11683", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11683", "abs": "https://arxiv.org/abs/2510.11683", "authors": ["Nianyi Lin", "Jiajie Zhang", "Lei Hou", "Juanzi Li"], "title": "Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models", "comment": null, "summary": "A key challenge in applying reinforcement learning (RL) to diffusion large\nlanguage models (dLLMs) lies in the intractability of their likelihood\nfunctions, which are essential for the RL objective, necessitating\ncorresponding approximation in each training step. While existing methods\napproximate the log-likelihoods by their evidence lower bounds (ELBOs) via\ncustomized Monte Carlo (MC) sampling, the forward computational graphs of all\nMC samples need to be retained for the gradient computation of non-linear terms\nin the RL objective, resulting in significant memory overhead. This constraint\nrestricts feasible sample sizes, leading to imprecise likelihood approximations\nand ultimately distorting the RL objective. To overcome this limitation, we\npropose \\emph{Boundary-Guided Policy Optimization} (BGPO), a memory-efficient\nRL algorithm that maximizes a specially constructed lower bound of the\nELBO-based objective. This lower bound is carefully designed to satisfy two key\nproperties: (1) Linearity: it is formulated in a linear sum where each term\ndepends only on a single MC sample, thereby enabling gradient accumulation\nacross samples and ensuring constant memory usage; (2) Equivalence: Both the\nvalue and gradient of this lower bound are equal to those of the ELBO-based\nobjective in on-policy training, making it also an effective approximation for\nthe original RL objective. These properties allow BGPO to adopt a large MC\nsample size, resulting in more accurate likelihood approximations and improved\nRL objective estimation, which in turn leads to enhanced performance.\nExperiments show that BGPO significantly outperforms previous RL algorithms for\ndLLMs in math problem solving, code generation, and planning tasks.", "AI": {"tldr": "\u63d0\u51faBGPO\u7b97\u6cd5\u89e3\u51b3\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u9020\u7279\u6b8a\u7684\u7ebf\u6027\u4e0b\u754c\u5b9e\u73b0\u5185\u5b58\u9ad8\u6548\u8bad\u7ec3\uff0c\u5728\u6570\u5b66\u89e3\u9898\u3001\u4ee3\u7801\u751f\u6210\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\u9700\u8981\u4fdd\u7559\u6240\u6709\u8499\u7279\u5361\u6d1b\u6837\u672c\u7684\u524d\u5411\u8ba1\u7b97\u56fe\uff0c\u5bfc\u81f4\u5185\u5b58\u5f00\u9500\u5927\uff0c\u9650\u5236\u4e86\u6837\u672c\u6570\u91cf\uff0c\u8fdb\u800c\u5f71\u54cd\u4f3c\u7136\u4f30\u8ba1\u7cbe\u5ea6\u548cRL\u76ee\u6807", "method": "\u63d0\u51fa\u8fb9\u754c\u5f15\u5bfc\u7b56\u7565\u4f18\u5316(BGPO)\uff0c\u6784\u9020\u6ee1\u8db3\u7ebf\u6027\u548c\u7b49\u4ef7\u6027\u4e24\u4e2a\u5173\u952e\u6027\u8d28\u7684\u7279\u6b8a\u4e0b\u754c\uff0c\u5b9e\u73b0\u8de8\u6837\u672c\u7684\u68af\u5ea6\u7d2f\u79ef\u548c\u6052\u5b9a\u5185\u5b58\u4f7f\u7528", "result": "BGPO\u5728\u6570\u5b66\u95ee\u9898\u6c42\u89e3\u3001\u4ee3\u7801\u751f\u6210\u548c\u89c4\u5212\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684RL\u7b97\u6cd5", "conclusion": "BGPO\u901a\u8fc7\u5185\u5b58\u9ad8\u6548\u7684RL\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u4f3c\u7136\u4f30\u8ba1\u548c\u66f4\u597d\u7684\u6027\u80fd"}}
{"id": "2510.11686", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11686", "abs": "https://arxiv.org/abs/2510.11686", "authors": ["Jens Tuyls", "Dylan J. Foster", "Akshay Krishnamurthy", "Jordan T. Ash"], "title": "Representation-Based Exploration for Language Models: From Test-Time to Post-Training", "comment": "Website and code: https://rep-exp.github.io", "summary": "Reinforcement learning (RL) promises to expand the capabilities of language\nmodels, but it is unclear if current RL techniques promote the discovery of\nnovel behaviors, or simply sharpen those already present in the base model. In\nthis paper, we investigate the value of deliberate exploration -- explicitly\nincentivizing the model to discover novel and diverse behaviors -- and aim to\nunderstand how the knowledge in pre-trained models can guide this search. Our\nmain finding is that exploration with a simple, principled,\nrepresentation-based bonus derived from the pre-trained language model's hidden\nstates significantly improves diversity and pass@k rates -- both for\npost-training, and in a novel inference-time scaling setting we introduce. For\ninference-time, exploration with representation-based diversity improves\nefficiency, consistently improving pass@k rates across a variety of models and\nreasoning tasks. For example, for Qwen-2.5-14b-Instruct we obtain over 50%\nimprovement in verifier efficiency on almost all tasks. For post-training, we\nshow that integrating this exploration strategy into an RL pipeline improves\nreasoning performance over that of the initial model and over standard RL\npost-training. For example, on AIME 2024, our post-trained\nQwen-2.5-7b-Instruct's pass@80 matches the pass@256 of GRPO on the same model,\ndemonstrating a 3x improvement in test-time sample efficiency. Overall, our\nfindings suggest that deliberate exploration -- with the right notion of\ndiversity -- is a practical path toward discovery of new behaviors beyond\nsharpening.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u5f15\u5165\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u9690\u85cf\u72b6\u6001\u7684\u8868\u793a\u591a\u6837\u6027\u63a2\u7d22\u5956\u52b1\uff0c\u53d1\u73b0\u5728\u63a8\u7406\u65f6\u548c\u8bad\u7ec3\u540e\u90fd\u80fd\u663e\u8457\u63d0\u9ad8\u591a\u6837\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u5f3a\u5316\u5b66\u4e60\u662f\u5426\u80fd\u4fc3\u8fdb\u8bed\u8a00\u6a21\u578b\u53d1\u73b0\u65b0\u884c\u4e3a\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u4f18\u5316\u5df2\u6709\u884c\u4e3a\uff0c\u63a2\u7d22\u9884\u8bad\u7ec3\u6a21\u578b\u77e5\u8bc6\u5982\u4f55\u6307\u5bfc\u8fd9\u79cd\u641c\u7d22\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u9690\u85cf\u72b6\u6001\u7684\u7b80\u5355\u3001\u539f\u5219\u6027\u7684\u8868\u793a\u591a\u6837\u6027\u5956\u52b1\uff0c\u5728\u63a8\u7406\u65f6\u548c\u8bad\u7ec3\u540e\u9636\u6bb5\u8fdb\u884c\u63a2\u7d22\u3002", "result": "\u8868\u793a\u591a\u6837\u6027\u63a2\u7d22\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u6837\u6027\u548cpass@k\u7387\uff1a\u63a8\u7406\u65f6\u6548\u7387\u63d0\u5347\uff08\u5982Qwen-2.5-14b-Instruct\u5728\u51e0\u4e4e\u6240\u6709\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u5668\u6548\u7387\u63d0\u534750%\u4ee5\u4e0a\uff09\uff0c\u8bad\u7ec3\u540e\u6027\u80fd\u8d85\u8fc7\u521d\u59cb\u6a21\u578b\u548c\u6807\u51c6RL\u8bad\u7ec3\uff08\u5982Qwen-2.5-7b-Instruct\u5728AIME 2024\u4e0apass@80\u5339\u914dGRPO\u7684pass@256\uff0c\u6d4b\u8bd5\u65f6\u6837\u672c\u6548\u7387\u63d0\u53473\u500d\uff09\u3002", "conclusion": "\u6709\u610f\u8bc6\u7684\u63a2\u7d22\u914d\u5408\u6b63\u786e\u7684\u591a\u6837\u6027\u6982\u5ff5\u662f\u8d85\u8d8a\u7b80\u5355\u4f18\u5316\u7684\u5b9e\u7528\u8def\u5f84\uff0c\u80fd\u591f\u53d1\u73b0\u65b0\u7684\u6a21\u578b\u884c\u4e3a\u3002"}}
{"id": "2510.11691", "categories": ["cs.LG", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.11691", "abs": "https://arxiv.org/abs/2510.11691", "authors": ["Taira Tsuchiya"], "title": "Tight Regret Upper and Lower Bounds for Optimistic Hedge in Two-Player Zero-Sum Games", "comment": "29 pages, 2 figures", "summary": "In two-player zero-sum games, the learning dynamic based on optimistic Hedge\nachieves one of the best-known regret upper bounds among strongly-uncoupled\nlearning dynamics. With an appropriately chosen learning rate, the social and\nindividual regrets can be bounded by $O(\\log(mn))$ in terms of the numbers of\nactions $m$ and $n$ of the two players. This study investigates the optimality\nof the dependence on $m$ and $n$ in the regret of optimistic Hedge. To this\nend, we begin by refining existing regret analysis and show that, in the\nstrongly-uncoupled setting where the opponent's number of actions is known,\nboth the social and individual regret bounds can be improved to $O(\\sqrt{\\log m\n\\log n})$. In this analysis, we express the regret upper bound as an\noptimization problem with respect to the learning rates and the coefficients of\ncertain negative terms, enabling refined analysis of the leading constants. We\nthen show that the existing social regret bound as well as these new social and\nindividual regret upper bounds cannot be further improved for optimistic Hedge\nby providing algorithm-dependent individual regret lower bounds. Importantly,\nthese social regret upper and lower bounds match exactly including the constant\nfactor in the leading term. Finally, building on these results, we improve the\nlast-iterate convergence rate and the dynamic regret of a learning dynamic\nbased on optimistic Hedge, and complement these bounds with algorithm-dependent\ndynamic regret lower bounds that match the improved bounds.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e50\u89c2Hedge\u7b97\u6cd5\u5728\u4e24\u4eba\u96f6\u548c\u535a\u5f08\u4e2d\u7684\u9057\u61be\u6700\u4f18\u6027\uff0c\u6539\u8fdb\u4e86\u73b0\u6709\u7684\u9057\u61be\u4e0a\u754c\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u65b0\u7684\u793e\u4ea4\u548c\u4e2a\u4f53\u9057\u61be\u4e0a\u754c\u4e3aO(\u221a(log m log n))\uff0c\u5e76\u63d0\u4f9b\u4e86\u5339\u914d\u7684\u7b97\u6cd5\u76f8\u5173\u4e0b\u754c\uff0c\u6700\u540e\u6539\u8fdb\u4e86\u6700\u540e\u8fed\u4ee3\u6536\u655b\u7387\u548c\u52a8\u6001\u9057\u61be\u3002", "motivation": "\u7814\u7a76\u4e50\u89c2Hedge\u7b97\u6cd5\u5728\u4e24\u4eba\u96f6\u548c\u535a\u5f08\u4e2d\u7684\u9057\u61be\u6700\u4f18\u6027\uff0c\u7279\u522b\u662f\u5bf9\u52a8\u4f5c\u6570m\u548cn\u7684\u4f9d\u8d56\u5173\u7cfb\u662f\u5426\u6700\u4f18\u3002", "method": "\u901a\u8fc7\u5c06\u9057\u61be\u4e0a\u754c\u8868\u793a\u4e3a\u5173\u4e8e\u5b66\u4e60\u7387\u548c\u67d0\u4e9b\u8d1f\u9879\u7cfb\u6570\u7684\u4f18\u5316\u95ee\u9898\uff0c\u8fdb\u884c\u7cbe\u5316\u5206\u6790\uff1b\u63d0\u4f9b\u7b97\u6cd5\u76f8\u5173\u7684\u4e2a\u4f53\u9057\u61be\u4e0b\u754c\u6765\u8bc1\u660e\u4e0a\u754c\u7684\u7d27\u6027\u3002", "result": "\u5728\u5f3a\u89e3\u8026\u8bbe\u7f6e\u4e0b\uff0c\u793e\u4ea4\u548c\u4e2a\u4f53\u9057\u61be\u4e0a\u754c\u6539\u8fdb\u4e3aO(\u221a(log m log n))\uff1b\u8bc1\u660e\u4e86\u8fd9\u4e9b\u4e0a\u754c\u65e0\u6cd5\u8fdb\u4e00\u6b65\u6539\u8fdb\uff0c\u4e14\u793e\u4ea4\u9057\u61be\u7684\u4e0a\u4e0b\u754c\u5728\u4e3b\u5bfc\u9879\u5e38\u6570\u4e0a\u5b8c\u5168\u5339\u914d\u3002", "conclusion": "\u4e50\u89c2Hedge\u7b97\u6cd5\u7684\u9057\u61be\u4e0a\u754c\u5728\u52a8\u4f5c\u6570\u4f9d\u8d56\u5173\u7cfb\u4e0a\u662f\u6700\u4f18\u7684\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u7ed3\u679c\u6539\u8fdb\u4e86\u6700\u540e\u8fed\u4ee3\u6536\u655b\u7387\u548c\u52a8\u6001\u9057\u61be\uff0c\u5e76\u63d0\u4f9b\u4e86\u5339\u914d\u7684\u52a8\u6001\u9057\u61be\u4e0b\u754c\u3002"}}
